[{"categories":"posts","content":"A2A 的安全性设计：认证、加密与访问控制 摘要：在企业 AI 系统中，安全性是代理间协作的基石。A2A（Agent2Agent）协议通过认证、加密和访问控制机制，确保通信的机密性、完整性和可信性。本文深入剖析 A2A 的安全性设计，聚焦 AgentAuthentication 的实现、HTTPS/WSS 加密、访问控制策略及其在分布式场景中的应用。结合 GitHub 仓库的实现、Mermaid 图表和代码示例，我们将揭示 A2A 如何通过硬核的安全机制保护多代理系统，为开发者提供深入的技术洞察。\n1. 引言：安全性的核心地位 随着 AI 代理在企业场景中的广泛应用（如财务处理、供应链协调），代理间通信可能涉及敏感数据，例如财务记录或用户隐私。任何安全漏洞都可能导致数据泄露、篡改或未授权访问。Google 的 A2A（Agent2Agent） 协议通过以下安全机制应对这些挑战：\n认证（Authentication）：验证代理身份，防止伪造。 加密（Encryption）：保护通信数据的机密性和完整性。 访问控制（Authorization）：限制代理的操作权限，确保最小权限原则。 A2A 的安全性设计基于 JSON Schema（a2a.json）和通信协议（HTTP/WebSocket），兼顾简单性和扩展性。本文将深入解析这些机制，结合 Google A2A GitHub 仓库 的实现，揭示其硬核内核。\n2. A2A 安全架构概览 A2A 的安全架构围绕代理间通信的核心环节设计，包括 AgentCard 交换、任务提交和状态更新。以下是安全架构的示意图：\ngraph TD A[Host Agent] --\u0026amp;gt;|HTTPS/WSS| B[Remote Agent] A --\u0026amp;gt; C[AgentAuthentication] B --\u0026amp;gt; C A --\u0026amp;gt; D[TLS Encryption] B --\u0026amp;gt; D A --\u0026amp;gt; E[Access Control] B --\u0026amp;gt; E C --\u0026amp;gt; F[Bearer Token] C --\u0026amp;gt; G[Future: OAuth 2.0] D --\u0026amp;gt; H[Data Integrity] E --\u0026amp;gt; I[Role-Based Access] style A …","date":1744777857,"description":"","fuzzywordcount":3400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"07616048b505ee20156486b7a0bb32f2","publishdate":1744777857,"relpermalink":"/posts/google/a2a/a2a10/","section":"posts","summary":"\u003ch1 id=\"a2a-的安全性设计认证加密与访问控制\"\u003eA2A 的安全性设计：认证、加密与访问控制\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：在企业 AI 系统中，安全性是代理间协作的基石。A2A（Agent2Agent）协议通过认证、加密和访问控制机制，确保通信的机密性、完整性和可信性。本文深入剖析 A2A 的安全性设计，聚焦 AgentAuthentication 的实现、HTTPS/WSS 加密、访问控制策略及其在分布式场景中的应用。结合 GitHub 仓库的实现、Mermaid 图表和代码示例，我们将揭示 A2A 如何通过硬核的安全机制保护多代理系统，为开发者提供深入的技术洞察。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (十) A2A 的安全性设计：认证、加密与访问控制","url":"https://yinlongfei.com/posts/google/a2a/a2a10/","wordcount":3395},{"categories":"posts","content":"性能优化：A2A 的流式传输与可靠性 摘要：流式传输和推送通知是 A2A（Agent2Agent）协议支持实时交互和高并发场景的关键特性。本文深入剖析 A2A 的流式传输（streaming）和推送通知（pushNotifications）机制，聚焦性能优化策略、可靠性设计和实现细节。结合 GitHub 仓库的实现、Mermaid 图表和社区讨论（GitHub Issues），我们将揭示 A2A 如何通过硬核的优化支持企业级多代理系统，为开发者提供深入的技术洞察。\n1. 引言：流式传输与可靠性的重要性 在企业 AI 系统中，代理（Agent）需要实时处理高并发的任务请求，例如实时客服、财务审批或多代理协作。Google 的 A2A（Agent2Agent） 协议通过流式传输（streaming）和推送通知（pushNotifications）机制，支持低延迟的动态交互和状态更新。然而，这些特性在高负载场景下带来了性能和可靠性挑战：\n性能：流式传输需要高效的带宽利用和低延迟处理。 可靠性：推送通知必须确保消息送达，即使在网络不稳定时。 扩展性：支持数千并发连接和大规模任务。 本文将深入分析 A2A 的流式传输和推送通知机制，探讨性能优化和可靠性设计，结合 Google A2A GitHub 仓库 的实现和社区改进计划，揭示其硬核内核。\n2. 流式传输与推送通知概览 2.1 流式传输（Streaming） A2A 的流式传输通过 WebSocket 实现，支持实时数据交换，适用于以下场景：\n音视频交互：通过 WebRTC 传输实时流媒体（见第十一篇）。 任务进度更新：分块传输任务结果，减少延迟。 动态交互：支持多模态交互（如中途切换到表单）。 流式传输由 AgentCard 的 capabilities.streaming 字段启用：\n1 2 3 4 5 6 7 { \u0026amp;#34;name\u0026amp;#34;: \u0026amp;#34;CustomerSupportAgent\u0026amp;#34;, \u0026amp;#34;capabilities\u0026amp;#34;: { \u0026amp;#34;streaming\u0026amp;#34;: true, \u0026amp;#34;interactionModes\u0026amp;#34;: [\u0026amp;#34;text\u0026amp;#34;, \u0026amp;#34;video\u0026amp;#34;] } } 2.2 推送通知（PushNotifications） …","date":1744777857,"description":"","fuzzywordcount":3e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"ff690263b4a5458c75e9b703fcd67745","publishdate":1744777857,"relpermalink":"/posts/google/a2a/a2a12/","section":"posts","summary":"\u003ch1 id=\"性能优化a2a-的流式传输与可靠性\"\u003e性能优化：A2A 的流式传输与可靠性\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：流式传输和推送通知是 A2A（Agent2Agent）协议支持实时交互和高并发场景的关键特性。本文深入剖析 A2A 的流式传输（streaming）和推送通知（pushNotifications）机制，聚焦性能优化策略、可靠性设计和实现细节。结合 GitHub 仓库的实现、Mermaid 图表和社区讨论（GitHub Issues），我们将揭示 A2A 如何通过硬核的优化支持企业级多代理系统，为开发者提供深入的技术洞察。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (十二) 性能优化：A2A 的流式传输与可靠性","url":"https://yinlongfei.com/posts/google/a2a/a2a12/","wordcount":2983},{"categories":"posts","content":"快速入门：搭建你的第一个 A2A 代理 摘要：A2A（Agent2Agent）协议通过标准化的通信机制实现了 AI 代理间的协作。本文通过分步教程，指导开发者基于 Google 的 A2A 协议搭建第一个代理，聚焦 Python 实现、AgentCard 配置和任务处理逻辑。结合 GitHub 仓库的 google_adk 示例、Mermaid 图表和调试技巧，我们将揭示 A2A 代理开发的硬核细节，帮助开发者快速上手并为企业 AI 系统构建高效的协作组件。\n1. 引言：为什么搭建 A2A 代理？ 在企业 AI 系统中，代理（Agent）是处理特定任务的独立模块，例如费用报销、客服支持或数据分析。Google 的 A2A（Agent2Agent） 协议通过 AgentCard、任务生命周期和 HTTP/WebSocket 通信，标准化了代理间的协作。搭建一个 A2A 代理不仅能帮助开发者理解协议的核心机制，还能为复杂系统（如多代理协作）奠定基础。\n本文基于 GitHub 仓库 https://github.com/google/A2A 的 samples/python/agents/google_adk 示例，展示如何从零搭建一个费用报销代理，覆盖环境配置、代码实现、测试和调试。无论你是初学者还是资深开发者，这篇硬核教程都将为你提供实操指导。\n2. 前置条件与环境准备 2.1 开发环境 操作系统：Windows、macOS 或 Linux。 Python：3.8 或以上，推荐 3.10。 依赖：aiohttp（异步 HTTP）、websockets（WebSocket 支持）、a2a（A2A 库，假设已发布）。 工具：Git、VS Code 或 PyCharm、Postman（可选，测试 API）。 2.2 安装依赖 克隆 A2A 仓库并安装依赖：\n1 2 3 git clone https://github.com/google/A2A.git cd A2A/samples/python/agents/google_adk pip install aiohttp websockets 如果 a2a 库尚未发布，可直接使用仓库中的 a2a.py 模块（假设包含 A2AServer 和 A2AClient 类）。\n2.3 项目结构 创建以下目录结构： …","date":1744777857,"description":"","fuzzywordcount":2800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"03d02955ea4c5d14336c437f0109fb9c","publishdate":1744777857,"relpermalink":"/posts/google/a2a/a2a13/","section":"posts","summary":"\u003ch1 id=\"快速入门搭建你的第一个-a2a-代理\"\u003e快速入门：搭建你的第一个 A2A 代理\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：A2A（Agent2Agent）协议通过标准化的通信机制实现了 AI 代理间的协作。本文通过分步教程，指导开发者基于 Google 的 A2A 协议搭建第一个代理，聚焦 Python 实现、AgentCard 配置和任务处理逻辑。结合 GitHub 仓库的 \u003ccode\u003egoogle_adk\u003c/code\u003e 示例、Mermaid 图表和调试技巧，我们将揭示 A2A 代理开发的硬核细节，帮助开发者快速上手并为企业 AI 系统构建高效的协作组件。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (十三) 快速入门：搭建你的第一个 A2A 代理","url":"https://yinlongfei.com/posts/google/a2a/a2a13/","wordcount":2712},{"categories":"posts","content":"构建多代理系统：A2A 的协同工作 摘要：A2A（Agent2Agent）协议通过标准化的通信机制支持多个 AI 代理协同完成复杂任务。本文深入探讨如何设计和实现多代理系统，以费用报销和汇率转换为例，展示 Host Agent 和 Remote Agent 的协作逻辑。结合 GitHub 仓库的 google_adk 示例、Mermaid 图表和优化策略，我们将揭示 A2A 在企业级协作场景中的硬核实现细节，为开发者提供实用指导。\n1. 引言：多代理系统的价值 在企业 AI 场景中，单一代理往往无法处理复杂任务。例如，费用报销可能需要验证金额、转换货币并生成报告，涉及多个专业模块。Google 的 A2A（Agent2Agent） 协议通过 AgentCard、任务委托和 HTTP/WebSocket 通信，允许 Host Agent 协调多个 Remote Agent 完成工作。\n本文基于 GitHub 仓库 https://github.com/google/A2A 的 samples/python/agents/google_adk 示例，展示如何构建一个多代理系统，包括费用报销代理（ExpenseAgent）和汇率转换代理（ForexAgent）。我们将覆盖系统设计、代码实现、测试和优化，揭示 A2A 的协同能力。\n2. 多代理系统设计 2.1 系统架构 多代理系统由以下组件组成：\nHost Agent：协调任务，分配子任务给 Remote Agent。 Remote Agent：处理特定任务（如费用报销或汇率转换）。 A2A 协议：通过 AgentCard 和任务通信实现协作。 以下是架构图（参考规划）：\ngraph TD A[User] --\u0026amp;gt; B[Host Agent] B --\u0026amp;gt; C[Remote Agent: Expense] B --\u0026amp;gt; D[Remote Agent: Forex] C --\u0026amp;gt; E[A2A Protocol] D --\u0026amp;gt; E E --\u0026amp;gt; F[Task Results] style B fill:#bbf,stroke:#333 style C fill:#bfb,stroke:#333 style D fill:#ffb,stroke:#333 2.2 协作流程 任务接收：用户通过 Host …","date":1744777857,"description":"","fuzzywordcount":2900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"fa3fb20924299a4f62896aef1be9d798","publishdate":1744777857,"relpermalink":"/posts/google/a2a/a2a14/","section":"posts","summary":"\u003ch1 id=\"构建多代理系统a2a-的协同工作\"\u003e构建多代理系统：A2A 的协同工作\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：A2A（Agent2Agent）协议通过标准化的通信机制支持多个 AI 代理协同完成复杂任务。本文深入探讨如何设计和实现多代理系统，以费用报销和汇率转换为例，展示 Host Agent 和 Remote Agent 的协作逻辑。结合 GitHub 仓库的 \u003ccode\u003egoogle_adk\u003c/code\u003e 示例、Mermaid 图表和优化策略，我们将揭示 A2A 在企业级协作场景中的硬核实现细节，为开发者提供实用指导。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (十四) 构建多代理系统：A2A 的协同工作","url":"https://yinlongfei.com/posts/google/a2a/a2a14/","wordcount":2820},{"categories":"posts","content":"A2A 的扩展性：支持多模态交互 摘要：A2A（Agent2Agent）协议通过支持多模态交互（文本、表单、音视频），为企业 AI 系统提供了灵活的协作能力。动态 UX 协商机制允许代理在运行时切换交互模式，适应复杂场景。本文深入剖析 A2A 的多模态交互设计，聚焦 AgentCard 的 interactionModes、动态协商流程和音视频流的支持。结合 GitHub 仓库的 demo 应用、Mermaid 图表和代码示例，我们将揭示 A2A 如何通过硬核的扩展性设计驱动动态协作，为开发者提供深入的技术洞察。\n1. 引言：多模态交互的必要性 在企业 AI 系统中，代理（Agent）需要与用户或其他代理以多样化的方式交互。例如，一个客服代理可能从文本聊天开始，切换到表单输入发票信息，甚至升级到音视频通话以解决复杂问题。传统的单一模式通信（如 REST API 的 JSON）无法满足这些动态需求。Google 的 A2A（Agent2Agent） 协议通过支持多模态交互（文本、表单、音视频），提供了高度扩展的协作框架。\nA2A 的多模态交互基于 AgentCard 的 capabilities.interactionModes 和动态 UX 协商，允许代理在运行时协商最合适的交互方式。本文将深入解析这一机制，结合 Google A2A GitHub 仓库 的 demo 应用，揭示其硬核内核。\n2. 多模态交互概览 A2A 的多模态交互允许代理支持以下模式：\n文本：基于 JSON 或纯文本的交互，适合简单任务（如查询状态）。 表单：结构化输入（如 HTML 表单或 JSON Schema），用于收集复杂数据。 音视频：实时流媒体，用于客服、教育或远程协作场景。 这些模式通过 AgentCard 的 interactionModes 字段声明，例如：\n1 2 3 4 5 6 7 8 9 { \u0026amp;#34;name\u0026amp;#34;: \u0026amp;#34;CustomerSupportAgent\u0026amp;#34;, \u0026amp;#34;url\u0026amp;#34;: \u0026amp;#34;https://example.com/a2a\u0026amp;#34;, \u0026amp;#34;capabilities\u0026amp;#34;: { \u0026amp;#34;interactionModes\u0026amp;#34;: [\u0026amp;#34;text\u0026amp;#34;, \u0026amp;#34;form\u0026amp;#34;, …","date":1744777857,"description":"","fuzzywordcount":3e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"6343994d4feb2bac9ef9ec7b5788bc3c","publishdate":1744777857,"relpermalink":"/posts/google/a2a/a2a11/","section":"posts","summary":"\u003ch1 id=\"a2a-的扩展性支持多模态交互\"\u003eA2A 的扩展性：支持多模态交互\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：A2A（Agent2Agent）协议通过支持多模态交互（文本、表单、音视频），为企业 AI 系统提供了灵活的协作能力。动态 UX 协商机制允许代理在运行时切换交互模式，适应复杂场景。本文深入剖析 A2A 的多模态交互设计，聚焦 AgentCard 的 \u003ccode\u003einteractionModes\u003c/code\u003e、动态协商流程和音视频流的支持。结合 GitHub 仓库的 demo 应用、Mermaid 图表和代码示例，我们将揭示 A2A 如何通过硬核的扩展性设计驱动动态协作，为开发者提供深入的技术洞察。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (十一) A2A 的扩展性：支持多模态交互","url":"https://yinlongfei.com/posts/google/a2a/a2a11/","wordcount":2987},{"categories":"posts","content":"A2A 的通信机制：HTTP vs WebSocket 摘要：通信机制是 A2A（Agent2Agent）协议的核心，决定了代理间如何高效交换 AgentCard、任务和状态更新。A2A 支持 HTTP 和 WebSocket，分别满足简单请求和实时交互的需求。本文深入剖析 A2A 的通信机制，聚焦 HTTP 和 WebSocket 的设计、实现细节、性能对比及其在代理协作中的应用。结合 GitHub 仓库的实现、Mermaid 图表和代码示例，我们将揭示 A2A 如何通过硬核的通信设计支持动态协作，为开发者提供深入的技术洞察。\n1. 引言：通信机制的基石 在企业 AI 系统中，代理（Agent）通过通信交换任务、元数据和状态更新，驱动从费用报销到实时客服的复杂协作。Google 的 A2A（Agent2Agent） 协议采用 HTTP 和 WebSocket 作为通信机制，分别满足同步请求和实时交互的需求。这种双协议设计借鉴了分布式系统的通信模式（如 REST 和 WebSocket），但针对 AI 代理的动态性进行了优化。\nHTTP 提供简单、可靠的请求-响应模型，适合获取 AgentCard 或提交任务；WebSocket 提供持久连接，支持实时状态更新和多模态交互。本文将深入解析 A2A 的通信机制，结合 Google A2A GitHub 仓库 的实现，揭示其硬核内核。\n2. A2A 通信机制概览 A2A 的通信机制围绕代理间的核心交互设计，包括：\nAgentCard 交换：Host Agent 获取 Remote Agent 的元数据。 任务提交与处理：Host Agent 提交任务，Remote Agent 返回结果。 状态更新：实时通知任务状态变化（如 in_progress 到 completed）。 动态交互：支持文本、表单、音视频等模式的协商和传输。 以下是通信机制的架构示意图：\ngraph TD A[Host Agent] --\u0026amp;gt;|HTTP| B[Remote Agent] A --\u0026amp;gt;|WebSocket| C[Remote Agent] B --\u0026amp;gt; D[AgentCard Response] B --\u0026amp;gt; E[Task Response] C --\u0026amp;gt; F[Status Updates] C --\u0026amp;gt; …","date":1744777497,"description":"","fuzzywordcount":3500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"457d2976ac0af115a2b92925f329c23c","publishdate":1744777497,"relpermalink":"/posts/google/a2a/a2a9/","section":"posts","summary":"\u003ch1 id=\"a2a-的通信机制http-vs-websocket\"\u003eA2A 的通信机制：HTTP vs WebSocket\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：通信机制是 A2A（Agent2Agent）协议的核心，决定了代理间如何高效交换 AgentCard、任务和状态更新。A2A 支持 HTTP 和 WebSocket，分别满足简单请求和实时交互的需求。本文深入剖析 A2A 的通信机制，聚焦 HTTP 和 WebSocket 的设计、实现细节、性能对比及其在代理协作中的应用。结合 GitHub 仓库的实现、Mermaid 图表和代码示例，我们将揭示 A2A 如何通过硬核的通信设计支持动态协作，为开发者提供深入的技术洞察。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (九) A2A 的通信机制：HTTP vs WebSocket","url":"https://yinlongfei.com/posts/google/a2a/a2a9/","wordcount":3476},{"categories":"posts","content":"生态集成：与大数据框架的无缝连接 1. 引言 KWDB（KaiwuDB）是一款为AIoT（人工智能物联网）场景设计的分布式多模数据库，其强大的生态集成能力使其能够无缝融入大数据处理生态，与Apache Spark、Flink等框架协同工作，满足复杂数据分析和实时流处理需求。在最新版本v2.2.0（2025年Q1发布），KWDB优化了连接层（支持gRPC并发增强）、新增了Go语言客户端实验性支持，并提升了与大数据框架的兼容性，显著降低了集成成本。\n本篇将深入剖析KWDB v2.2.0的生态集成机制，聚焦其与Spark、Flink等框架的连接方式、实现原理和新特性，揭示其如何在AIoT场景中实现高效数据流转和分析。内容结合代码示例和Mermaid图表，适合希望将KWDB融入大数据生态的开发者和架构师。\n2. 生态集成概览 KWDB的生态集成能力基于其灵活的连接层和标准化的数据接口，核心目标包括：\n无缝连接：支持与主流大数据框架（如Spark、Flink）的高效集成。 高性能：确保数据读写和处理过程中的低延迟和高吞吐。 多语言支持：提供Python、Java、C++和v2.2.0新增的Go客户端，适配多样化开发需求。 v2.2.0新特性： gRPC并发优化：连接层并发处理能力提升约15%，支持高负载场景。 Go语言支持：实验性Go客户端，扩展开发生态。 增强兼容性：优化Spark和Flink连接器，提升数据传输效率。 集成涉及以下组件：\n连接层：支持HTTP、gRPC和多语言驱动。 数据接口：提供SQL和NoSQL风格的访问方式。 生态工具：支持KMP（数据迁移平台）和KAP（自治平台）。 Mermaid图表：生态集成架构 classDiagram class 生态集成系统 { +连接层 +数据接口 +生态工具 } 生态集成系统 --\u0026amp;gt; 连接层 : HTTP/gRPC+多语言 生态集成系统 --\u0026amp;gt; 数据接口 : SQL/NoSQL 生态集成系统 --\u0026amp;gt; 生态工具 : KMP/KAP 连接层 --\u0026amp;gt; Spark : 数据源 连接层 --\u0026amp;gt; Flink : 流处理 连接层 --\u0026amp;gt; Go客户端 : 新支持 3. 与Apache Spark集成：批处理与分析 3.1 设计目标 Spark集成旨在利用KWDB的多模数据（时序+关系）进行大规模批处 …","date":1744607937,"description":"","fuzzywordcount":3200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"df0d9b4e1a1ce95f50493176cbece6ba","publishdate":1744607937,"relpermalink":"/posts/database/langchao/kwdb/kwdb14/","section":"posts","summary":"\u003ch1 id=\"生态集成与大数据框架的无缝连接\"\u003e生态集成：与大数据框架的无缝连接\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003eKWDB（KaiwuDB）是一款为AIoT（人工智能物联网）场景设计的分布式多模数据库，其强大的生态集成能力使其能够无缝融入大数据处理生态，与Apache Spark、Flink等框架协同工作，满足复杂数据分析和实时流处理需求。在最新版本v2.2.0（2025年Q1发布），KWDB优化了连接层（支持gRPC并发增强）、新增了Go语言客户端实验性支持，并提升了与大数据框架的兼容性，显著降低了集成成本。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （十四） 生态集成：与大数据框架的无缝连接","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb14/","wordcount":3174},{"categories":"posts","content":"性能优化：从查询到写入的极致加速 1. 引言 KWDB（KaiwuDB）是一款为AIoT（人工智能物联网）场景打造的分布式多模数据库，面对高频写入和复杂查询的挑战，性能是其核心竞争力。在最新版本v2.2.0（2025年Q1发布），KWDB通过查询计划缓存、并行执行优化和WAL写入提速等新特性，显著提升了性能：跨模查询延迟降低约30%，写入吞吐量提升约10%。这些优化使KWDB在车联网、工业物联网等高并发场景中表现出色。\n本篇将深入剖析KWDB v2.2.0的性能优化机制，聚焦查询、写入和分布式处理的加速技术，揭示其如何实现极致性能。内容结合代码示例和Mermaid图表，适合希望优化KWDB应用的开发者和架构师。\n2. 性能优化概览 KWDB的性能优化涵盖查询、写入和分布式协同，核心目标包括：\n低延迟查询：亿级数据秒级响应，支持复杂跨模分析。 高吞吐写入：支持百万级每秒写入，适配高频时序数据。 分布式效率：优化节点间通信和负载均衡，提升集群性能。 v2.2.0新特性： 查询计划缓存：高频查询性能提升约20%。 并行执行优化：跨模查询延迟降低约30%。 WAL写入提速：批量写入和异步I/O提升吞吐量约10%。 优化涉及以下组件：\n查询引擎：解析、优化和执行SQL。 存储引擎：管理时序和关系数据。 分布式管理：协调分片和副本。 WAL与CHECKPOINT：保障一致性与性能。 Mermaid图表：性能优化架构 classDiagram class 性能优化系统 { +查询引擎 +存储引擎 +分布式管理 +WAL与CHECKPOINT } 性能优化系统 --\u0026amp;gt; 查询引擎 : 计划缓存+并行执行 性能优化系统 --\u0026amp;gt; 存储引擎 : 压缩+索引 性能优化系统 --\u0026amp;gt; 分布式管理 : 分片+负载均衡 性能优化系统 --\u0026amp;gt; WAL与CHECKPOINT : 批量写入 3. 查询优化：低延迟与高效率 3.1 设计目标 查询优化旨在降低复杂SQL（尤其是跨模查询）的延迟，支持实时分析和监控。\n3.2 实现机制 查询计划缓存： v2.2.0新增缓存机制，存储高频查询的执行计划，减少重复解析和优化开销。 缓存命中率达90%时，查询性能提升约20%。 并行执行优化： 查询分解为子任务，多线程并行处理，v2.2.0优化任务调度，跨模查询延迟降低30%。 例如，时序和关系 …","date":1744604337,"description":"","fuzzywordcount":2700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"6d444682cc2dce962e5a684896567787","publishdate":1744604337,"relpermalink":"/posts/database/langchao/kwdb/kwdb13/","section":"posts","summary":"\u003ch1 id=\"性能优化从查询到写入的极致加速\"\u003e性能优化：从查询到写入的极致加速\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003eKWDB（KaiwuDB）是一款为AIoT（人工智能物联网）场景打造的分布式多模数据库，面对高频写入和复杂查询的挑战，性能是其核心竞争力。在最新版本v2.2.0（2025年Q1发布），KWDB通过查询计划缓存、并行执行优化和WAL写入提速等新特性，显著提升了性能：跨模查询延迟降低约30%，写入吞吐量提升约10%。这些优化使KWDB在车联网、工业物联网等高并发场景中表现出色。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （十三） 性能优化：从查询到写入的极致加速","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb13/","wordcount":2601},{"categories":"posts","content":"高可用设计：故障自愈与多副本策略 1. 引言 KWDB（KaiwuDB）是一款专为AIoT（人工智能物联网）场景设计的分布式多模数据库，其高可用（High Availability, HA）设计确保在节点故障或网络异常时，系统仍能提供不间断服务。在最新版本v2.2.0（2025年Q1发布），KWDB通过优化故障自愈机制（恢复时间缩短至2秒）和副本同步效率（延迟降低约10%），显著提升了集群可靠性，满足车联网、工业物联网等高并发场景的需求。\n本篇将深入剖析KWDB v2.2.0的高可用设计，聚焦故障自愈和多副本策略的原理、实现和新特性，揭示其如何保障AIoT应用的连续性和数据一致性。内容结合代码示例和Mermaid图表，适合希望构建健壮KWDB集群的开发者和架构师。\n2. 高可用设计概览 KWDB的高可用设计基于分布式架构，核心目标是：\n零服务中断：节点故障时，系统自动切换，查询和写入不受影响。 数据一致性：多副本机制确保数据在故障后仍可访问且一致。 动态扩展：支持节点添加或移除，保持高可用性。 v2.2.0新特性： 秒级故障自愈：故障检测和副本切换时间从5秒缩短至2秒。 副本同步优化：异步复制延迟降低约10%，提升性能。 自适应副本分配：根据节点负载动态调整副本分布。 高可用设计依赖以下组件：\n多副本复制：数据分片存储多个副本，分布在不同节点。 故障检测与自愈：心跳机制快速识别故障，自动切换副本。 负载均衡：确保副本访问均衡，避免热点。 Mermaid图表：高可用架构 classDiagram class 高可用系统 { +多副本复制 +故障检测与自愈 +负载均衡 +动态扩展 } 高可用系统 --\u0026amp;gt; 多副本复制 : 主副本+副本 高可用系统 --\u0026amp;gt; 故障检测与自愈 : 心跳+切换 高可用系统 --\u0026amp;gt; 负载均衡 : 副本访问均衡 高可用系统 --\u0026amp;gt; 动态扩展 : 节点调整 多副本复制 --\u0026amp;gt; 存储层 : 数据一致性 3. 多副本复制：数据可靠性的基石 3.1 设计目标 多副本复制通过在多个节点存储数据副本，确保故障时数据仍可访问，同时保证一致性和性能。\n3.2 实现机制 副本结构：每个数据分片（shard）包含一个主副本（primary）和多个从副本（replica），默认3份，分布在不同节点。 异步复制： 主副本接收写入操作，记 …","date":1744600737,"description":"","fuzzywordcount":2600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"8496c34ba6d327e605d7fca22e97d6a3","publishdate":1744600737,"relpermalink":"/posts/database/langchao/kwdb/kwdb12/","section":"posts","summary":"\u003ch1 id=\"高可用设计故障自愈与多副本策略\"\u003e高可用设计：故障自愈与多副本策略\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003eKWDB（KaiwuDB）是一款专为AIoT（人工智能物联网）场景设计的分布式多模数据库，其高可用（High Availability, HA）设计确保在节点故障或网络异常时，系统仍能提供不间断服务。在最新版本v2.2.0（2025年Q1发布），KWDB通过优化故障自愈机制（恢复时间缩短至2秒）和副本同步效率（延迟降低约10%），显著提升了集群可靠性，满足车联网、工业物联网等高并发场景的需求。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （十二） 高可用设计：故障自愈与多副本策略","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb12/","wordcount":2571},{"categories":"posts","content":"KWDB的压缩技术：平衡性能与存储 1. 引言 KWDB（KaiwuDB）是一款专为AIoT（人工智能物联网）场景设计的分布式多模数据库，面对物联网设备生成的高频时序数据，存储效率是其核心挑战之一。KWDB通过先进的压缩技术，在保证高性能写入和查询的同时，显著降低存储成本。在最新版本v2.2.0（2025年Q1发布），KWDB引入了改进的Delta-of-Delta编码和动态压缩策略，使时序数据的压缩率提升约20%，解压速度提高约15%，进一步优化了性能与存储的平衡。\n本篇将深入剖析KWDB v2.2.0的压缩技术，探讨其设计原理、实现机制及新特性，揭示其如何在AIoT场景中高效管理海量数据。内容结合代码示例和Mermaid图表，适合希望优化KWDB存储效率的开发者和架构师。\n2. 压缩技术概览 KWDB的压缩技术主要针对时序数据（如传感器读数、设备日志），同时对关系数据提供轻量压缩。其核心目标包括：\n高压缩率：减少存储空间，降低硬件成本。 低计算开销：确保压缩和解压过程不影响写入和查询性能。 灵活性：适配不同数据模式（如高频低变差或高变差数据）。 v2.2.0新特性： 改进的Delta-of-Delta编码：时序数据压缩率提升约20%，特别适合连续性强的场景。 动态压缩策略：根据数据特征自适应选择压缩算法。 快速解压：解压速度提升约15%，优化查询性能。 Mermaid图表：压缩技术架构 classDiagram class 压缩引擎 { +时序数据压缩 +关系数据压缩 +动态压缩策略 } 压缩引擎 --\u0026amp;gt; 时序数据压缩 : Delta-of-Delta编码 压缩引擎 --\u0026amp;gt; 关系数据压缩 : 轻量编码 压缩引擎 --\u0026amp;gt; 动态压缩策略 : 自适应选择 时序数据压缩 --\u0026amp;gt; 存储层 : 压缩数据 3. 时序数据压缩：高压缩率与低开销 3.1 设计目标 时序数据是AIoT场景的核心，具有高频写入、连续性和低变差的特点（例如，温度传感器数据变化平滑）。KWDB的时序压缩技术旨在：\n最大化压缩率：减少存储占用，适配亿级数据场景。 最小化性能影响：压缩和解压速度快，支持百万级每秒写入。 支持高精度：适配v2.2.0引入的纳秒级时间戳。 3.2 实现机制 Delta-of-Delta编码： 原理：记录连续数据点之间的差值（Delta），再对差值进行二次 …","date":1744597137,"description":"","fuzzywordcount":3e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"0a219cb3d717893ac69ab7a8ab223cf5","publishdate":1744597137,"relpermalink":"/posts/database/langchao/kwdb/kwdb11/","section":"posts","summary":"\u003ch1 id=\"kwdb的压缩技术平衡性能与存储\"\u003eKWDB的压缩技术：平衡性能与存储\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003eKWDB（KaiwuDB）是一款专为AIoT（人工智能物联网）场景设计的分布式多模数据库，面对物联网设备生成的高频时序数据，存储效率是其核心挑战之一。KWDB通过先进的压缩技术，在保证高性能写入和查询的同时，显著降低存储成本。在最新版本v2.2.0（2025年Q1发布），KWDB引入了改进的Delta-of-Delta编码和动态压缩策略，使时序数据的压缩率提升约20%，解压速度提高约15%，进一步优化了性能与存储的平衡。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （十一） KWDB的压缩技术：平衡性能与存储","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb11/","wordcount":2903},{"categories":"posts","content":"WAL与CHECKPOINT：确保数据一致性的秘密 1. 引言 KWDB（KaiwuDB）作为一款面向AIoT场景的分布式多模数据库，处理高并发写入和大规模数据时，数据一致性和可靠性是其核心要求。Write-Ahead Logging (WAL) 和 CHECKPOINT 机制是KWDB确保数据一致性的关键技术，在分布式环境中保障事务完整性和故障恢复能力。在最新版本v2.2.0（2025年Q1发布），KWDB优化了WAL写入性能和CHECKPOINT效率，进一步降低了I/O开销和恢复时间，适配高频时序数据场景。\n本篇将深入剖析KWDB v2.2.0的WAL和CHECKPOINT机制，探讨其设计原理、实现细节和新特性，揭示其如何为AIoT应用提供可靠的数据保障。内容结合代码示例和Mermaid图表，适合希望理解KWDB一致性机制的开发者和架构师。\n2. WAL与CHECKPOINT概述 WAL和CHECKPOINT是KWDB分布式存储引擎的核心组件，共同确保数据一致性和快速恢复：\nWrite-Ahead Logging (WAL): 在执行写操作（如插入、更新）前，将操作日志预先写入持久化存储，确保即使系统崩溃也能通过日志恢复数据。 CHECKPOINT: 定期将内存中的数据写入磁盘，生成一致性快照，减少WAL日志积累和恢复时间。 v2.2.0新特性: WAL性能优化: 减少I/O开销，写入吞吐量提升约10%。 CHECKPOINT加速: 快照生成速度提升约15%，缩短恢复时间。 分布式一致性: 优化多节点WAL同步，降低跨节点事务延迟。 Mermaid图表：WAL与CHECKPOINT架构 classDiagram class ConsistencyMechanism { +WAL +CHECKPOINT +DistributedSync } ConsistencyMechanism --\u0026amp;gt; WAL : 日志预写 ConsistencyMechanism --\u0026amp;gt; CHECKPOINT : 数据快照 ConsistencyMechanism --\u0026amp;gt; DistributedSync : 多节点一致性 WAL --\u0026amp;gt; Storage : 持久化日志 CHECKPOINT --\u0026amp;gt; Storage : 持久化数据 3. Write-Ahead …","date":1744593537,"description":"","fuzzywordcount":2600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"156577df09fd3c3093581c5cbbb63f04","publishdate":1744593537,"relpermalink":"/posts/database/langchao/kwdb/kwdb10/","section":"posts","summary":"\u003ch1 id=\"wal与checkpoint确保数据一致性的秘密\"\u003eWAL与CHECKPOINT：确保数据一致性的秘密\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003eKWDB（KaiwuDB）作为一款面向AIoT场景的分布式多模数据库，处理高并发写入和大规模数据时，数据一致性和可靠性是其核心要求。Write-Ahead Logging (WAL) 和 CHECKPOINT 机制是KWDB确保数据一致性的关键技术，在分布式环境中保障事务完整性和故障恢复能力。在最新版本v2.2.0（2025年Q1发布），KWDB优化了WAL写入性能和CHECKPOINT效率，进一步降低了I/O开销和恢复时间，适配高频时序数据场景。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （十） WAL与CHECKPOINT：确保数据一致性的秘密","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb10/","wordcount":2516},{"categories":"posts","content":"分布式管理：Range分区与负载均衡 1. 引言 KWDB（KaiwuDB）是一款专为AIoT场景设计的分布式多模数据库，其分布式管理能力是实现高并发、可扩展和高可用性的关键。在最新版本v2.2.0（2025年Q1发布），KWDB通过动态分区调整算法、节点扩展速度提升约15%和秒级故障自愈等新特性，进一步优化了分布式架构，满足了工业物联网、车联网等大规模数据场景的需求。\n本篇将深入剖析KWDB v2.2.0的分布式管理机制，聚焦Range分区、负载均衡和高可用设计，揭示其如何高效处理亿级数据和高并发访问。内容结合代码示例和Mermaid图表，帮助开发者和架构师理解KWDB分布式系统的内核技术及其在AIoT场景中的应用价值。\n2. 分布式管理概述 KWDB的分布式管理模块负责协调集群中的节点，确保数据分布均衡、查询高效和系统高可用。其核心功能包括：\nRange分区：基于数据范围（如时间戳或主键）自动分片，优化数据分布。 负载均衡：动态调整数据和查询负载，防止热点问题。 高可用：多副本复制和故障自愈机制，保障服务连续性。 动态扩展：支持节点在线添加或移除，数据自动迁移。 v2.2.0引入的增强包括：\n动态分区调整：新增算法减少热点数据问题，提升查询效率。 节点扩展优化：数据迁移速度提升约15%。 秒级故障自愈：心跳检测和副本切换时间缩短至秒级。 Mermaid图表：分布式管理架构 classDiagram class DistributedManager { +RangePartitioning +LoadBalancing +HighAvailability +DynamicScaling } DistributedManager --\u0026amp;gt; RangePartitioning : 动态分区 DistributedManager --\u0026amp;gt; LoadBalancing : 负载均衡 DistributedManager --\u0026amp;gt; HighAvailability : 副本+自愈 DistributedManager --\u0026amp;gt; DynamicScaling : 节点扩展 3. Range分区：高效数据分片 3.1 设计目标 AIoT场景的数据量和访问频率快速增长，单节点无法应对。KWDB通过Range分区将数据按范围（如时间戳或主键）分割成 …","date":1744589937,"description":"","fuzzywordcount":2400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"ee16e829b734a66fac244146a9b3aec5","publishdate":1744589937,"relpermalink":"/posts/database/langchao/kwdb/kwdb9/","section":"posts","summary":"\u003ch1 id=\"分布式管理range分区与负载均衡\"\u003e分布式管理：Range分区与负载均衡\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003eKWDB（KaiwuDB）是一款专为AIoT场景设计的分布式多模数据库，其分布式管理能力是实现高并发、可扩展和高可用性的关键。在最新版本v2.2.0（2025年Q1发布），KWDB通过动态分区调整算法、节点扩展速度提升约15%和秒级故障自愈等新特性，进一步优化了分布式架构，满足了工业物联网、车联网等大规模数据场景的需求。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （九） 分布式管理：Range分区与负载均衡","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb9/","wordcount":2325},{"categories":"posts","content":"查询引擎揭秘：跨模SQL的高性能实现 1. 引言 KWDB（KaiwuDB）作为一款面向AIoT场景的分布式多模数据库，其查询引擎是实现高效数据分析和跨模查询的核心组件。在最新版本v2.2.0（2025年Q1发布），KWDB引入了分组窗口函数、查询计划缓存和并行执行优化，使跨模SQL查询性能提升约30%，特别是在处理时序和关系数据的联合分析时表现出色。\n本篇将深入剖析KWDB v2.2.0查询引擎的设计原理、实现机制和新特性，揭示其如何通过SQL解析、优化和执行实现高性能跨模查询。内容将结合代码示例和Mermaid图表，帮助开发者和架构师理解查询引擎的内核技术及其在AIoT场景中的应用价值。\n2. 查询引擎概述 KWDB的查询引擎负责处理用户提交的SQL语句，涵盖以下核心功能：\nSQL解析：将SQL语句转换为抽象语法树（AST）并验证语义。 查询优化：生成高效的执行计划，减少计算和I/O开销。 执行引擎：支持跨模查询（时序+关系）和并行处理，加速结果返回。 新特性（v2.2.0）： 分组窗口函数：支持时间窗口和维度分组的复杂聚合。 查询计划缓存：重复查询性能提升约20%。 并行执行优化：跨模查询延迟降低约30%。 查询引擎与存储引擎紧密协作，通过统一接口访问时序和关系数据，确保高效性和一致性。\nMermaid图表：查询引擎架构 classDiagram class QueryEngine { +SQLParser +QueryOptimizer +ExecutionEngine +PlanCache } QueryEngine --\u0026amp;gt; SQLParser : 语法分析 QueryEngine --\u0026amp;gt; QueryOptimizer : 计划优化 QueryEngine --\u0026amp;gt; ExecutionEngine : 并行执行 QueryEngine --\u0026amp;gt; PlanCache : 缓存计划 QueryEngine --\u0026amp;gt; StorageEngine : 跨模数据访问 3. SQL解析：从文本到执行计划 3.1 设计目标 SQL解析模块将用户输入的SQL语句转换为可执行的逻辑计划，确保语法正确性和语义一致性，同时支持复杂的跨模查询。\n3.2 实现机制 词法分析：将SQL语句分解为令牌（tokens），如关键字、标识符和运算符。 语法分析：基于上 …","date":1744586337,"description":"","fuzzywordcount":2500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"3fc122266bcc0eeca269edabf44c711d","publishdate":1744586337,"relpermalink":"/posts/database/langchao/kwdb/kwdb8/","section":"posts","summary":"\u003ch1 id=\"查询引擎揭秘跨模sql的高性能实现\"\u003e查询引擎揭秘：跨模SQL的高性能实现\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003eKWDB（KaiwuDB）作为一款面向AIoT场景的分布式多模数据库，其查询引擎是实现高效数据分析和跨模查询的核心组件。在最新版本v2.2.0（2025年Q1发布），KWDB引入了分组窗口函数、查询计划缓存和并行执行优化，使跨模SQL查询性能提升约30%，特别是在处理时序和关系数据的联合分析时表现出色。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （八） 查询引擎揭秘：跨模SQL的高性能实现","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb8/","wordcount":2475},{"categories":"posts","content":"多模存储引擎：时序与关系的融合之道 1. 引言 KWDB（KaiwuDB）是一款专为AIoT场景打造的分布式多模数据库，其核心竞争力之一在于多模存储引擎，能够在同一实例内高效管理时序数据（如传感器读数）和关系数据（如设备元信息）。最新版本v2.2.0（2025年Q1发布）通过引入纳秒级时间精度、优化的压缩算法和跨模存储增强，进一步提升了性能和灵活性，满足高精度、高并发场景需求。\n本篇将深入解析KWDB v2.2.0多模存储引擎的设计原理、实现机制和新特性，展示其如何实现时序与关系的无缝融合，为AIoT应用提供高效的数据底座。无论你是开发者还是架构师，本篇将帮助你理解KWDB存储引擎的内核技术及其在实际场景中的优势。\n2. 多模存储引擎概述 KWDB的多模存储引擎是其多模融合能力的核心，支持以下功能：\n时序存储：针对时间序列数据（如传感器数据），提供纳秒级精度和高效压缩。 关系存储：支持结构化数据（如设备信息），提供主键索引和事务支持。 跨模优化：统一存储接口，允许时序和关系数据的联合查询和一致性管理。 高性能：百万级写入、亿级查询，适配AIoT高并发场景。 v2.2.0通过以下新特性增强了存储引擎：\n纳秒级时间精度：时间戳支持纳秒分辨率，适用于高频数据场景。 改进压缩算法：时序数据压缩率提升约20%，降低存储成本。 动态分区：存储层支持更细粒度的分区管理，提升查询效率。 Mermaid图表：多模存储引擎架构 classDiagram class MultiModalStorageEngine { +TimeSeriesStorage +RelationalStorage +UnifiedInterface +DynamicPartitioning } MultiModalStorageEngine --\u0026amp;gt; TimeSeriesStorage : 纳秒级时序+压缩 MultiModalStorageEngine --\u0026amp;gt; RelationalStorage : 行式存储+索引 MultiModalStorageEngine --\u0026amp;gt; UnifiedInterface : 跨模访问 MultiModalStorageEngine --\u0026amp;gt; DynamicPartitioning : 细粒度分区 3. 时序存储：纳秒级精度与高效压缩 3.1 …","date":1744582737,"description":"","fuzzywordcount":2600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"10a28b689045ac2f2433e33c9c9df02d","publishdate":1744582737,"relpermalink":"/posts/database/langchao/kwdb/kwdb7/","section":"posts","summary":"\u003ch1 id=\"多模存储引擎时序与关系的融合之道\"\u003e多模存储引擎：时序与关系的融合之道\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003eKWDB（KaiwuDB）是一款专为AIoT场景打造的分布式多模数据库，其核心竞争力之一在于多模存储引擎，能够在同一实例内高效管理时序数据（如传感器读数）和关系数据（如设备元信息）。最新版本v2.2.0（2025年Q1发布）通过引入纳秒级时间精度、优化的压缩算法和跨模存储增强，进一步提升了性能和灵活性，满足高精度、高并发场景需求。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （七） 多模存储引擎：时序与关系的融合之道","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb7/","wordcount":2536},{"categories":"posts","content":"KWDB技术架构全景 1. 引言 KWDB（KaiwuDB）是一款专为AIoT（人工智能物联网）场景设计的分布式多模数据库，以其多模融合、高性能时序处理和灵活的分布式架构在工业物联网、车联网和智慧城市等领域表现出色。最新版本v2.2.0（2025年Q1发布）引入了多项关键特性，包括纳秒级时间精度、分组窗口函数和跨模查询性能优化，进一步提升了其在高精度、高并发场景下的竞争力。\n本篇将全面剖析KWDB v2.2.0的技术架构，聚焦核心组件（如存储引擎、查询引擎、分布式管理）和新功能如何协同工作，为AIoT应用提供高效、可靠的数据支持。无论你是架构师还是开发者，本篇将帮助你理解KWDB的技术内核及其最新进展。\n2. KWDB v2.2.0技术架构概览 KWDB的架构采用模块化设计，分为以下核心组件：\n存储引擎：支持时序表和关系表，新增纳秒级时间精度和压缩优化。 查询引擎：增强跨模查询性能，支持分组窗口函数和复杂SQL解析。 分布式管理：无中心全对等架构，优化数据分片和节点扩展。 WAL机制：预写日志结合CHECKPOINT，确保数据一致性和故障恢复。 连接层：支持多协议（HTTP、gRPC）和多语言驱动（Python、Java、C++）。 v2.2.0通过性能优化和功能扩展，进一步强化了这些组件的协同能力，特别是在高精度时序数据处理和多模分析场景中。\nMermaid图表：KWDB v2.2.0架构全景 classDiagram class KWDB_Architecture { +StorageEngine +QueryEngine +DistributedManager +WALMechanism +ConnectionLayer } KWDB_Architecture --\u0026amp;gt; StorageEngine : 纳秒级时序+关系表 KWDB_Architecture --\u0026amp;gt; QueryEngine : 跨模查询+分组窗口 KWDB_Architecture --\u0026amp;gt; DistributedManager : 自动分片+负载均衡 KWDB_Architecture --\u0026amp;gt; WALMechanism : 一致性+故障恢复 KWDB_Architecture --\u0026amp;gt; ConnectionLayer : HTTP/gRPC+多语言 3. …","date":1744579137,"description":"","fuzzywordcount":2300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"4bba788a848754c08b8b57f2de4582b6","publishdate":1744579137,"relpermalink":"/posts/database/langchao/kwdb/kwdb6/","section":"posts","summary":"\u003ch1 id=\"kwdb技术架构全景\"\u003eKWDB技术架构全景\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003eKWDB（KaiwuDB）是一款专为AIoT（人工智能物联网）场景设计的分布式多模数据库，以其多模融合、高性能时序处理和灵活的分布式架构在工业物联网、车联网和智慧城市等领域表现出色。最新版本v2.2.0（2025年Q1发布）引入了多项关键特性，包括纳秒级时间精度、分组窗口函数和跨模查询性能优化，进一步提升了其在高精度、高并发场景下的竞争力。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （六） KWDB技术架构全景","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb6/","wordcount":2215},{"categories":"posts","content":"KWDB支持的开发语言和协议 1. 引言 KWDB（KaiwuDB）作为一款面向AIoT场景的分布式多模数据库，不仅在性能和架构上表现出色，还提供了丰富的开发接口和协议支持，方便开发者快速集成到各种应用场景。无论是用Python编写数据分析脚本、用Java开发企业级后端，还是用C++实现高性能边缘计算，KWDB都能通过多语言客户端和灵活的协议满足需求。\n本篇将全面介绍KWDB支持的开发语言和协议，包含安装方法、代码示例和使用场景，帮助你选择合适的开发方式，快速上手KWDB。\n2. 开发语言支持 KWDB提供了多种编程语言的官方客户端驱动，覆盖主流开发场景，确保开发者可以无缝集成。以下是主要支持的语言及其特点。\n2.1 Python 特点：易用性高，适合数据分析、快速原型开发和AIoT数据处理。 适用场景：物联网数据可视化、实时监控脚本、与AI框架（如TensorFlow、PyTorch）集成。 安装： 1 pip install kwdb-client 示例代码：连接KWDB，创建表并查询数据。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from kwdb import KWDBClient # 初始化客户端 client = KWDBClient(host=\u0026amp;#34;localhost\u0026amp;#34;, port=8080) # 创建时序表 client.execute(\u0026amp;#34;\u0026amp;#34;\u0026amp;#34; CREATE TABLE sensor_data ( time TIMESTAMP, device_id STRING, value FLOAT ) \u0026amp;#34;\u0026amp;#34;\u0026amp;#34;) # 插入数据 client.execute(\u0026amp;#34;\u0026amp;#34;\u0026amp;#34; INSERT INTO sensor_data VALUES (\u0026amp;#39;2025-04-12 10:00:00\u0026amp;#39;, \u0026amp;#39;dev001\u0026amp;#39;, 23.5) \u0026amp;#34;\u0026amp;#34;\u0026amp;#34;) # 查询数据 result = client.query(\u0026amp;#34;SELECT * FROM sensor_data\u0026amp;#34;) for row in result: print(row) 输出： …","date":1744575537,"description":"","fuzzywordcount":2400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"4776f9a2fd830290579ec81eced4f496","publishdate":1744575537,"relpermalink":"/posts/database/langchao/kwdb/kwdb5/","section":"posts","summary":"\u003ch2 id=\"kwdb支持的开发语言和协议\"\u003eKWDB支持的开发语言和协议\u003c/h2\u003e\n\u003ch3 id=\"1-引言\"\u003e1. 引言\u003c/h3\u003e\n\u003cp\u003eKWDB（KaiwuDB）作为一款面向AIoT场景的分布式多模数据库，不仅在性能和架构上表现出色，还提供了丰富的开发接口和协议支持，方便开发者快速集成到各种应用场景。无论是用Python编写数据分析脚本、用Java开发企业级后端，还是用C++实现高性能边缘计算，KWDB都能通过多语言客户端和灵活的协议满足需求。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （五） KWDB支持的开发语言和协议","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb5/","wordcount":2351},{"categories":"posts","content":"KWDB核心概念解析：多模、时序与分布式 1. 引言 KWDB（KaiwuDB）作为一款面向AIoT（人工智能物联网）的分布式多模数据库，以其独特的多模融合设计、高效时序处理能力和灵活的分布式架构，满足了物联网场景下复杂数据管理的需求。要深入掌握KWDB，理解其三大核心概念——多模融合、时序数据处理和分布式架构——至关重要。本篇将逐一解析这些概念，揭示KWDB如何在技术上赋能AIoT应用。\n通过本篇，你将了解KWDB的设计理念、技术实现及其与AIoT场景的契合点，为后续开发和优化打下基础。\n2. 多模融合：统一管理时序与关系数据 2.1 什么是多模融合？ AIoT场景中，数据类型多样，包括：\n时序数据：如传感器的时间戳和数值（温度、压力）。 关系数据：如设备元信息（ID、型号、位置）。 其他数据：如日志、事件流等。 传统数据库通常专注于单一模型（如MySQL的关系模型或InfluxDB的时序模型），导致AIoT应用需部署多个数据库，增加复杂性。KWDB的多模融合设计允许在同一数据库实例内同时创建和管理时序表和关系表，通过统一的SQL接口实现跨模查询。\n2.2 实现机制 统一数据模型：KWDB定义了通用表结构，支持时序表（基于时间戳索引）和关系表（支持主键和外键）。两者共享存储引擎，优化数据访问。 跨模查询引擎：KWDB的查询优化器支持SQL解析和联合查询。例如，可通过JOIN操作关联时序数据（如传感器读数）和关系数据（如设备信息）。 高效存储：时序数据采用列式存储和压缩算法，关系数据使用行式存储，兼顾查询性能和存储效率。 2.3 使用示例 假设需要管理工厂设备数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 -- 创建时序表存储传感器数据 CREATE TABLE sensor_data ( time TIMESTAMP, device_id STRING, temperature FLOAT ); -- 创建关系表存储设备信息 CREATE TABLE device_info ( device_id STRING PRIMARY KEY, location STRING ); -- 插入数据 INSERT INTO sensor_data VALUES (\u0026amp;#39;2025-04-12 …","date":1744571937,"description":"","fuzzywordcount":2400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"8574c4d4d3bc5ed599866138469d1478","publishdate":1744571937,"relpermalink":"/posts/database/langchao/kwdb/kwdb4/","section":"posts","summary":"\u003ch2 id=\"kwdb核心概念解析多模时序与分布式\"\u003eKWDB核心概念解析：多模、时序与分布式\u003c/h2\u003e\n\u003ch3 id=\"1-引言\"\u003e1. 引言\u003c/h3\u003e\n\u003cp\u003eKWDB（KaiwuDB）作为一款面向AIoT（人工智能物联网）的分布式多模数据库，以其独特的多模融合设计、高效时序处理能力和灵活的分布式架构，满足了物联网场景下复杂数据管理的需求。要深入掌握KWDB，理解其三大核心概念——\u003cstrong\u003e多模融合\u003c/strong\u003e、\u003cstrong\u003e时序数据处理\u003c/strong\u003e和\u003cstrong\u003e分布式架构\u003c/strong\u003e——至关重要。本篇将逐一解析这些概念，揭示KWDB如何在技术上赋能AIoT应用。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （四） KWDB核心概念解析：多模、时序与分布式","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb4/","wordcount":2329},{"categories":"posts","content":"快速上手KWDB：从零到部署的5分钟指南 1. 引言 KWDB（KaiwuDB）是一款面向AIoT场景的分布式多模数据库，支持时序和关系数据的统一管理，具备高性能和易扩展的特点。无论你是想探索其多模融合能力，还是为物联网项目寻找高效数据库，本篇将带你从零开始，在5分钟内完成KWDB的单机部署、配置和基本操作，快速体验其强大功能。\n本指南假设你有基本的Linux操作知识，推荐环境为4核8G、SSD存储。无需复杂依赖，只需几个步骤即可运行KWDB！\n2. 准备工作 在开始之前，确保以下条件：\n操作系统：Ubuntu 20.04+、CentOS 7+ 或其他主流Linux发行版。 硬件要求：最低4核CPU，8GB内存，20GB SSD存储（推荐）。 网络：稳定的网络连接，用于下载安装包。 工具：终端工具（如bash），Python环境（可选，用于客户端测试）。 KWDB提供DEB和RPM安装包，官方推荐从Gitee仓库（https://gitee.com/kwdb/kwdb/releases）或官网（https://www.kaiwudb.com/）下载最新版本（截至2025年4月，最新为v2.1.0）。\nMermaid图表：准备流程 graph TD A[开始] --\u0026amp;gt; B[检查环境] B --\u0026amp;gt; C[OS: Ubuntu/CentOS] B --\u0026amp;gt; D[硬件: 4核8G] B --\u0026amp;gt; E[网络连接] C --\u0026amp;gt; F[下载安装包] D --\u0026amp;gt; F E --\u0026amp;gt; F F --\u0026amp;gt; G[准备完成] 3. 部署KWDB 以下是单机部署KWDB的详细步骤，预计耗时3分钟。\n步骤1：下载安装包 访问Gitee发布页面（https://gitee.com/kwdb/kwdb/releases），选择适合的安装包：\nUbuntu：kwdb_2.1.0_amd64.deb CentOS：kwdb_2.1.0_x86_64.rpm 示例命令（以Ubuntu为例）：\n1 wget https://gitee.com/kwdb/kwdb/releases/download/v2.1.0/kwdb_2.1.0_amd64.deb 步骤2：安装KWDB 执行安装命令：\n1 sudo dpkg -i kwdb_2.1.0_amd64.deb  …","date":1744568337,"description":"","fuzzywordcount":2100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"5b80d150ad4aff5e773cad2ffae45c91","publishdate":1744568337,"relpermalink":"/posts/database/langchao/kwdb/kwdb3/","section":"posts","summary":"\u003ch2 id=\"快速上手kwdb从零到部署的5分钟指南\"\u003e快速上手KWDB：从零到部署的5分钟指南\u003c/h2\u003e\n\u003ch3 id=\"1-引言\"\u003e1. 引言\u003c/h3\u003e\n\u003cp\u003eKWDB（KaiwuDB）是一款面向AIoT场景的分布式多模数据库，支持时序和关系数据的统一管理，具备高性能和易扩展的特点。无论你是想探索其多模融合能力，还是为物联网项目寻找高效数据库，本篇将带你从零开始，在5分钟内完成KWDB的单机部署、配置和基本操作，快速体验其强大功能。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （三） 快速上手KWDB：从零到部署的5分钟指南","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb3/","wordcount":2089},{"categories":"posts","content":"KWDB vs 传统数据库：多模数据库的独特优势 1. 引言 在AIoT（人工智能物联网）场景中，数据呈现多样性（时序、关系、半结构化）、高并发和高吞吐的特点，传统数据库往往难以满足需求。KWDB（KaiwuDB）作为一款分布式多模数据库，结合了时序数据库和关系数据库的优势，专为AIoT设计。本文将对比KWDB与传统数据库（如MySQL、InfluxDB、PostgreSQL），分析其在性能、功能和适用场景上的差异，揭示KWDB的独特价值。\n2. 传统数据库的局限性 传统数据库通常针对特定场景优化，但在AIoT环境中会遇到挑战。以下是几种典型数据库的特性与局限：\nMySQL（关系型数据库）\n特性：支持结构化数据，SQL标准，事务一致性强，广泛用于Web应用。 局限： 时序数据处理效率低，高频写入（如传感器数据）易成为瓶颈。 分布式扩展复杂，需依赖分库分表，运维成本高。 不支持多模融合，需额外集成时序数据库。 InfluxDB（时序数据库）\n特性：专为时间序列数据设计，适合高频写入和聚合查询，内置压缩。 局限： 仅支持时序数据，缺乏对关系数据或复杂事务的支持。 分布式版本功能受限，社区版性能较弱。 不适合需要跨模分析的场景。 PostgreSQL（关系型+扩展）\n特性：支持扩展（如TimescaleDB插件），可处理时序和关系数据，功能丰富。 局限： 扩展模块增加复杂性，性能优化依赖专业调优。 高并发场景下写入性能不如专用时序数据库。 分布式能力较弱，需第三方工具支持。 这些数据库在单一场景下表现出色，但在AIoT场景中，面对多模数据、高并发和动态扩展的需求，往往需要组合多种数据库，增加了架构复杂性和运维成本。\nMermaid图表：传统数据库局限性 graph TD A[AIoT场景需求] --\u0026amp;gt; B[多模数据] A --\u0026amp;gt; C[高并发] A --\u0026amp;gt; D[动态扩展] B --\u0026amp;gt; E[MySQL: 仅关系数据] B --\u0026amp;gt; F[InfluxDB: 仅时序数据] B --\u0026amp;gt; G[PostgreSQL: 扩展复杂] C --\u0026amp;gt; H[MySQL: 写入瓶颈] C --\u0026amp;gt; I[InfluxDB: 社区版受限] C --\u0026amp;gt; J[PostgreSQL: 调优复杂] D --\u0026amp;gt; K[MySQL: 分库分表] D --\u0026amp;gt; …","date":1744564737,"description":"","fuzzywordcount":2900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"fa94025a62558329b545321cb13c3283","publishdate":1744564737,"relpermalink":"/posts/database/langchao/kwdb/kwdb2/","section":"posts","summary":"\u003ch2 id=\"kwdb-vs-传统数据库多模数据库的独特优势\"\u003eKWDB vs 传统数据库：多模数据库的独特优势\u003c/h2\u003e\n\u003ch3 id=\"1-引言\"\u003e1. 引言\u003c/h3\u003e\n\u003cp\u003e在AIoT（人工智能物联网）场景中，数据呈现多样性（时序、关系、半结构化）、高并发和高吞吐的特点，传统数据库往往难以满足需求。KWDB（KaiwuDB）作为一款分布式多模数据库，结合了时序数据库和关系数据库的优势，专为AIoT设计。本文将对比KWDB与传统数据库（如MySQL、InfluxDB、PostgreSQL），分析其在性能、功能和适用场景上的差异，揭示KWDB的独特价值。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （二） KWDB vs 传统数据库：多模数据库的独特优势","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb2/","wordcount":2860},{"categories":"posts","content":"KWDB（KaiwuDB）系列专题目录 基础篇：认识KWDB KWDB简介：面向AIoT的分布式多模数据库 介绍KWDB的背景、核心功能和多模融合设计理念。 KWDB vs 传统数据库：多模数据库的独特优势 对比KWDB与MySQL、InfluxDB等数据库在AIoT场景中的差异。 快速上手KWDB：从零到部署的5分钟指南 单点部署步骤，适合初学者快速体验。 KWDB核心概念解析：多模、时序与分布式 深入讲解KWDB的多模表、时序处理和分布式架构基础。 KWDB支持的开发语言和协议 介绍C++、Python、Java等客户端驱动及HTTP、gRPC协议。 技术架构篇：深入KWDB内核 KWDB技术架构全景 详细剖析存储引擎、查询引擎和分布式管理模块。 多模存储引擎：时序与关系的融合之道 探讨时序表与关系表的存储优化机制。 查询引擎揭秘：跨模SQL的高性能实现 解析SQL解析器和查询优化器的工作原理。 分布式管理：Range分区与负载均衡 介绍KWDB的无中心设计和动态扩展能力。 WAL与CHECKPOINT：确保数据一致性的秘密 深入分析预写日志和检查点机制。 KWDB的压缩技术：平衡性能与存储 探讨时间序列数据的压缩算法和实现。 高可用设计：故障自愈与多副本策略 讲解KWDB的复制机制和故障恢复流程。 KWDB的索引优化：加速亿级数据查询 介绍时序索引和关系索引的优化技巧。 应用场景篇：KWDB的行业实践 工业物联网：KWDB如何赋能智能制造 分析KWDB在设备监控和数据分析中的应用。 数字能源：KWDB在电力系统的实时优化 探讨能耗管理和故障预测的案例。 车联网：KWDB支持亿级轨迹数据处理 分享临沂大数据局的车辆监管案例。 智慧城市：KWDB的多源数据融合实践 介绍KWDB在城市大脑中的应用。 金融物联网：KWDB在高并发场景中的表现 探讨KWDB在金融设备数据处理中的潜力。 边缘计算：KWDB在边缘节点的部署实践 分析KWDB在边缘AIoT场景中的优化。 开发与运维篇：实用指南 KWDB集群部署：从单点到分布式 提供多节点集群的配置和部署教程。 KWDB性能调优：百万级写入的优化技巧 分享内存、存储和网络的调优经验。 KWDB监控与运维：工具与最佳实践 介绍KWDB自带的监控接口和第三方工具集成。 KWDB备份与恢复：数据安全的保障 讲解全量备份和增量恢复的 …","date":1744561137,"description":"","fuzzywordcount":1300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"385f6a15a8234b94759082e1501b57a3","publishdate":1744561137,"relpermalink":"/posts/database/langchao/kwdb/kwdbtoc/","section":"posts","summary":"\u003ch2 id=\"kwdbkaiwudb系列专题目录\"\u003eKWDB（KaiwuDB）系列专题目录\u003c/h2\u003e\n\u003ch3 id=\"基础篇认识kwdb\"\u003e基础篇：认识KWDB\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eKWDB简介：面向AIoT的分布式多模数据库\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e介绍KWDB的背景、核心功能和多模融合设计理念。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKWDB vs 传统数据库：多模数据库的独特优势\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e对比KWDB与MySQL、InfluxDB等数据库在AIoT场景中的差异。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e快速上手KWDB：从零到部署的5分钟指南\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e单点部署步骤，适合初学者快速体验。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKWDB核心概念解析：多模、时序与分布式\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e深入讲解KWDB的多模表、时序处理和分布式架构基础。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKWDB支持的开发语言和协议\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e介绍C++、Python、Java等客户端驱动及HTTP、gRPC协议。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"技术架构篇深入kwdb内核\"\u003e技术架构篇：深入KWDB内核\u003c/h3\u003e\n\u003col start=\"6\"\u003e\n\u003cli\u003e\u003cstrong\u003eKWDB技术架构全景\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e详细剖析存储引擎、查询引擎和分布式管理模块。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e多模存储引擎：时序与关系的融合之道\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e探讨时序表与关系表的存储优化机制。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e查询引擎揭秘：跨模SQL的高性能实现\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e解析SQL解析器和查询优化器的工作原理。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e分布式管理：Range分区与负载均衡\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e介绍KWDB的无中心设计和动态扩展能力。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWAL与CHECKPOINT：确保数据一致性的秘密\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e深入分析预写日志和检查点机制。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKWDB的压缩技术：平衡性能与存储\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e探讨时间序列数据的压缩算法和实现。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e高可用设计：故障自愈与多副本策略\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e讲解KWDB的复制机制和故障恢复流程。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKWDB的索引优化：加速亿级数据查询\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e介绍时序索引和关系索引的优化技巧。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"应用场景篇kwdb的行业实践\"\u003e应用场景篇：KWDB的行业实践\u003c/h3\u003e\n\u003col start=\"14\"\u003e\n\u003cli\u003e\u003cstrong\u003e工业物联网：KWDB如何赋能智能制造\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e分析KWDB在设备监控和数据分析中的应用。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e数字能源：KWDB在电力系统的实时优化\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e探讨能耗管理和故障预测的案例。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e车联网：KWDB支持亿级轨迹数据处理\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e分享临沂大数据局的车辆监管案例。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e智慧城市：KWDB的多源数据融合实践\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e介绍KWDB在城市大脑中的应用。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e金融物联网：KWDB在高并发场景中的表现\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e探讨KWDB在金融设备数据处理中的潜力。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e边缘计算：KWDB在边缘节点的部署实践\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e分析KWDB在边缘AIoT场景中的优化。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"开发与运维篇实用指南\"\u003e开发与运维篇：实用指南\u003c/h3\u003e\n\u003col start=\"20\"\u003e\n\u003cli\u003e\u003cstrong\u003eKWDB集群部署：从单点到分布式\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e提供多节点集群的配置和部署教程。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eKWDB性能调优：百万级写入的优化技巧\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e分享内存、存储和网络的调优经验。 …\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ol\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdbtoc/","wordcount":1227},{"categories":"posts","content":"KWDB简介：面向AIoT的分布式多模数据库 1. 什么是KWDB？ KWDB（KaiwuDB）是由浪潮控股的上海沄熹科技有限公司开发的一款开源分布式多模数据库，专为AIoT（人工智能物联网）场景设计。它结合了时序数据库和关系数据库的优点，支持同一实例内创建和管理时序库与关系库，实现多模数据的统一存储和高效处理。\nKWDB于2024年8月在Gitee正式开源（https://gitee.com/kwdb/kwdb），由开放原子开源基金会孵化，目标是成为AIoT领域高性能、易扩展的数据库解决方案。无论是工业物联网的设备监控、数字能源的能耗优化，还是车联网的轨迹分析，KWDB都能提供强大的数据底座支持。\nMermaid图表：KWDB定位 graph TD A[KWDB] --\u0026amp;gt; B[AIoT场景] A --\u0026amp;gt; C[多模数据库] A --\u0026amp;gt; D[开源社区] B --\u0026amp;gt; B1[工业物联网] B --\u0026amp;gt; B2[数字能源] B --\u0026amp;gt; B3[车联网] C --\u0026amp;gt; C1[时序数据] C --\u0026amp;gt; C2[关系数据] C --\u0026amp;gt; C3[跨模查询] D --\u0026amp;gt; D1[Gitee源码] D --\u0026amp;gt; D2[开放原子] 2. 核心功能 KWDB以其独特的多模融合设计和高性能架构，满足了AIoT场景下的复杂数据需求。以下是其核心功能：\n多模融合\n支持时序表和关系表在同一实例内共存，数据模型统一管理。 提供跨模查询能力，通过SQL语句实现时序和关系数据的联合分析。 减少数据孤岛，提升开发效率。 高效时序处理\n支持千万级设备接入，百万级数据点每秒写入，亿级数据秒级查询。 针对高频时间序列数据优化，适合传感器、设备日志等场景。 内置压缩算法，降低存储成本。 分布式架构\n采用无中心全对等设计，支持自动分区分片和负载均衡。 动态扩展节点，适应高并发和大规模数据增长。 故障自愈机制，确保系统高可用。 稳定安全\n提供细粒度的权限管理，支持用户角色分配和访问控制。 数据加密和审计功能，满足关键行业的安全合规需求。 自主可控，适配国产化软硬件环境。 易用与生态\n支持多语言客户端（C++、Python、Java等）和协议（HTTP、gRPC）。 提供一站式部署工具，降低运维复杂性。 兼容大数据生态，与Spark、Flink等框架无缝集成。 …","date":1744561137,"description":"","fuzzywordcount":2300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"d3733494439b1d2faeb3ed2fbc1efb7c","publishdate":1744561137,"relpermalink":"/posts/database/langchao/kwdb/kwdb1/","section":"posts","summary":"\u003ch2 id=\"kwdb简介面向aiot的分布式多模数据库\"\u003eKWDB简介：面向AIoT的分布式多模数据库\u003c/h2\u003e\n\u003ch3 id=\"1-什么是kwdb\"\u003e1. 什么是KWDB？\u003c/h3\u003e\n\u003cp\u003eKWDB（KaiwuDB）是由浪潮控股的上海沄熹科技有限公司开发的一款开源分布式多模数据库，专为AIoT（人工智能物联网）场景设计。它结合了时序数据库和关系数据库的优点，支持同一实例内创建和管理时序库与关系库，实现多模数据的统一存储和高效处理。\u003c/p\u003e","tags":["数据库","浪潮","KWDB"],"title":"KWDB（KaiwuDB）系列专题 （一） KWDB简介：面向AIoT的分布式多模数据库","url":"https://yinlongfei.com/posts/database/langchao/kwdb/kwdb1/","wordcount":2244},{"categories":"posts","content":"任务生命周期管理：从创建到完成 摘要：任务（Task）是 A2A（Agent2Agent）协议的核心工作单元，其生命周期管理确保了代理间协作的可靠性和一致性。本文深入剖析 A2A 的任务生命周期，聚焦状态机设计、状态转换逻辑、错误处理和实时更新机制。结合 GitHub 仓库的实现、Mermaid 图表和代码示例，我们将揭示 A2A 如何通过硬核的任务管理支持多代理系统的动态协作，为开发者提供深入的技术洞察。\n1. 引言：任务管理的核心地位 在企业 AI 系统中，代理（Agent）通过任务（Task）协作完成复杂工作，例如处理费用报销、生成报表或协调物流。任务不仅承载了输入数据和输出结果，还需要在分布式环境中保持状态一致性和可靠性。Google 的 A2A（Agent2Agent） 协议通过任务生命周期管理，定义了任务从创建到完成（或失败）的完整流程，类似工作流系统（Workflow System）的状态机，但更轻量且针对代理间通信优化。\nA2A 的任务生命周期以 JSON Schema 为基础，结合 HTTP 和 WebSocket 通信，确保动态性和实时性。本文将深入解析这一机制，结合 Google A2A GitHub 仓库 的实现，揭示其硬核内核。\n2. 任务生命周期概览 A2A 的任务生命周期是一个状态机，定义了任务的合法状态和转换路径。核心状态包括：\nCreated：任务被 Host Agent 创建，等待分派。 In Progress：任务被 Remote Agent 接受并开始处理。 Completed：任务成功完成，返回结果。 Failed：任务失败，返回错误信息。 Canceled：任务被主动取消（可选状态）。 以下是任务生命周期的流程图：\nflowchart TD A[Created] --\u0026amp;gt; B[In Progress] B --\u0026amp;gt; C{Outcome} C --\u0026amp;gt; D[Completed] C --\u0026amp;gt; E[Failed] C --\u0026amp;gt; F[Canceled] D --\u0026amp;gt; G[Result Returned] E --\u0026amp;gt; H[Error Reported] F --\u0026amp;gt; I[Task Aborted] 2.1 任务结构 任务以 JSON 格式定义，基于 a2a.json 的 Schema，包含以下字 …","date":1744219497,"description":"","fuzzywordcount":3300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"1373830d4f44899682dbea48d85b7eb2","publishdate":1744219497,"relpermalink":"/posts/google/a2a/a2a8/","section":"posts","summary":"\u003ch1 id=\"任务生命周期管理从创建到完成\"\u003e任务生命周期管理：从创建到完成\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：任务（Task）是 A2A（Agent2Agent）协议的核心工作单元，其生命周期管理确保了代理间协作的可靠性和一致性。本文深入剖析 A2A 的任务生命周期，聚焦状态机设计、状态转换逻辑、错误处理和实时更新机制。结合 GitHub 仓库的实现、Mermaid 图表和代码示例，我们将揭示 A2A 如何通过硬核的任务管理支持多代理系统的动态协作，为开发者提供深入的技术洞察。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (八) 任务生命周期管理：从创建到完成","url":"https://yinlongfei.com/posts/google/a2a/a2a8/","wordcount":3212},{"categories":"posts","content":"代理发现与协商：A2A 如何实现动态交互 摘要：A2A（Agent2Agent）协议通过代理发现与协商机制，实现了 AI 代理在运行时的动态协作，无需硬编码配置即可识别彼此并协商交互方式。本文深入剖析 A2A 的发现与协商流程，聚焦 AgentCard 的交换、能力解析和交互模式的动态调整。结合 GitHub 仓库的实现、Mermaid 图表和代码示例，我们将揭示 A2A 如何通过硬核设计支持多代理系统的灵活性，为开发者提供深入的技术洞察。\n1. 引言：动态交互的必要性 在企业 AI 系统中，代理（Agent）需要像团队成员一样协作，处理从费用报销到客服交互的多样化任务。然而，传统的静态接口（例如 REST API）无法满足代理的动态需求：代理可能在运行时加入或更改功能，用户交互可能从文本切换到表单甚至音视频。Google 的 A2A（Agent2Agent） 协议通过 代理发现 和 交互协商 解决了这一问题，让代理能够自适应地识别彼此并优化通信。\nA2A 的发现与协商机制以 AgentCard 为核心，结合任务管理和通信协议（HTTP/WebSocket），实现了运行时的灵活性。本文将深入解析这一机制，结合 Google A2A GitHub 仓库 的实现，揭示其硬核内核。\n2. 代理发现：从未知到可信 2.1 发现的定义 代理发现是指 Host Agent 在运行时识别 Remote Agent 的过程，了解其身份、能力和服务端点。A2A 通过 AgentCard 的交换实现这一目标，类似服务注册中心（如 ZooKeeper）或 DNS，但更轻量且专注于 AI 代理。\n发现的流程包括：\n请求 AgentCard：Host Agent 向 Remote Agent 的 URL 发送 GET 请求。 解析 AgentCard：获取 Remote Agent 的元数据（名称、能力、任务 schema 等）。 验证能力：检查 Remote Agent 是否支持所需的功能（例如特定的交互模式或任务类型）。 以下是发现过程的时序图：\nsequenceDiagram participant H as Host Agent participant R as Remote Agent H-\u0026amp;gt;\u0026amp;gt;R: GET /agentcard R--\u0026amp;gt;\u0026amp;gt;H: Return …","date":1744219437,"description":"","fuzzywordcount":3200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"cea684b118780498562bd1d634f8c20e","publishdate":1744219437,"relpermalink":"/posts/google/a2a/a2a7/","section":"posts","summary":"\u003ch1 id=\"代理发现与协商a2a-如何实现动态交互\"\u003e代理发现与协商：A2A 如何实现动态交互\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：A2A（Agent2Agent）协议通过代理发现与协商机制，实现了 AI 代理在运行时的动态协作，无需硬编码配置即可识别彼此并协商交互方式。本文深入剖析 A2A 的发现与协商流程，聚焦 AgentCard 的交换、能力解析和交互模式的动态调整。结合 GitHub 仓库的实现、Mermaid 图表和代码示例，我们将揭示 A2A 如何通过硬核设计支持多代理系统的灵活性，为开发者提供深入的技术洞察。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (七) 代理发现与协商：A2A 如何实现动态交互","url":"https://yinlongfei.com/posts/google/a2a/a2a7/","wordcount":3131},{"categories":"posts","content":"A2A 的 JSON Schema：协议的核心规范 摘要：JSON Schema 是 A2A（Agent2Agent）协议的基石，定义了代理间通信的数据结构和规则，确保互操作性和一致性。本文深入剖析 A2A 的 JSON Schema，聚焦 AgentCard、任务（Task）和认证（AgentAuthentication）等核心组件的设计与实现。结合 GitHub 仓库的代码、Mermaid 图表和协议细节，我们将揭示 A2A 如何通过标准化 Schema 支持动态协作，为开发者提供硬核的技术洞察。\n1. 引言：JSON Schema 的力量 在分布式 AI 系统中，代理（Agent）需要以一致的方式交换信息，无论是描述自身能力、提交任务还是协商交互模式。Google 的 A2A（Agent2Agent） 协议通过 JSON Schema 提供了标准化的数据定义，类似 Web 的 OpenAPI 或 GraphQL Schema，确保不同代理能够无缝理解彼此。\nA2A 的 JSON Schema（a2a.json）是协议的核心，涵盖了代理元数据（AgentCard）、任务结构（Task）、认证机制（AgentAuthentication）等关键部分。它的设计不仅保证了数据一致性，还支持动态性和扩展性。本文将深入解析 A2A 的 JSON Schema，结合 Google A2A GitHub 仓库 的实现，揭示其硬核内核。\n2. JSON Schema 在 A2A 中的作用 JSON Schema 是一种用于定义 JSON 数据结构的规范（参考 json-schema.org），广泛应用于 API 设计和数据验证。A2A 利用 JSON Schema 实现以下目标：\n标准化：确保所有代理使用一致的数据格式，例如 AgentCard 和 Task 的字段定义。 验证：客户端和服务器可以验证数据的合法性，减少错误。 动态发现：通过 Schema 描述代理能力和任务要求，支持运行时协商。 扩展性：允许社区添加新功能（例如新的交互模式）而无需破坏兼容性。 A2A 的 JSON Schema 文件（a2a.json）托管于 GitHub，定义了协议的完整规范。以下是 Schema 的核心组件示意图：\nclassDiagram class A2A_Schema { …","date":1744219377,"description":"","fuzzywordcount":3100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"3ff66df3d0b252f9c3777936a16cffab","publishdate":1744219377,"relpermalink":"/posts/google/a2a/a2a6/","section":"posts","summary":"\u003ch1 id=\"a2a-的-json-schema协议的核心规范\"\u003eA2A 的 JSON Schema：协议的核心规范\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：JSON Schema 是 A2A（Agent2Agent）协议的基石，定义了代理间通信的数据结构和规则，确保互操作性和一致性。本文深入剖析 A2A 的 JSON Schema，聚焦 AgentCard、任务（Task）和认证（AgentAuthentication）等核心组件的设计与实现。结合 GitHub 仓库的代码、Mermaid 图表和协议细节，我们将揭示 A2A 如何通过标准化 Schema 支持动态协作，为开发者提供硬核的技术洞察。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (六) A2A 的 JSON Schema：协议的核心规范","url":"https://yinlongfei.com/posts/google/a2a/a2a6/","wordcount":3094},{"categories":"posts","content":"A2A 协议架构：客户端-服务器模型解析 摘要：A2A（Agent2Agent）协议通过客户端-服务器模型实现了 AI 代理间的动态协作，为企业场景提供了标准化通信框架。本文深入剖析 A2A 的架构设计，聚焦客户端与服务器的交互、AgentCard 的作用、通信协议（HTTP 和 WebSocket）以及任务管理机制。结合 GitHub 仓库的实现、Mermaid 图表和代码示例，我们将揭示 A2A 如何在技术细节上支持多代理系统的互操作性，为开发者提供硬核的技术洞察。\n1. 引言：架构驱动的代理协作 在企业 AI 系统中，代理（Agent）需要像微服务一样高效协作，处理从费用报销到供应链优化的复杂任务。Google 的 A2A（Agent2Agent） 协议通过客户端-服务器模型，为代理间通信提供了标准化框架。这种架构不仅支持动态发现和多模态交互，还确保了系统的可扩展性和可靠性。\nA2A 的客户端-服务器模型借鉴了分布式系统的设计理念，但针对 AI 代理的动态性进行了优化。核心组件包括客户端（Host Agent）、服务器（Remote Agent）、AgentCard（元数据描述）和任务（Task）管理。本文将深入解析这一架构，结合 Google A2A GitHub 仓库 的实现，揭示其硬核内核。\n2. A2A 架构概览 A2A 的架构基于 客户端-服务器模型，但与传统 REST API 不同，它强调代理间的对等协作和动态协商。以下是核心组件的示意图：\ngraph TD A[Client: Host Agent] --\u0026amp;gt;|HTTP/WebSocket| B[Server: Remote Agent] A --\u0026amp;gt;|请求 AgentCard| B B --\u0026amp;gt;|返回 AgentCard| A A --\u0026amp;gt;|提交 Task| B B --\u0026amp;gt;|返回 Task Result| A B --\u0026amp;gt; C[AgentCard] B --\u0026amp;gt; D[Task Lifecycle] C --\u0026amp;gt; E[Capabilities] D --\u0026amp;gt; F[Status Updates] 2.1 核心组件 客户端（Host Agent）：任务的发起者和协调者，负责发现 Remote Agent、协商交互模式并分派任务。 服务器（Remote …","date":1744219317,"description":"","fuzzywordcount":3300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"d5d4dba77cc17ad73f0615ec7579d0db","publishdate":1744219317,"relpermalink":"/posts/google/a2a/a2a5/","section":"posts","summary":"\u003ch1 id=\"a2a-协议架构客户端-服务器模型解析\"\u003eA2A 协议架构：客户端-服务器模型解析\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：A2A（Agent2Agent）协议通过客户端-服务器模型实现了 AI 代理间的动态协作，为企业场景提供了标准化通信框架。本文深入剖析 A2A 的架构设计，聚焦客户端与服务器的交互、AgentCard 的作用、通信协议（HTTP 和 WebSocket）以及任务管理机制。结合 GitHub 仓库的实现、Mermaid 图表和代码示例，我们将揭示 A2A 如何在技术细节上支持多代理系统的互操作性，为开发者提供硬核的技术洞察。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (五) A2A 协议架构：客户端-服务器模型解析","url":"https://yinlongfei.com/posts/google/a2a/a2a5/","wordcount":3258},{"categories":"posts","content":"A2A 与其他协议的初步比较：MCP 和更多 摘要：A2A（Agent2Agent）协议为企业 AI 代理的互操作性提供了标准化框架，但它并非唯一的解决方案。Anthropic 的 Model Context Protocol（MCP）等协议也在尝试解决 AI 系统间的协作问题。本文深入比较 A2A 与 MCP，分析它们的设计目标、技术架构和适用场景，同时简要提及其他协议（如 Language Server Protocol）。通过 GitHub 仓库的实现、MCP 文档的细节和 Mermaid 图表，我们将揭示 A2A 的独特优势与局限，为开发者提供硬核的技术洞察。\n1. 引言：AI 协作协议的竞争格局 随着 AI 代理在企业中的普及，协作与互操作性成为关键挑战。Google 的 A2A（Agent2Agent） 协议通过代理间通信（Agent-to-Agent Communication）打破孤岛，而 Anthropic 的 Model Context Protocol（MCP） 则专注于连接 AI 模型与外部数据源和工具。两者都旨在提升 AI 系统的协同能力，但目标和实现方式截然不同。\n此外，AI 领域还有其他协议，例如 Language Server Protocol（LSP）为开发工具提供了灵感。这些协议的出现反映了行业对标准化协作的迫切需求。本文将以 A2A 和 MCP 为重点，结合 Google A2A GitHub 仓库 和 MCP 官方文档，深入对比它们的架构、功能和生态影响。\n2. A2A 概述：代理间的协作标准 如前几篇所述，A2A 是 Google 主导的开源协议，专注于 代理间通信。其核心设计包括：\nAgentCard：代理的元数据，描述名称、能力（如文本、表单、音视频）和通信端点。 任务（Task）：代理间的工作单元，遵循状态生命周期（Created → In Progress → Completed/Failed）。 动态协商：代理通过 AgentCard 交换信息，运行时协商交互模式。 通信机制：支持 HTTP 和 WebSocket，兼顾简单任务和实时流。 A2A 的目标是让不同供应商、框架的代理（如费用报销、汇率转换代理）无缝协作，类似互联网的 HTTP 协议。以下是 A2A 的架构示意图：\ngraph TD A[User] …","date":1744219257,"description":"","fuzzywordcount":4200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"8691418da2cad67208cc030dff1ce18b","publishdate":1744219257,"relpermalink":"/posts/google/a2a/a2a4/","section":"posts","summary":"\u003ch1 id=\"a2a-与其他协议的初步比较mcp-和更多\"\u003eA2A 与其他协议的初步比较：MCP 和更多\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：A2A（Agent2Agent）协议为企业 AI 代理的互操作性提供了标准化框架，但它并非唯一的解决方案。Anthropic 的 Model Context Protocol（MCP）等协议也在尝试解决 AI 系统间的协作问题。本文深入比较 A2A 与 MCP，分析它们的设计目标、技术架构和适用场景，同时简要提及其他协议（如 Language Server Protocol）。通过 GitHub 仓库的实现、MCP 文档的细节和 Mermaid 图表，我们将揭示 A2A 的独特优势与局限，为开发者提供硬核的技术洞察。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (四) A2A 与其他协议的初步比较：MCP 和更多","url":"https://yinlongfei.com/posts/google/a2a/a2a4/","wordcount":4118},{"categories":"posts","content":"为什么需要 A2A？从孤岛到协作的 AI 生态 摘要：企业 AI 代理的快速发展带来了碎片化和孤岛问题，阻碍了系统间的协作。Google 的 A2A（Agent2Agent）协议通过标准化通信和动态协商，试图打破这些壁垒，构建一个协作的 AI 生态。本文深入剖析 AI 孤岛的根源、A2A 的解决方案及其技术优势，结合 GitHub 仓库的实现和 Mermaid 图表，揭示 A2A 如何为多代理系统铺平道路。无论是开发者还是企业决策者，这篇文章将为你展现 A2A 的硬核价值。\n1. 引言：AI 孤岛的困局 人工智能的浪潮席卷企业，从财务自动化到供应链优化，AI 代理（Agent）已成为不可或缺的工具。然而，繁荣背后隐藏着危机：\n碎片化生态：不同的 AI 框架（TensorFlow、PyTorch、Hugging Face）和供应商（Google Cloud、AWS、Microsoft Azure）各自为政，缺乏统一标准。 通信壁垒：代理间无法高效交互，企业需要为每对代理编写定制代码，成本高昂。 扩展难题：新增代理或功能时，系统需要重新设计接口，灵活性不足。 这些问题构成了“AI 孤岛”：每个代理像一座孤立的城堡，无法与其他系统无缝协作。Google 的 A2A（Agent2Agent） 协议应运而生，旨在通过开源和标准化，打造 AI 代理的“互联网”，实现从孤岛到协作的转型。\n本文将从技术与生态视角，深入分析为何需要 A2A，结合 Google A2A GitHub 仓库 的实现，揭示其设计背后的硬核逻辑。\n2. AI 孤岛的根源：技术与生态的挑战 2.1 技术碎片化 AI 生态的碎片化源于以下几个方面：\n框架多样性：TensorFlow 擅长深度学习，PyTorch 便于研究，Hugging Face 主攻 NLP，但它们的数据格式和 API 互不兼容。例如，一个用 PyTorch 构建的文本分析代理可能无法直接调用 TensorFlow 的图像处理代理。 供应商锁定：云供应商提供专有 AI 服务（例如 Google 的 Vertex AI、AWS 的 SageMaker），但跨平台集成需要大量适配工作。 协议缺失：AI 代理缺乏类似 HTTP 的通用通信协议，导致开发者需要为每对交互设计定制接口。 2.2 通信与协作痛点 在企业场景中，代理间的通信问题尤为突出：\n …","date":1744219197,"description":"","fuzzywordcount":3500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"a87405893fd1c4e786f473669ef82e40","publishdate":1744219197,"relpermalink":"/posts/google/a2a/a2a3/","section":"posts","summary":"\u003ch1 id=\"为什么需要-a2a从孤岛到协作的-ai-生态\"\u003e为什么需要 A2A？从孤岛到协作的 AI 生态\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：企业 AI 代理的快速发展带来了碎片化和孤岛问题，阻碍了系统间的协作。Google 的 A2A（Agent2Agent）协议通过标准化通信和动态协商，试图打破这些壁垒，构建一个协作的 AI 生态。本文深入剖析 AI 孤岛的根源、A2A 的解决方案及其技术优势，结合 GitHub 仓库的实现和 Mermaid 图表，揭示 A2A 如何为多代理系统铺平道路。无论是开发者还是企业决策者，这篇文章将为你展现 A2A 的硬核价值。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (三) 为什么需要 A2A？从孤岛到协作的 AI 生态","url":"https://yinlongfei.com/posts/google/a2a/a2a3/","wordcount":3448},{"categories":"posts","content":"A2A 的核心概念：代理、AgentCard 和任务 摘要：A2A（Agent2Agent）协议的核心在于代理（Agent）、AgentCard 和任务（Task）。这些概念定义了 AI 代理如何描述自身、发现彼此并协作完成工作。本文深入探讨这三大组件的设计理念、技术细节和实现方式，结合 GitHub 仓库的代码和 Mermaid 图表，揭示 A2A 如何通过标准化实现多代理系统的互操作性。无论你是开发者还是 AI 研究者，这篇文章将带你走进 A2A 的技术内核。\n1. 引言：从孤立到协作的基石 在企业 AI 场景中，代理（Agent）是执行任务的基本单元，例如处理费用报销、生成报表或协调物流。然而，代理的多样性和复杂性带来了挑战：如何让不同来源、不同功能的代理高效协作？Google 的 A2A 协议通过三个核心概念解决了这一问题：\n代理（Agent）：任务的执行者，分为 Host Agent 和 Remote Agent。 AgentCard：代理的“身份卡”，描述其能力和通信方式。 任务（Task）：代理间交换的工作单元，遵循明确的状态生命周期。 这三大概念构成了 A2A 的基础，类似互联网的 IP 地址、DNS 和数据包，定义了多代理系统的通信规则。本文将从技术视角深入剖析每个概念，结合 Google A2A GitHub 仓库 的实现，揭示其硬核设计。\n2. 代理（Agent）：A2A 的执行单元 2.1 代理的定义 在 A2A 中，代理是能够接收、处理和响应任务的独立实体。代理可以是简单的脚本（例如验证费用报销的 Python 程序），也可以是复杂的 AI 系统（例如结合大语言模型和数据库的客服代理）。A2A 将代理分为两类：\nHost Agent：任务的发起者和协调者，负责发现 Remote Agent 并分派任务。 Remote Agent：任务的执行者，通过 A2A 协议向 Host Agent 返回结果。 代理之间的关系是动态的，一个代理可以同时扮演 Host 和 Remote 角色，类似微服务架构中的服务调用。\n2.2 代理的职责 每个代理的核心职责包括：\n自我描述：通过 AgentCard 声明自己的功能和通信方式。 任务处理：接收任务，执行逻辑，返回结果或错误。 动态交互：与对端代理协商交互模式（例如文本、表单或音视频）。 以下是一个代理交互 …","date":1744219137,"description":"","fuzzywordcount":3400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"91574d335d97d55d21c4b00dc8326333","publishdate":1744219137,"relpermalink":"/posts/google/a2a/a2a2/","section":"posts","summary":"\u003ch1 id=\"a2a-的核心概念代理agentcard-和任务\"\u003eA2A 的核心概念：代理、AgentCard 和任务\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：A2A（Agent2Agent）协议的核心在于代理（Agent）、AgentCard 和任务（Task）。这些概念定义了 AI 代理如何描述自身、发现彼此并协作完成工作。本文深入探讨这三大组件的设计理念、技术细节和实现方式，结合 GitHub 仓库的代码和 Mermaid 图表，揭示 A2A 如何通过标准化实现多代理系统的互操作性。无论你是开发者还是 AI 研究者，这篇文章将带你走进 A2A 的技术内核。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (二) A2A 的核心概念：代理、AgentCard 和任务","url":"https://yinlongfei.com/posts/google/a2a/a2a2/","wordcount":3336},{"categories":"posts","content":"什么是 A2A？企业 AI 互操作性的新标准 摘要：A2A（Agent2Agent）是 Google 主导的开源协议，旨在解决企业 AI 代理之间的通信和互操作性难题。本文深入剖析 A2A 的背景、设计理念和技术架构，探讨其如何通过标准化协议打破 AI 系统孤岛，为多代理协作铺平道路。我们将结合 GitHub 仓库的实现细节和 Mermaid 图表，揭示 A2A 的硬核内核。\n1. 引言：AI 代理的孤岛困境 在企业 AI 的浪潮中，代理（Agent）已成为自动化和智能化的核心。从处理费用报销的简单脚本到协调供应链的复杂系统，AI 代理无处不在。然而，现实却充满挑战：\n框架碎片化：TensorFlow、PyTorch、Hugging Face 等框架各有千秋，但缺乏统一接口。 供应商壁垒：Google Cloud、AWS、Azure 的 AI 服务各自为政，难以跨平台协作。 通信障碍：代理间缺乏标准协议，导致开发者和企业需要为每对交互编写定制代码。 这些问题催生了“AI 孤岛”：每个代理像一座孤立的堡垒，无法高效协同。Google 的 A2A（Agent2Agent） 协议应运而生，试图通过开源和标准化，打造 AI 代理的“互联网”。\nA2A 是一个轻量级协议，定义了代理间通信的规则，允许不同系统、框架和供应商的代理无缝交互。根据 Google A2A GitHub 仓库，A2A 已在企业场景中获得初步验证（例如 Articul8 和 Arize AI 的支持）。本文将从技术视角深入剖析 A2A，揭示其设计理念和实现细节。\n2. A2A 的核心理念：代理即服务 A2A 的核心思想是将 AI 代理抽象为“服务”，类似于微服务架构中的模块化组件。每个代理通过 AgentCard（代理卡片）声明自己的身份和能力，代理间通过标准化的任务接口（Task Interface）交换工作。以下是 A2A 的三大支柱：\nAgentCard：代理的“名片”，包含名称、描述、URL、支持的交互模式（文本、表单、音视频）等。 任务生命周期：任务从创建到完成的状态机，代理通过 HTTP 或 WebSocket 交换状态更新。 动态协商：代理在交互前协商通信方式（例如文本优先还是流式音视频），确保灵活性。 为了直观理解 A2A 的工作方式，以下是一个简单的架构图：\ngraph TD …","date":1744215537,"description":"","fuzzywordcount":3e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c8428c51c3ce2f7e36ab8e895932f94a","publishdate":1744215537,"relpermalink":"/posts/google/a2a/a2a1/","section":"posts","summary":"\u003ch1 id=\"什么是-a2a企业-ai-互操作性的新标准\"\u003e什么是 A2A？企业 AI 互操作性的新标准\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e摘要\u003c/strong\u003e：A2A（Agent2Agent）是 Google 主导的开源协议，旨在解决企业 AI 代理之间的通信和互操作性难题。本文深入剖析 A2A 的背景、设计理念和技术架构，探讨其如何通过标准化协议打破 AI 系统孤岛，为多代理协作铺平道路。我们将结合 GitHub 仓库的实现细节和 Mermaid 图表，揭示 A2A 的硬核内核。\u003c/p\u003e","tags":["测试","大模型","A2A"],"title":"A2A（Agent2Agent）系列专题 (一) 什么是 A2A？企业 AI 互操作性的新标准","url":"https://yinlongfei.com/posts/google/a2a/a2a1/","wordcount":2909},{"categories":"posts","content":"Testcontainers 系列专题 - 第 7 篇：扩展与生态 - Testcontainers 的未来 引言 在之前的六篇文章中，我们从 Testcontainers 的基础用法到最佳实践，逐步掌握了其在测试中的核心能力。然而，Testcontainers 的价值不仅限于 Java 或单个场景，它的生态系统正在不断扩展，支持更多语言和工具，同时引入创新解决方案如 Testcontainers Cloud。本篇将带你走进 Testcontainers 的扩展世界，并展望容器化测试的未来。\nTestcontainers 的多语言支持 虽然 Testcontainers 起源于 Java，但它已扩展到多种编程语言，为不同技术栈的开发者提供支持。\n1. Python 库：testcontainers-python。 安装： 1 pip install testcontainers 示例：启动 MySQL 容器： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from testcontainers.mysql import MySqlContainer import mysql.connector with MySqlContainer(\u0026amp;#39;mysql:8.0\u0026amp;#39;) as mysql: connection = mysql.connector.connect( host=mysql.get_container_host_ip(), port=mysql.get_exposed_port(3306), user=\u0026amp;#39;root\u0026amp;#39;, password=mysql.get_env(\u0026amp;#39;MYSQL_ROOT_PASSWORD\u0026amp;#39;), database=\u0026amp;#39;mysql\u0026amp;#39; ) cursor = connection.cursor() cursor.execute(\u0026amp;#34;CREATE TABLE test (id INT)\u0026amp;#34;) connection.close() 特点：与 Python 的上下文管理器（with 语句）集成，自动清理容器。 2. Node.js 库：testcontainers。 安装： 1 npm install @testcontainers/core …","date":1720191685,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"ada131de97b42fec5e531f73e47a62d7","publishdate":1720191685,"relpermalink":"/posts/test/testcontainer/testcontainer7/","section":"posts","summary":"\u003ch2 id=\"testcontainers-系列专题---第-7-篇扩展与生态---testcontainers-的未来\"\u003eTestcontainers 系列专题 - 第 7 篇：扩展与生态 - Testcontainers 的未来\u003c/h2\u003e\n\u003ch3 id=\"引言\"\u003e引言\u003c/h3\u003e\n\u003cp\u003e在之前的六篇文章中，我们从 Testcontainers 的基础用法到最佳实践，逐步掌握了其在测试中的核心能力。然而，Testcontainers 的价值不仅限于 Java 或单个场景，它的生态系统正在不断扩展，支持更多语言和工具，同时引入创新解决方案如 Testcontainers Cloud。本篇将带你走进 Testcontainers 的扩展世界，并展望容器化测试的未来。\u003c/p\u003e","tags":["测试","Testcontainers"],"title":"Testcontainers 系列专题：第 7 篇 扩展与生态 - Testcontainers 的未来","url":"https://yinlongfei.com/posts/test/testcontainer/testcontainer7/","wordcount":1737},{"categories":"posts","content":"Testcontainers 系列专题 - 第 6 篇：最佳实践与注意事项 引言 在前五篇中，我们从 Testcontainers 的入门用法逐步深入到复杂系统的实战案例，展示了其在测试中的强大功能。然而，要在实际项目中高效使用 Testcontainers，还需要遵循一些最佳实践，并了解可能遇到的陷阱。本篇将为你提供实用建议，确保测试代码既高效又可靠。\n最佳实践 1. 保持测试隔离性 每个测试都应独立运行，避免容器状态相互干扰。\n实践：使用 @Container 注解为每个测试类或方法创建独立的容器实例。 示例： 1 2 3 4 5 6 7 8 9 10 11 12 @Testcontainers public class IsolatedTests { @Container private MySQLContainer\u0026amp;lt;?\u0026amp;gt; mysql = new MySQLContainer\u0026amp;lt;\u0026amp;gt;(\u0026amp;#34;mysql:8.0\u0026amp;#34;); @Test public void test1() { /* 测试逻辑 */ } @Test public void test2() { /* 测试逻辑 */ } } 好处：避免测试间数据污染，确保结果可重复。 2. 优化容器启动时间 容器启动是 Testcontainers 的主要开销，以下方法可提高效率：\n使用轻量镜像：选择 slim 或 alpine 版本（如 postgres:15-alpine）。 重用容器（本地开发）：在 .testcontainers.properties 中启用 testcontainers.reuse.enable=true，并设置 withReuse(true)。 预加载数据：将初始化脚本（如 SQL 文件）通过 withCopyFileToContainer 注入容器，避免运行时执行。 1 2 3 4 mysql.withCopyFileToContainer( MountableFile.forClasspathResource(\u0026amp;#34;init.sql\u0026amp;#34;), \u0026amp;#34;/docker-entrypoint-initdb.d/init.sql\u0026amp;#34; ); 3. 并行化测试 利用 Testcontainers 的隔离性，支持并行运行测试：\nMaven 配置： 1 2 …","date":1720105285,"description":"","fuzzywordcount":1600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"d271bb79d952dc75c57cdc26468e5f66","publishdate":1720105285,"relpermalink":"/posts/test/testcontainer/testcontainer6/","section":"posts","summary":"\u003ch2 id=\"testcontainers-系列专题---第-6-篇最佳实践与注意事项\"\u003eTestcontainers 系列专题 - 第 6 篇：最佳实践与注意事项\u003c/h2\u003e\n\u003ch3 id=\"引言\"\u003e引言\u003c/h3\u003e\n\u003cp\u003e在前五篇中，我们从 Testcontainers 的入门用法逐步深入到复杂系统的实战案例，展示了其在测试中的强大功能。然而，要在实际项目中高效使用 Testcontainers，还需要遵循一些最佳实践，并了解可能遇到的陷阱。本篇将为你提供实用建议，确保测试代码既高效又可靠。\u003c/p\u003e","tags":["测试","Testcontainers"],"title":"Testcontainers 系列专题：第 6 篇 最佳实践与注意事项","url":"https://yinlongfei.com/posts/test/testcontainer/testcontainer6/","wordcount":1537},{"categories":"posts","content":"Testcontainers 系列专题 - 第 5 篇：实战案例 - 测试复杂系统 引言 在前四篇中，我们从 Testcontainers 的基础用法逐步过渡到 CI/CD 集成，掌握了其核心功能和优化技巧。然而，在实际项目中，系统往往包含多个依赖（如消息队列、分布式存储），测试这些组件的交互是一个挑战。本篇将通过两个实战案例——测试 Kafka 消息队列和模拟 Elasticsearch 分布式系统——展示 Testcontainers 的强大能力，并分析它与 Mock 的使用场景。\n实战案例 1：测试消息队列（Kafka） 场景描述 假设你正在开发一个订单处理系统，订单通过 Kafka 消息队列传递给下游服务。你需要测试生产者和消费者的正确性。\n实现步骤 添加依赖：\n1 2 3 4 5 6 7 8 9 10 11 \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.testcontainers\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;kafka\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.19.7\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;scope\u0026amp;gt;test\u0026amp;lt;/scope\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;org.apache.kafka\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;kafka-clients\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.6.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; 测试代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import org.apache.kafka.clients.consumer.ConsumerConfig; import …","date":1720018885,"description":"","fuzzywordcount":1600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"efe3cc4cf58aac027b502c921487787a","publishdate":1720018885,"relpermalink":"/posts/test/testcontainer/testcontainer5/","section":"posts","summary":"\u003ch2 id=\"testcontainers-系列专题---第-5-篇实战案例---测试复杂系统\"\u003eTestcontainers 系列专题 - 第 5 篇：实战案例 - 测试复杂系统\u003c/h2\u003e\n\u003ch3 id=\"引言\"\u003e引言\u003c/h3\u003e\n\u003cp\u003e在前四篇中，我们从 Testcontainers 的基础用法逐步过渡到 CI/CD 集成，掌握了其核心功能和优化技巧。然而，在实际项目中，系统往往包含多个依赖（如消息队列、分布式存储），测试这些组件的交互是一个挑战。本篇将通过两个实战案例——测试 Kafka 消息队列和模拟 Elasticsearch 分布式系统——展示 Testcontainers 的强大能力，并分析它与 Mock 的使用场景。\u003c/p\u003e","tags":["测试","Testcontainers"],"title":"Testcontainers 系列专题：第 5 篇 实战案例 - 测试复杂系统","url":"https://yinlongfei.com/posts/test/testcontainer/testcontainer5/","wordcount":1531},{"categories":"posts","content":"Testcontainers 系列专题 - 第 4 篇：Testcontainers 与 CI/CD 集成 引言 在前三篇中，我们从入门到进阶逐步掌握了 Testcontainers 的用法，包括基本操作、自定义容器和网络管理。然而，在现代软件开发中，测试不仅限于本地环境，还需要在 CI/CD 流水线中运行以确保代码质量。本篇将探讨如何将 Testcontainers 无缝集成到 CI/CD 流程中，结合具体示例和优化技巧，帮助你在自动化环境中充分发挥其价值。\n为什么需要 CI/CD 集成？ 在 CI/CD 环境中运行测试有以下优势：\n自动化验证：每次代码提交后自动运行测试，确保功能完整性。 一致性：所有开发者和构建服务器使用相同的测试环境。 快速反馈：尽早发现问题，减少修复成本。 Testcontainers 的容器化特性非常适合 CI/CD，因为它无需预装依赖，所有环境都通过 Docker 动态创建。然而，CI 环境与本地开发有一些差异（如资源限制、网络配置），需要特别注意。\n在 CI/CD 中运行 Testcontainers 示例：GitHub Actions 配置 GitHub Actions 是一个流行的 CI/CD 平台，以下是一个在 GitHub Actions 中运行 Testcontainers 测试的配置：\n创建 .github/workflows/test.yml 文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 name: CI with Testcontainers on: push: branches: [ main ] pull_request: branches: [ main ] jobs: test: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v4 - name: Set up JDK 17 uses: actions/setup-java@v4 with: java-version: \u0026amp;#39;17\u0026amp;#39; distribution: …","date":1719932485,"description":"","fuzzywordcount":1600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"935aaacce7412d46754f664461e6bea0","publishdate":1719932485,"relpermalink":"/posts/test/testcontainer/testcontainer4/","section":"posts","summary":"\u003ch2 id=\"testcontainers-系列专题---第-4-篇testcontainers-与-cicd-集成\"\u003eTestcontainers 系列专题 - 第 4 篇：Testcontainers 与 CI/CD 集成\u003c/h2\u003e\n\u003ch3 id=\"引言\"\u003e引言\u003c/h3\u003e\n\u003cp\u003e在前三篇中，我们从入门到进阶逐步掌握了 Testcontainers 的用法，包括基本操作、自定义容器和网络管理。然而，在现代软件开发中，测试不仅限于本地环境，还需要在 CI/CD 流水线中运行以确保代码质量。本篇将探讨如何将 Testcontainers 无缝集成到 CI/CD 流程中，结合具体示例和优化技巧，帮助你在自动化环境中充分发挥其价值。\u003c/p\u003e","tags":["测试","Testcontainers"],"title":"Testcontainers 系列专题：第 4 篇 Testcontainers 与 CI/CD 集成","url":"https://yinlongfei.com/posts/test/testcontainer/testcontainer4/","wordcount":1571},{"categories":"posts","content":"Testcontainers 系列专题 - 第 3 篇：进阶用法 - 自定义容器与网络 引言 在前两篇中，我们掌握了 Testcontainers 的基本用法和核心功能，能够轻松启动数据库容器并集成到测试框架中。然而，在真实项目中，我们可能需要使用自定义镜像，或者让多个容器协同工作来模拟复杂的系统。本篇将深入探讨这些进阶主题，帮助你解锁 Testcontainers 的更多潜力。\n自定义容器 Testcontainers 的内置容器（如 PostgreSQLContainer、MySQLContainer）已经覆盖了许多常见场景，但有时你需要运行特定的镜像或自定义配置。这时，可以使用 GenericContainer 或从 Dockerfile 构建容器。\n从远程镜像启动自定义容器 假设你需要测试一个运行在 Nginx 上的静态网站，可以直接使用 GenericContainer：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import org.junit.jupiter.api.Test; import org.testcontainers.containers.GenericContainer; import org.testcontainers.junit.jupiter.Container; import org.testcontainers.junit.jupiter.Testcontainers; import org.testcontainers.utility.MountableFile; import java.net.HttpURLConnection; import java.net.URL; import static org.junit.jupiter.api.Assertions.assertEquals; @Testcontainers public class CustomNginxTest { @Container public GenericContainer\u0026amp;lt;?\u0026amp;gt; nginx = new GenericContainer\u0026amp;lt;\u0026amp;gt;(\u0026amp;#34;nginx:latest\u0026amp;#34;) …","date":1719846085,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"e53c55544cc010e56c839390f2f21bcf","publishdate":1719846085,"relpermalink":"/posts/test/testcontainer/testcontainer3/","section":"posts","summary":"\u003ch2 id=\"testcontainers-系列专题---第-3-篇进阶用法---自定义容器与网络\"\u003eTestcontainers 系列专题 - 第 3 篇：进阶用法 - 自定义容器与网络\u003c/h2\u003e\n\u003ch3 id=\"引言\"\u003e引言\u003c/h3\u003e\n\u003cp\u003e在前两篇中，我们掌握了 Testcontainers 的基本用法和核心功能，能够轻松启动数据库容器并集成到测试框架中。然而，在真实项目中，我们可能需要使用自定义镜像，或者让多个容器协同工作来模拟复杂的系统。本篇将深入探讨这些进阶主题，帮助你解锁 Testcontainers 的更多潜力。\u003c/p\u003e","tags":["测试","Testcontainers"],"title":"Testcontainers 系列专题：第 3 篇 进阶用法","url":"https://yinlongfei.com/posts/test/testcontainer/testcontainer3/","wordcount":1672},{"categories":"posts","content":"Testcontainers 系列专题 - 第 2 篇：核心功能与基本用法 引言 在第 1 篇中，我们了解了 Testcontainers 的基本概念，并通过一个简单的 PostgreSQL 示例快速上手。本篇将进一步探索 Testcontainers 的核心功能，包括常用容器类、容器配置、生命周期管理，以及如何与主流测试框架集成。通过这些内容，你将能够更自信地使用 Testcontainers 来编写可靠的测试。\n核心功能概览 Testcontainers 提供了丰富的功能，让开发者可以轻松管理测试中的容器化依赖。以下是本篇将重点介绍的几个方面：\n常用容器类：开箱即用的专用容器支持。 容器配置：自定义端口、环境变量等。 生命周期管理：控制容器的启动、停止和重用。 测试框架集成：与 JUnit 和 Spring Boot 无缝协作。 常用容器类 Testcontainers 提供了多种预配置的容器类，针对常见服务进行了封装，简化使用过程。以下是几个典型例子：\nGenericContainer：通用容器类，可运行任何 Docker 镜像。 PostgreSQLContainer：专为 PostgreSQL 设计的容器，内置 JDBC 支持。 MySQLContainer：用于 MySQL 数据库的容器。 KafkaContainer：快速启动 Apache Kafka。 LocalStackContainer：模拟 AWS 服务（如 S3、SQS）。 示例：使用 MySQLContainer 以下是一个使用 MySQLContainer 的简单测试：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import org.junit.jupiter.api.Test; import org.testcontainers.containers.MySQLContainer; import org.testcontainers.junit.jupiter.Container; import org.testcontainers.junit.jupiter.Testcontainers; import java.sql.Connection; import …","date":1719759685,"description":"","fuzzywordcount":1500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"99f4d9bd24729894b448cc4fe8dc3e8e","publishdate":1719759685,"relpermalink":"/posts/test/testcontainer/testcontainer2/","section":"posts","summary":"\u003ch2 id=\"testcontainers-系列专题---第-2-篇核心功能与基本用法\"\u003eTestcontainers 系列专题 - 第 2 篇：核心功能与基本用法\u003c/h2\u003e\n\u003ch3 id=\"引言\"\u003e引言\u003c/h3\u003e\n\u003cp\u003e在第 1 篇中，我们了解了 Testcontainers 的基本概念，并通过一个简单的 PostgreSQL 示例快速上手。本篇将进一步探索 Testcontainers 的核心功能，包括常用容器类、容器配置、生命周期管理，以及如何与主流测试框架集成。通过这些内容，你将能够更自信地使用 Testcontainers 来编写可靠的测试。\u003c/p\u003e","tags":["测试","Testcontainers"],"title":"Testcontainers 系列专题：第 2 篇 核心功能与基本用法","url":"https://yinlongfei.com/posts/test/testcontainer/testcontainer2/","wordcount":1457},{"categories":"posts","content":"Testcontainers 系列专题 - 第 1 篇：Testcontainers 入门 - 什么是 Testcontainers？ 引言 在软件开发中，测试是确保代码质量的重要环节。然而，传统的测试方法常常面临一些挑战：依赖外部服务（如数据库、消息队列）的配置繁琐、测试环境不一致、难以模拟生产环境等。这时，Testcontainers 应运而生，它通过容器化技术为我们提供了一种优雅的解决方案。本篇将带你了解 Testcontainers 的基本概念，并通过一个简单的示例快速上手。\n什么是 Testcontainers？ Testcontainers 是一个开源库，旨在帮助开发者在测试中使用容器化技术来管理依赖。它最初是为 Java 设计的（支持 JUnit、TestNG 等测试框架），如今已扩展到 Python、Node.js、Go 等多种语言。简单来说，Testcontainers 可以在测试运行时动态启动 Docker 容器（如数据库、Web 服务器、消息队列），执行测试后自动清理，无需手动配置外部服务。\n核心特点 容器化依赖：通过 Docker 容器运行依赖服务，隔离性强。 动态管理：测试开始时启动容器，结束后自动销毁。 接近生产环境：使用与生产相同的镜像（如 PostgreSQL、MySQL），减少环境差异。 语言支持广泛：不仅限于 Java，还支持多种编程语言的生态。 解决的问题 传统测试中，开发者可能需要在本地安装数据库，或者依赖共享的测试环境，这会导致：\n配置复杂，耗时长。 测试结果因环境差异而不可靠。 难以并行运行多个测试。 Testcontainers 通过将依赖封装为容器，解决了这些痛点，让测试更简单、更可控。\n为什么需要 Testcontainers？ 假设你在开发一个需要连接 PostgreSQL 数据库的应用，传统的测试方法可能是：\n在本地安装 PostgreSQL。 创建测试数据库和表。 运行测试。 清理数据。 如果团队中有多人，或者测试需要在 CI/CD 环境中运行，这种方式会变得非常麻烦。而使用 Testcontainers，你只需几行代码就能启动一个 PostgreSQL 容器，执行测试后自动销毁，既省时又保证了一致性。\n优势总结 隔离性：每个测试都有独立的容器，避免干扰。 可重复性：容器基于镜像运行，行为一致。 接近生产：使用 …","date":1719673285,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"4edfe79f3dc1236f2278a9a84bb44e97","publishdate":1719673285,"relpermalink":"/posts/test/testcontainer/testcontainer1/","section":"posts","summary":"\u003ch2 id=\"testcontainers-系列专题---第-1-篇testcontainers-入门---什么是-testcontainers\"\u003eTestcontainers 系列专题 - 第 1 篇：Testcontainers 入门 - 什么是 Testcontainers？\u003c/h2\u003e\n\u003ch3 id=\"引言\"\u003e引言\u003c/h3\u003e\n\u003cp\u003e在软件开发中，测试是确保代码质量的重要环节。然而，传统的测试方法常常面临一些挑战：依赖外部服务（如数据库、消息队列）的配置繁琐、测试环境不一致、难以模拟生产环境等。这时，Testcontainers 应运而生，它通过容器化技术为我们提供了一种优雅的解决方案。本篇将带你了解 Testcontainers 的基本概念，并通过一个简单的示例快速上手。\u003c/p\u003e","tags":["测试","Testcontainers"],"title":"Testcontainers 系列专题：第 1 篇 Testcontainers 入门","url":"https://yinlongfei.com/posts/test/testcontainer/testcontainer1/","wordcount":1678},{"categories":"posts","content":"Testcontainers 系列专题：从入门到实战 专题目标 通过本系列，帮助读者理解 Testcontainers 的核心概念、使用方法及其在测试中的价值，逐步从基础知识过渡到高级应用和实战案例。\n目录与内容规划 第 1 篇：Testcontainers 入门 - 什么是 Testcontainers？ 内容要点： Testcontainers 的定义：一个用于在测试中动态管理容器化依赖的开源库。 为什么需要 Testcontainers？解决传统测试中依赖管理的问题（如数据库、消息队列等）。 支持的语言和生态：Java（JUnit 4/5、TestNG）、Python、Node.js 等。 核心优势：隔离性、可重复性、接近生产环境。 示例： 安装 Testcontainers（以 Java + Maven/Gradle 为例）。 编写第一个测试：启动一个 PostgreSQL 容器并运行简单查询。 目标：让读者快速上手并理解基本概念。 第 2 篇：核心功能与基本用法 内容要点： 常用容器类：GenericContainer、PostgreSQLContainer、MySQLContainer 等。 配置容器：端口映射、环境变量、启动命令。 生命周期管理：启动、停止、重用容器。 与测试框架集成：JUnit 4/5、Spring Boot 测试。 示例： 使用 MySQLContainer 测试 Spring Data JPA 应用。 配置容器日志输出，用于调试。 目标：掌握 Testcontainers 的基本操作和常见场景。 第 3 篇：进阶用法 - 自定义容器与网络 内容要点： 自定义镜像：从 Dockerfile 或远程镜像启动容器。 容器网络：多个容器协同工作（如数据库 + 应用服务）。 等待策略：确保容器就绪（内置策略与自定义策略）。 示例： 创建一个自定义 Nginx 容器并测试 HTTP 请求。 模拟微服务架构：一个 API 容器 + Redis 容器。 目标：学习如何处理复杂测试场景。 第 4 篇：Testcontainers 与 CI/CD 集成 内容要点： 在 CI 环境中运行 Testcontainers（GitHub Actions、Jenkins 等）。 优化性能：容器重用、Testcontainers Cloud。 常见问题与解决方 …","date":1719586885,"description":"","fuzzywordcount":1400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"e311ca50f7de943b5ebe80a002ed0821","publishdate":1719586885,"relpermalink":"/posts/test/testcontainer/testcontainertoc/","section":"posts","summary":"\u003ch3 id=\"testcontainers-系列专题从入门到实战\"\u003eTestcontainers 系列专题：从入门到实战\u003c/h3\u003e\n\u003ch4 id=\"专题目标\"\u003e专题目标\u003c/h4\u003e\n\u003cp\u003e通过本系列，帮助读者理解 Testcontainers 的核心概念、使用方法及其在测试中的价值，逐步从基础知识过渡到高级应用和实战案例。\u003c/p\u003e","tags":["测试","Testcontainers"],"title":"Testcontainers 系列专题：从入门到实战","url":"https://yinlongfei.com/posts/test/testcontainer/testcontainertoc/","wordcount":1342},{"categories":"posts","content":"Spring Batch 专题系列（九）：Spring Batch 生产实践 1. 引言 在上一篇文章中，我们学习了 Spring Batch 的扩展与定制（自定义组件、监听器、动态配置），掌握了如何根据业务需求灵活增强功能。随着批处理任务进入生产环境，开发者需要关注部署方式、管理策略、性能监控和故障处理。Spring Batch 提供了强大的生产支持，与 Spring Boot、容器化技术（如 Docker）和监控工具（如 Prometheus）无缝集成。\n本文将聚焦以下内容：\n部署和管理 Job：Spring Boot 集成、容器化部署。 监控和报警：使用 JMX、Prometheus 和 Grafana 跟踪性能。 生产问题与解决方案：处理失败、重启、性能瓶颈等。 通过代码示例和 Mermaid 图表展示生产实践的实现。 通过本文，你将学会如何在生产环境中高效运行 Spring Batch 作业，确保稳定性和可维护性。\n2. 生产实践的核心概念 生产环境的 Spring Batch 部署需要考虑以下关键点：\n部署：将 Job 集成到 Spring Boot 应用，或使用容器化（如 Docker）实现隔离和可扩展性。 管理：通过命令行、API 或 UI 触发和管理 Job，支持动态调度和参数传递。 监控：实时跟踪 Job 执行状态、性能指标和失败事件，结合报警机制及时响应。 问题处理：设计健壮的错误处理、重启策略和性能优化，应对生产中的复杂情况。 这些实践依赖 Spring Batch 的 JobRepository（存储元数据）、Spring Boot 的自动化配置和外部工具的集成。\n生产部署流程图 以下是用 Mermaid 绘制的 Spring Batch 生产部署流程图，展示从部署到监控的完整过程：\ngraph TD A[Development] --\u0026amp;gt; B[Build: Spring Boot JAR] B --\u0026amp;gt; C[Deploy: Docker Container] C --\u0026amp;gt; D[Run: JobLauncher] D --\u0026amp;gt; E[Job Execution] E --\u0026amp;gt; F[JobRepository] F --\u0026amp;gt;|存储元数据| G[Database] E --\u0026amp;gt; H[Monitoring: …","date":1717945285,"description":"","fuzzywordcount":3800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"ec39dcf8d49a94d0b6f134448a34b002","publishdate":1717945285,"relpermalink":"/posts/spring/spring-batch/springbatch9/","section":"posts","summary":"\u003ch1 id=\"spring-batch-专题系列九spring-batch-生产实践\"\u003eSpring Batch 专题系列（九）：Spring Batch 生产实践\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003e在上一篇文章中，我们学习了 Spring Batch 的扩展与定制（自定义组件、监听器、动态配置），掌握了如何根据业务需求灵活增强功能。随着批处理任务进入生产环境，开发者需要关注部署方式、管理策略、性能监控和故障处理。Spring Batch 提供了强大的生产支持，与 Spring Boot、容器化技术（如 Docker）和监控工具（如 Prometheus）无缝集成。\u003c/p\u003e","tags":["Spring","Spring Batch"],"title":"Spring Batch 专题系列（九）：Spring Batch 生产实践","url":"https://yinlongfei.com/posts/spring/spring-batch/springbatch9/","wordcount":3770},{"categories":"posts","content":"Spring Batch 专题系列（八）：Spring Batch 高级主题：扩展与定制 1. 引言 在上一篇文章中，我们学习了 Spring Batch 与数据库的集成（JDBC、JPA、MyBatis），掌握了如何高效读写数据、配置事务和优化性能。Spring Batch 的强大之处不仅在于其内置功能，还在于其高度可扩展性。通过自定义组件、监听器、拦截器和动态配置，你可以根据具体业务需求灵活定制批处理流程。\n本文将聚焦以下内容：\n自定义 ItemReader、ItemProcessor 和 ItemWriter，适配非标准数据源和目标。 使用监听器（Listener）和拦截器（ItemStream、StepExecutionListener 等）增强监控和控制。 动态配置 Job 和 Step，支持运行时调整流程。 通过代码示例和 Mermaid 图表展示扩展与定制的实现。 通过本文，你将学会如何将 Spring Batch 应用于复杂业务场景，打造高度定制化的批处理解决方案。\n2. 扩展与定制的核心概念 Spring Batch 的扩展性体现在其模块化设计，允许开发者通过以下方式定制功能：\n自定义组件：实现 ItemReader、ItemProcessor、ItemWriter 接口，处理特殊数据源（如 API、文件系统）或复杂逻辑。 监听器：通过 JobExecutionListener、StepExecutionListener、ChunkListener 等捕获生命周期事件，记录日志或干预执行。 拦截器：使用 ItemStream 或自定义拦截器在读/写/处理阶段插入逻辑。 动态配置：通过 JobParameters、Spring 表达式或代码动态生成 Job 和 Step，适应变化的需求。 这些机制依赖 Spring 的依赖注入和 AOP，支持无缝集成到现有项目。\n扩展流程图 以下是用 Mermaid 绘制的 Spring Batch 扩展流程图，展示自定义组件和监听器的协作：\ngraph TD A[Job] --\u0026amp;gt; B[Step] B --\u0026amp;gt; C[Custom ItemReader] B --\u0026amp;gt; D[Custom ItemProcessor] B --\u0026amp;gt; E[Custom ItemWriter] B --\u0026amp;gt; …","date":1717858885,"description":"","fuzzywordcount":4700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"a681e81cdbaf6393a9dc08223c42365b","publishdate":1717858885,"relpermalink":"/posts/spring/spring-batch/springbatch8/","section":"posts","summary":"\u003ch1 id=\"spring-batch-专题系列八spring-batch-高级主题扩展与定制\"\u003eSpring Batch 专题系列（八）：Spring Batch 高级主题：扩展与定制\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003e在上一篇文章中，我们学习了 Spring Batch 与数据库的集成（JDBC、JPA、MyBatis），掌握了如何高效读写数据、配置事务和优化性能。Spring Batch 的强大之处不仅在于其内置功能，还在于其高度可扩展性。通过自定义组件、监听器、拦截器和动态配置，你可以根据具体业务需求灵活定制批处理流程。\u003c/p\u003e","tags":["Spring","Spring Batch"],"title":"Spring Batch 专题系列（八）：Spring Batch 高级主题：扩展与定制","url":"https://yinlongfei.com/posts/spring/spring-batch/springbatch8/","wordcount":4663},{"categories":"posts","content":"Spring Batch 专题系列（七）：Spring Batch 与数据库集成 1. 引言 在上一篇文章中，我们学习了 Spring Batch 的并行处理机制（多线程 Step、分区、并行 Job）和性能优化技巧，掌握了如何处理海量数据。在批处理任务中，数据库操作是最常见的场景之一，例如从源表读取数据，经过转换后写入目标表（ETL）、批量更新记录或生成报表。Spring Batch 提供了强大的数据库集成支持，与主流 ORM 框架（如 JDBC、JPA、MyBatis）无缝协作。\n本文将聚焦以下内容：\n使用 JDBC 实现高效的数据库读写。 使用 JPA 处理复杂实体关系。 使用 MyBatis 提供灵活的 SQL 控制。 配置事务管理，确保数据一致性。 优化数据库性能的实践（如批量操作、分页读取）。 通过代码示例和 Mermaid 图表展示数据库集成流程。 通过本文，你将学会如何在 Spring Batch 中高效操作数据库，为生产环境中的 ETL、数据迁移等任务提供可靠支持。\n2. 数据库集成的核心概念 Spring Batch 的数据库集成主要涉及以下组件：\nItemReader：从数据库读取数据，如 JdbcCursorItemReader、JpaPagingItemReader、MyBatisCursorItemReader。 ItemWriter：将数据写入数据库，如 JdbcBatchItemWriter、JpaItemWriter、MyBatisBatchItemWriter。 事务管理：通过 Spring 的事务管理器（PlatformTransactionManager）确保 Chunk 级别的事务一致性。 JobRepository：存储 Job 和 Step 的元数据，通常使用数据库实现，支持重启和状态追踪。 数据库操作的性能关键在于：\n批量处理：减少 IO 开销，提高吞吐量。 分页或游标：避免一次性加载大数据集。 事务优化：合理配置 Chunk 大小和隔离级别。 数据库交互流程图 以下是用 Mermaid 绘制的 Spring Batch 数据库交互流程图，展示从源表读取到目标表写入的过程：\ngraph TD A[Job] --\u0026amp;gt; B[Step] B --\u0026amp;gt; C[ItemReader] B --\u0026amp;gt; …","date":1717772485,"description":"","fuzzywordcount":4800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"5a5380cce8fcf878c59790036acbdd7c","publishdate":1717772485,"relpermalink":"/posts/spring/spring-batch/springbatch7/","section":"posts","summary":"\u003ch1 id=\"spring-batch-专题系列七spring-batch-与数据库集成\"\u003eSpring Batch 专题系列（七）：Spring Batch 与数据库集成\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003e在上一篇文章中，我们学习了 Spring Batch 的并行处理机制（多线程 Step、分区、并行 Job）和性能优化技巧，掌握了如何处理海量数据。在批处理任务中，数据库操作是最常见的场景之一，例如从源表读取数据，经过转换后写入目标表（ETL）、批量更新记录或生成报表。Spring Batch 提供了强大的数据库集成支持，与主流 ORM 框架（如 JDBC、JPA、MyBatis）无缝协作。\u003c/p\u003e","tags":["Spring","Spring Batch"],"title":"Spring Batch 专题系列（七）：Spring Batch 与数据库集成","url":"https://yinlongfei.com/posts/spring/spring-batch/springbatch7/","wordcount":4731},{"categories":"posts","content":"Spring Batch 专题系列（六）：并行处理与性能优化 1. 引言 在上一篇文章中，我们学习了 Spring Batch 的错误处理机制（Skip、Retry、Restart 和 Listener），掌握了如何提升作业的健壮性。随着数据量的增加，批处理任务的性能成为关键挑战。Spring Batch 提供了强大的并行处理功能，包括多线程 Step、分区（Partitioning）和并行 Job，能够显著缩短运行时间。此外，性能优化还涉及 Chunk 大小、缓冲区配置等细节。\n本文将聚焦以下内容：\n多线程 Step：使用线程池并行执行 Step。 分区（Partitioning）：将大数据集分割为多个子集并行处理。 并行 Job：同时运行多个独立 Job。 性能优化技巧：调整 Chunk 大小、优化数据库交互等。 通过代码示例和 Mermaid 图表展示并行处理和优化的实现。 通过本文，你将学会如何利用 Spring Batch 的并行机制处理海量数据，并优化作业性能，为生产环境提供高效的批处理解决方案。\n2. 并行处理的核心概念 Spring Batch 的并行处理旨在通过并发执行任务来提高吞吐量，主要包括以下方式：\n多线程 Step：在单个 Step 内使用线程池并行处理 Chunk，适合 CPU 密集型或 IO 密集型任务。 分区（Partitioning）：将大数据集分割为多个子集，每个子集由独立的 Step 处理，可分布在多线程或多节点上。 并行 Job：同时运行多个独立 Job，适合无依赖关系的任务。 异步执行：通过异步 JobLauncher 并发启动 Job。 这些机制依赖 Spring Batch 的任务执行器（TaskExecutor）和分区管理器（PartitionHandler）。性能优化的关键在于合理配置线程数、Chunk 大小和数据源访问。\n并行处理流程图 以下是用 Mermaid 绘制的 Spring Batch 并行处理概览图，展示多线程 Step 和分区的关系：\ngraph TD A[Job] --\u0026amp;gt; B[Partitioned Step] A --\u0026amp;gt; C[Multi-Threaded Step] B --\u0026amp;gt; D[Partitioner] D --\u0026amp;gt; E[Slave Step 1] D --\u0026amp;gt; …","date":1717686085,"description":"","fuzzywordcount":5200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c9d9ff6f6c4daae5942ccba6e62f1ae5","publishdate":1717686085,"relpermalink":"/posts/spring/spring-batch/springbatch6/","section":"posts","summary":"\u003ch1 id=\"spring-batch-专题系列六并行处理与性能优化\"\u003eSpring Batch 专题系列（六）：并行处理与性能优化\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003e在上一篇文章中，我们学习了 Spring Batch 的错误处理机制（Skip、Retry、Restart 和 Listener），掌握了如何提升作业的健壮性。随着数据量的增加，批处理任务的性能成为关键挑战。Spring Batch 提供了强大的并行处理功能，包括多线程 Step、分区（Partitioning）和并行 Job，能够显著缩短运行时间。此外，性能优化还涉及 Chunk 大小、缓冲区配置等细节。\u003c/p\u003e","tags":["Spring","Spring Batch"],"title":"Spring Batch 专题系列（六）：并行处理与性能优化","url":"https://yinlongfei.com/posts/spring/spring-batch/springbatch6/","wordcount":5120},{"categories":"posts","content":"Spring Batch 专题系列（五）：错误处理与重试机制 1. 引言 在上一篇文章中，我们学习了 Spring Batch 的配置方式（Java 和 XML）以及调度机制（Spring Scheduler、Quartz、手动触发），掌握了如何定义和运行作业。在实际生产环境中，批处理任务难免会遇到异常，如数据格式错误、数据库连接失败或外部服务不可用。Spring Batch 提供了强大的错误处理机制，包括跳过（Skip）、重试（Retry）、重启（Restart）和监听器（Listener），确保作业在异常情况下依然可靠运行。\n本文将聚焦以下内容：\n跳过（Skip）：忽略无效记录，继续处理后续数据。 重试（Retry）：自动重试失败的操作，如网络超时。 重启（Restart）：恢复中断的作业，从上次失败点继续执行。 监听器（Listener）：捕获和记录错误信息，自定义错误处理逻辑。 通过代码示例和 Mermaid 图表展示错误处理流程。 通过本文，你将学会如何配置 Spring Batch 的错误处理机制，提升作业的健壮性和可维护性。\n2. 错误处理的核心概念 Spring Batch 的错误处理机制旨在平衡任务的可靠性与性能，主要包括以下功能：\nSkip：当某些记录导致异常时，跳过这些记录，继续处理后续数据。适合处理数据格式错误等非致命异常。 Retry：当操作失败时（如网络问题），自动重试指定次数。适合处理临时性错误。 Restart：允许从上次失败的点恢复作业，依赖 JobRepository 存储的状态。 Listener：通过监听器捕获 Job 或 Step 的生命周期事件，记录错误或执行自定义逻辑。 这些机制可以通过配置或编程方式实现，Spring Batch 提供了灵活的 API 支持。\n错误处理流程图 以下是用 Mermaid 绘制的 Spring Batch 错误处理流程图，展示异常发生时的处理逻辑：\ngraph TD A[Start Chunk] --\u0026amp;gt; B[ItemReader: Read Item] B --\u0026amp;gt; C[ItemProcessor: Process Item] C --\u0026amp;gt; D[ItemWriter: Write Chunk] D --\u0026amp;gt;|异常| E{Retry Configured?} E …","date":1717599685,"description":"","fuzzywordcount":4900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"dd777e6786e304d34ead8a2321d7fe98","publishdate":1717599685,"relpermalink":"/posts/spring/spring-batch/springbatch5/","section":"posts","summary":"\u003ch1 id=\"spring-batch-专题系列五错误处理与重试机制\"\u003eSpring Batch 专题系列（五）：错误处理与重试机制\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003e在上一篇文章中，我们学习了 Spring Batch 的配置方式（Java 和 XML）以及调度机制（Spring Scheduler、Quartz、手动触发），掌握了如何定义和运行作业。在实际生产环境中，批处理任务难免会遇到异常，如数据格式错误、数据库连接失败或外部服务不可用。Spring Batch 提供了强大的错误处理机制，包括跳过（Skip）、重试（Retry）、重启（Restart）和监听器（Listener），确保作业在异常情况下依然可靠运行。\u003c/p\u003e","tags":["Spring","Spring Batch"],"title":"Spring Batch 专题系列（五）：错误处理与重试机制","url":"https://yinlongfei.com/posts/spring/spring-batch/springbatch5/","wordcount":4821},{"categories":"posts","content":"Spring Batch 专题系列（四）：配置与调度 Spring Batch 作业 1. 引言 在上一篇文章中，我们详细探讨了 Spring Batch 的核心组件（Job、Step、Chunk、ItemReader、ItemProcessor、ItemWriter），并通过示例展示了它们的协作方式。掌握了这些组件后，接下来需要了解如何灵活配置 Spring Batch 作业，并通过调度机制控制作业的执行时机。本文将聚焦以下内容：\nSpring Batch 的配置方式：XML 配置和 Java 配置的对比与实现。 JobParameters 的定义和使用，用于动态传递运行时参数。 调度 Spring Batch 作业：使用 Spring Scheduler、Quartz 或手动触发。 通过代码示例和 Mermaid 图表展示配置和调度的完整流程。 通过本文，你将学会如何根据项目需求配置 Spring Batch 作业，并实现定时或手动触发，为生产环境部署奠定基础。\n2. Spring Batch 配置方式 Spring Batch 支持两种主要配置方式：XML 配置 和 Java 配置。Java 配置因其类型安全和现代化特性在 Spring Boot 项目中更常见，但 XML 配置在遗留系统或特定场景中仍有使用价值。以下分别介绍这两种方式。\n2.1 Java 配置 Java 配置使用 Spring 的 @Configuration 注解和流式 API（如 JobBuilder、StepBuilder）定义 Job 和 Step。上一篇文章的示例已展示了 Java 配置，这里回顾并扩展一个更复杂的配置。\n示例：Java 配置多 Step 作业\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 package com.example.springbatchdemo.config; …","date":1717513285,"description":"","fuzzywordcount":4e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"9b2c5056eb4e262aa1be2e8d0bbf5a06","publishdate":1717513285,"relpermalink":"/posts/spring/spring-batch/springbatch4/","section":"posts","summary":"\u003ch1 id=\"spring-batch-专题系列四配置与调度-spring-batch-作业\"\u003eSpring Batch 专题系列（四）：配置与调度 Spring Batch 作业\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003e在上一篇文章中，我们详细探讨了 Spring Batch 的核心组件（Job、Step、Chunk、ItemReader、ItemProcessor、ItemWriter），并通过示例展示了它们的协作方式。掌握了这些组件后，接下来需要了解如何灵活配置 Spring Batch 作业，并通过调度机制控制作业的执行时机。本文将聚焦以下内容：\u003c/p\u003e","tags":["Spring","Spring Batch"],"title":"Spring Batch 专题系列（四）：配置与调度 Spring Batch 作业","url":"https://yinlongfei.com/posts/spring/spring-batch/springbatch4/","wordcount":3910},{"categories":"posts","content":"Spring Batch 专题系列（三）：Spring Batch 的核心组件详解 1. 引言 在上一篇文章中，我们通过一个简单的示例（从 CSV 文件读取商品数据，处理后写入数据库）快速搭建并运行了一个 Spring Batch 作业，初步接触了 Job、Step、ItemReader、ItemProcessor 和 ItemWriter 等核心组件。本文将进一步深入这些组件，详细讲解它们的定义、作用、实现方式及常见用法。我们将：\n分析 Job 和 Step 的结构与配置。 对比 Chunk-Oriented Step 和 Tasklet Step 的使用场景。 探索 ItemReader、ItemProcessor 和 ItemWriter 的多种实现。 通过代码示例和 Mermaid 图表展示组件的协作方式。 通过本文，你将对 Spring Batch 的核心组件有系统性的理解，为后续学习错误处理、并行处理等高级主题打下坚实基础。\n2. Spring Batch 核心组件概览 Spring Batch 的设计围绕模块化和可扩展性，其核心组件共同协作完成批处理任务。以下是主要组件的简要回顾：\nJob：一个完整的批处理任务，包含一个或多个 Step。 Step：Job 的独立执行单元，分为 Chunk-Oriented Step（基于块的处理）和 Tasklet Step（自定义任务）。 Chunk：Spring Batch 的核心处理模型，将数据分成块（Chunk）进行读取、处理和写入。 ItemReader：从数据源读取数据的组件（如文件、数据库、消息队列）。 ItemProcessor：对读取的数据进行转换或业务逻辑处理（可选）。 ItemWriter：将处理后的数据写入目标（如数据库、文件）。 JobRepository：存储 Job 和 Step 的元数据，通常使用数据库实现。 JobLauncher：启动 Job 的组件。 本文将重点讲解 Job、Step 和 Chunk 模型的实现细节，并深入 ItemReader、ItemProcessor 和 ItemWriter 的多种用法。\n组件协作流程图 以下是用 Mermaid 绘制的 Spring Batch 核心组件协作流程图，展示 Job、Step 和 Chunk 模型的关系：\ngraph TD …","date":1717426885,"description":"","fuzzywordcount":4100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c6ff7c20f55fb503279c8d58c55234e8","publishdate":1717426885,"relpermalink":"/posts/spring/spring-batch/springbatch3/","section":"posts","summary":"\u003ch1 id=\"spring-batch-专题系列三spring-batch-的核心组件详解\"\u003eSpring Batch 专题系列（三）：Spring Batch 的核心组件详解\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003e在上一篇文章中，我们通过一个简单的示例（从 CSV 文件读取商品数据，处理后写入数据库）快速搭建并运行了一个 Spring Batch 作业，初步接触了 Job、Step、ItemReader、ItemProcessor 和 ItemWriter 等核心组件。本文将进一步深入这些组件，详细讲解它们的定义、作用、实现方式及常见用法。我们将：\u003c/p\u003e","tags":["Spring","Spring Batch"],"title":"Spring Batch 专题系列（三）：Spring Batch 的核心组件详解","url":"https://yinlongfei.com/posts/spring/spring-batch/springbatch3/","wordcount":4047},{"categories":"posts","content":"Spring Batch 专题系列（二）：快速入门：构建第一个 Spring Batch 作业 1. 引言 在上一篇文章中，我们介绍了 Spring Batch 的核心概念，包括 Job、Step、Chunk、ItemReader、ItemProcessor 和 ItemWriter 等。本文将通过一个简单的示例，带你从零开始构建一个 Spring Batch 作业，体验其基本功能。你将学习如何：\n配置 Spring Boot 和 Spring Batch 环境。 实现从 CSV 文件读取数据、处理数据并写入数据库的完整流程。 定义 Job 和 Step。 运行并验证作业结果。 示例场景 我们将实现一个 ETL（Extract-Transform-Load）任务：\n输入：一个包含商品信息的 CSV 文件（字段：商品 ID、名称、价格）。 处理：将价格统一转换为美元（假设输入为人民币，乘以汇率 0.14），并过滤掉价格低于 0 的记录。 输出：将处理后的商品数据写入数据库的 product 表。 2. 准备工作 2.1 技术栈 Spring Boot：简化项目配置和依赖管理。 Spring Batch：提供批处理功能。 H2 数据库：嵌入式数据库，便于测试（生产环境可替换为 MySQL、PostgreSQL 等）。 Maven：依赖管理工具。 2.2 项目依赖 创建一个 Spring Boot 项目，添加以下依赖（pom.xml）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 \u0026amp;lt;?xml version=\u0026amp;#34;1.0\u0026amp;#34; encoding=\u0026amp;#34;UTF-8\u0026amp;#34;?\u0026amp;gt; \u0026amp;lt;project xmlns=\u0026amp;#34;http://maven.apache.org/POM/4.0.0\u0026amp;#34; xmlns:xsi=\u0026amp;#34;http://www.w3.org/2001/XMLSchema-instance\u0026amp;#34; …","date":1717340485,"description":"","fuzzywordcount":2600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"826aa52f98ce236502fcbc1c48430dc2","publishdate":1717340485,"relpermalink":"/posts/spring/spring-batch/springbatch2/","section":"posts","summary":"\u003ch1 id=\"spring-batch-专题系列二快速入门构建第一个-spring-batch-作业\"\u003eSpring Batch 专题系列（二）：快速入门：构建第一个 Spring Batch 作业\u003c/h1\u003e\n\u003ch2 id=\"1-引言\"\u003e1. 引言\u003c/h2\u003e\n\u003cp\u003e在上一篇文章中，我们介绍了 Spring Batch 的核心概念，包括 Job、Step、Chunk、ItemReader、ItemProcessor 和 ItemWriter 等。本文将通过一个简单的示例，带你从零开始构建一个 Spring Batch 作业，体验其基本功能。你将学习如何：\u003c/p\u003e","tags":["Spring","Spring Batch"],"title":"Spring Batch 专题系列（二）：快速入门：构建第一个 Spring Batch 作业","url":"https://yinlongfei.com/posts/spring/spring-batch/springbatch2/","wordcount":2597},{"categories":"posts","content":"Spring Batch 专题系列（一）：Spring Batch 简介与核心概念 1. 什么是 Spring Batch？ Spring Batch 是一个功能强大且轻量级的批处理框架，专为处理企业级系统中的大规模数据任务而设计。它是 Spring 生态系统的一部分，充分利用了 Spring 框架的依赖注入、AOP 和事务管理等特性。Spring Batch 的核心目标是提供一种可重用、健壮的批处理解决方案，适用于以下场景：\n批量数据处理：如 ETL（Extract-Transform-Load）任务，从数据源提取数据、转换后加载到目标。 定时任务：如每日生成财务报表、清理过期数据。 数据迁移：如将数据从旧系统迁移到新系统，或在数据库之间同步数据。 复杂业务逻辑：如批量更新订单状态、计算促销折扣。 Spring Batch 不仅支持简单的批量任务，还提供了高级功能，如错误处理、重试机制、跳过策略、并行处理、作业重启等，使其在生产环境中表现出色。\n为什么选择 Spring Batch？ 模块化：提供灵活的组件模型，易于扩展和定制。 健壮性：内置错误处理、事务管理和状态持久化机制。 可维护性：通过元数据存储跟踪作业执行状态，便于监控和调试。 生态集成：与 Spring Boot、Spring Cloud 等无缝集成，支持现代化开发。 2. Spring Batch 的核心概念 要理解 Spring Batch 的工作原理，首先需要掌握其核心概念。以下是 Spring Batch 的主要组件及其作用：\nJob（作业）\n一个 Job 代表一个完整的批处理任务，是 Spring Batch 的顶级抽象。一个 Job 通常由一个或多个 Step 组成，按定义的顺序执行。\n示例：一个生成财务报表的 Job，可能包含“读取交易数据”和“生成报表文件”两个 Step。\nStep（步骤）\nStep 是 Job 的一个独立执行单元，定义了具体的处理逻辑。Spring Batch 支持两种类型的 Step：\nChunk-Oriented Step：基于块（Chunk）的处理，适合处理大量数据，包含 ItemReader、ItemProcessor 和 ItemWriter。 Tasklet Step：执行自定义逻辑，适合简单的任务（如调用存储过程或清理资源）。 Chunk（块） …","date":1717254085,"description":"","fuzzywordcount":3200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"1daae8e522006dc6916fd9a1e4286865","publishdate":1717254085,"relpermalink":"/posts/spring/spring-batch/springbatch1/","section":"posts","summary":"\u003ch1 id=\"spring-batch-专题系列一spring-batch-简介与核心概念\"\u003eSpring Batch 专题系列（一）：Spring Batch 简介与核心概念\u003c/h1\u003e\n\u003ch2 id=\"1-什么是-spring-batch\"\u003e1. 什么是 Spring Batch？\u003c/h2\u003e\n\u003cp\u003eSpring Batch 是一个功能强大且轻量级的批处理框架，专为处理企业级系统中的大规模数据任务而设计。它是 Spring 生态系统的一部分，充分利用了 Spring 框架的依赖注入、AOP 和事务管理等特性。Spring Batch 的核心目标是提供一种可重用、健壮的批处理解决方案，适用于以下场景：\u003c/p\u003e","tags":["Spring","Spring Batch"],"title":"Spring Batch 专题系列（一）：Spring Batch 简介与核心概念","url":"https://yinlongfei.com/posts/spring/spring-batch/springbatch1/","wordcount":3126},{"categories":"posts","content":"第8篇：SOLR 的未来与源码贡献 8.1 前言 在前七篇文章中，我们从 SOLR 的基础架构到性能优化，系统地剖析了其核心机制和实现细节。作为一个成熟的开源项目，SOLR 不仅提供了强大的搜索功能，还通过活跃的社区不断演进，适应新的技术趋势和用户需求。本篇将聚焦于 SOLR 的未来与源码贡献，从社区动态和最新特性入手，分析前沿功能的源码实现，并指导读者如何参与 SOLR 的开发，提交补丁或修复 Bug。\n通过本篇，你将了解 SOLR 的发展方向，掌握参与开源的基本流程，并通过实际案例体会贡献的乐趣。这不仅是专栏的收尾，也是你迈向 SOLR 社区一员的起点。\n8.2 SOLR 社区动态 SOLR 是 Apache 基金会下的顶级项目，其社区由全球开发者、企业用户和研究者组成。SOLR 的发展呈现以下趋势：\n版本迭代：假设当前最新版本为 9.5 或 10.0（具体版本以官方发布为准），持续修复 Bug 并引入新特性。 社区活动：Apache Con、邮件列表讨论、JIRA 任务活跃。 用户需求：对云原生支持和性能优化的需求日益增加。 8.2.1 获取动态 邮件列表：订阅 dev@solr.apache.org 和 users@solr.apache.org。 JIRA：访问 https://issues.apache.org/jira/projects/SOLR 查看任务。 Git 仓库：https://gitbox.apache.org/repos/asf/lucene-solr.git。 8.3 最新特性与源码分析 SOLR 的前沿特性体现了其对现代需求的响应，以下分析两个假设的最新功能（基于趋势推测）。\n8.3.1 矢量搜索支持 随着 AI 的普及，矢量搜索（Vector Search）成为搜索领域的新热点，用于支持语义搜索或推荐系统。\n实现猜想：\n索引阶段：添加矢量字段类型，存储高维向量。 查询阶段：实现近似最近邻（ANN）搜索。 源码分析： 假设在 SchemaField 中新增 VectorField：\n1 2 3 4 5 6 7 8 9 10 11 12 public class VectorField extends FieldType { @Override protected void init(IndexSchema schema, …","date":1714230085,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"2430d9c9232ec8559b86d4d8145f5eef","publishdate":1714230085,"relpermalink":"/posts/solr/solr8/","section":"posts","summary":"\u003ch2 id=\"第8篇solr-的未来与源码贡献\"\u003e\u003cstrong\u003e第8篇：SOLR 的未来与源码贡献\u003c/strong\u003e\u003c/h2\u003e\n\u003ch3 id=\"81-前言\"\u003e\u003cstrong\u003e8.1 前言\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e在前七篇文章中，我们从 SOLR 的基础架构到性能优化，系统地剖析了其核心机制和实现细节。作为一个成熟的开源项目，SOLR 不仅提供了强大的搜索功能，还通过活跃的社区不断演进，适应新的技术趋势和用户需求。本篇将聚焦于 \u003cstrong\u003eSOLR 的未来与源码贡献\u003c/strong\u003e，从社区动态和最新特性入手，分析前沿功能的源码实现，并指导读者如何参与 SOLR 的开发，提交补丁或修复 Bug。\u003c/p\u003e","tags":["Solr"],"title":"SOLR深度源码系列解读专栏（八）：SOLR 的未来与源码贡献","url":"https://yinlongfei.com/posts/solr/solr8/","wordcount":1669},{"categories":"posts","content":"7.1 前言 在前几篇文章中，我们已经全面剖析了 SOLR 的核心机制，包括索引、查询、分布式架构和插件扩展。掌握了这些基础后，如何让 SOLR 在实际应用中运行得更快、更稳定，成为了开发者关注的重点。本篇将聚焦于 性能优化与问题排查，从索引速度、查询延迟到内存管理，逐步揭示 SOLR 的优化策略和调试技巧，并通过源码分析核心实现细节。\n通过本篇，你将学会如何识别 SOLR 的性能瓶颈、应用优化手段解决问题，并利用日志和源码定位异常。这不仅能提升系统性能，还能增强对 SOLR 内部机制的掌控力。\n7.2 性能瓶颈分析 SOLR 的性能问题通常出现在以下几个方面：\n索引速度慢：文档提交或提交耗时过长。 查询延迟高：搜索响应时间过长。 内存压力大：频繁 GC 或 OOM。 分布式瓶颈：分片间通信或数据同步延迟。 7.2.1 瓶颈识别 工具：SOLR Admin UI（Metrics、Logging）、JVisualVM、日志分析。 指标： 索引吞吐量（docs/sec）。 查询 QPS 和平均延迟。 JVM 堆使用率和 GC 频率。 7.3 索引性能优化 索引是 SOLR 的核心操作，优化索引速度可以显著提升系统效率。\n7.3.1 批量提交 单次提交多个文档比逐个提交更高效：\n1 2 3 4 5 6 7 8 9 10 CloudSolrClient client = new CloudSolrClient.Builder().withZkHost(\u0026amp;#34;localhost:2181\u0026amp;#34;).build(); List\u0026amp;lt;SolrInputDocument\u0026amp;gt; docs = new ArrayList\u0026amp;lt;\u0026amp;gt;(); for (int i = 0; i \u0026amp;lt; 1000; i++) { SolrInputDocument doc = new SolrInputDocument(); doc.addField(\u0026amp;#34;id\u0026amp;#34;, String.valueOf(i)); doc.addField(\u0026amp;#34;title\u0026amp;#34;, \u0026amp;#34;Test \u0026amp;#34; + i); docs.add(doc); } client.add(\u0026amp;#34;my_collection\u0026amp;#34;, docs); client.commit(); 7.3.2 调整提交 …","date":1713366085,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"dad5fe0e75d3289a1c3fb8a57bd825e6","publishdate":1713366085,"relpermalink":"/posts/solr/solr7/","section":"posts","summary":"\u003ch3 id=\"71-前言\"\u003e\u003cstrong\u003e7.1 前言\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e在前几篇文章中，我们已经全面剖析了 SOLR 的核心机制，包括索引、查询、分布式架构和插件扩展。掌握了这些基础后，如何让 SOLR 在实际应用中运行得更快、更稳定，成为了开发者关注的重点。本篇将聚焦于 \u003cstrong\u003e性能优化与问题排查\u003c/strong\u003e，从索引速度、查询延迟到内存管理，逐步揭示 SOLR 的优化策略和调试技巧，并通过源码分析核心实现细节。\u003c/p\u003e","tags":["Solr"],"title":"SOLR深度源码系列解读专栏（七）：性能优化与问题排查","url":"https://yinlongfei.com/posts/solr/solr7/","wordcount":1657},{"categories":"posts","content":"6.1 前言 在前几篇文章中，我们已经全面剖析了 SOLR 的核心功能，包括索引构建、查询执行和分布式架构（SolrCloud）。然而，SOLR 的强大不仅在于其内置功能，还在于其高度可扩展的插件机制。无论是自定义查询解析、修改索引流程，还是添加新的搜索组件，SOLR 都通过插件架构提供了灵活的定制能力。本篇将从插件机制的设计理念入手，逐步揭示其实现细节，并通过源码分析和实践案例，帮助读者掌握如何扩展 SOLR。\n通过本篇，你将理解 SOLR 的插件加载流程、常见扩展点及其源码实现，并能够动手开发自己的插件。这不仅能满足特定业务需求，还能深化对 SOLR 内部机制的理解。\n6.2 插件机制的设计理念 SOLR 的插件机制基于“模块化”和“松耦合”的设计思想，旨在允许开发者在不修改核心代码的情况下扩展功能。其核心理念包括：\n可插拔性：通过配置文件动态加载插件。 标准化：提供统一的接口和生命周期管理。 灵活性：支持多种扩展点，覆盖索引、查询和请求处理。 隔离性：插件独立运行，不干扰核心逻辑。 插件机制的核心依托于 Java 的反射机制和 SOLR 的配置系统（solrconfig.xml）。\n6.3 插件架构概览 SOLR 的插件架构围绕以下组件展开：\nSolrPluginUtils：插件加载和初始化工具。 SolrConfig：解析 solrconfig.xml，注册插件。 SolrCore：管理插件实例的容器。 接口与基类：如 SolrRequestHandler、SearchComponent 等。 典型插件类型 RequestHandler：处理特定请求（如 /select、/update）。 SearchComponent：查询流程中的模块（如分面、高亮）。 QueryParser：自定义查询解析逻辑。 UpdateProcessor：修改索引流程。 6.4 插件加载流程 插件的加载始于 SOLR 的启动过程，由 SolrCore 协调。\n6.4.1 配置定义 插件通常在 solrconfig.xml 中声明，例如：\n1 2 3 4 5 \u0026amp;lt;requestHandler name=\u0026amp;#34;/myhandler\u0026amp;#34; class=\u0026amp;#34;com.example.MyRequestHandler\u0026amp;#34;\u0026amp;gt; \u0026amp;lt;lst …","date":1712588485,"description":"","fuzzywordcount":1900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"5d451e92f0a33aa8117ae9c19e60f7f1","publishdate":1712588485,"relpermalink":"/posts/solr/solr6/","section":"posts","summary":"\u003ch3 id=\"61-前言\"\u003e\u003cstrong\u003e6.1 前言\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e在前几篇文章中，我们已经全面剖析了 SOLR 的核心功能，包括索引构建、查询执行和分布式架构（SolrCloud）。然而，SOLR 的强大不仅在于其内置功能，还在于其高度可扩展的插件机制。无论是自定义查询解析、修改索引流程，还是添加新的搜索组件，SOLR 都通过插件架构提供了灵活的定制能力。本篇将从插件机制的设计理念入手，逐步揭示其实现细节，并通过源码分析和实践案例，帮助读者掌握如何扩展 SOLR。\u003c/p\u003e","tags":["Solr"],"title":"SOLR深度源码系列解读专栏（六）：插件机制与扩展性","url":"https://yinlongfei.com/posts/solr/solr6/","wordcount":1832},{"categories":"posts","content":"5.1 前言 在之前的文章中，我们已经详细探讨了 SOLR 在单机模式下的索引构建、更新和查询机制。然而，现代搜索应用的规模往往需要分布式系统来支持高并发、大数据量和高可用性。SOLR 通过 SolrCloud 提供了分布式解决方案，能够将索引和查询任务分布到多个节点，同时利用 ZooKeeper 实现集群协调。本篇将从 SolrCloud 的设计理念入手，逐步揭示其分布式架构和关键实现细节，并通过源码分析核心组件的功能。\n通过本篇，你将理解 SolrCloud 如何管理分片和副本、如何处理分布式查询和索引，以及如何确保数据一致性。这不仅是对前几篇内容的扩展，也是掌握 SOLR 企业级应用的关键一步。\n5.2 SolrCloud 的设计理念 SolrCloud 是 SOLR 的分布式模式，旨在解决单机模式的局限性（如存储容量和查询性能）。其核心设计目标包括：\n可扩展性：通过分片（Sharding）支持水平扩展。 高可用性：通过副本（Replica）实现故障转移。 一致性：利用 ZooKeeper 维护集群状态。 简单性：对客户端屏蔽分布式复杂性，提供统一的访问接口。 5.2.1 核心概念 Collection：逻辑上的索引集合，包含多个分片。 Shard：Collection 的一个子集，独立存储部分数据。 Replica：Shard 的副本，运行在不同节点上。 ZooKeeper：分布式协调服务，存储集群元数据（如分片状态）。 Leader：每个 Shard 的主副本，负责协调更新。 这些概念在源码中以类和数据结构的形式体现，后文会逐一分析。\n5.3 SolrCloud 架构概览 SolrCloud 的架构可以分为以下层次：\n客户端层：通过 CloudSolrClient 与集群交互。 节点层：多个 SOLR 实例（节点），每个节点运行多个 Core。 协调层：ZooKeeper 管理集群状态和配置。 存储层：分布式索引文件，基于 Lucene。 架构示意图（文字描述） 客户端 → CloudSolrClient → [Node1(Shard1 Leader), Node2(Shard1 Replica), Node3(Shard2 Leader)] → ZooKeeper → Lucene 索引 5.4 ZooKeeper 的作用 ZooKeeper …","date":1711551685,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"ec34201cc19d0a465ca2c362a11d10d2","publishdate":1711551685,"relpermalink":"/posts/solr/solr5/","section":"posts","summary":"\u003ch3 id=\"51-前言\"\u003e\u003cstrong\u003e5.1 前言\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e在之前的文章中，我们已经详细探讨了 SOLR 在单机模式下的索引构建、更新和查询机制。然而，现代搜索应用的规模往往需要分布式系统来支持高并发、大数据量和高可用性。SOLR 通过 \u003cstrong\u003eSolrCloud\u003c/strong\u003e 提供了分布式解决方案，能够将索引和查询任务分布到多个节点，同时利用 ZooKeeper 实现集群协调。本篇将从 SolrCloud 的设计理念入手，逐步揭示其分布式架构和关键实现细节，并通过源码分析核心组件的功能。\u003c/p\u003e","tags":["Solr"],"title":"SOLR深度源码系列解读专栏（五）：分布式搜索与 SolrCloud","url":"https://yinlongfei.com/posts/solr/solr5/","wordcount":1791},{"categories":"posts","content":"第4篇：查询解析与执行 4.1 前言 在上一篇文章中，我们详细剖析了 SOLR 的索引构建与更新机制，理解了数据如何被高效存储到 Lucene 索引中。现在，我们将视线转向 SOLR 的另一核心功能：查询解析与执行。查询是 SOLR 的“门面”，它决定了用户能否快速、准确地找到所需数据。本篇将从查询的生命周期入手，逐步揭示 SOLR 如何将用户输入的查询字符串转化为高效的搜索操作，并通过源码分析关键实现细节。\nSOLR 的查询处理涉及多个组件，包括查询解析器、搜索核心、结果排序与高亮等。通过本篇，你将掌握 SOLR 查询的内部机制，为后续优化查询性能或开发自定义查询功能打下基础。\n4.2 查询的生命周期 SOLR 的查询过程可以分为以下几个阶段：\n客户端提交查询：通过 HTTP 请求发送查询参数（如 q=title:Hello）。 请求分发：SOLR 接收并路由到查询处理器。 查询解析：将查询字符串转化为内部查询对象。 搜索执行：基于 Lucene 索引执行查询。 结果处理与返回：排序、分页、高亮后返回客户端。 本篇以单机模式为主，后续会在分布式篇章中扩展 SolrCloud 的查询机制。\n4.3 客户端提交：查询请求示例 查询通常通过 HTTP GET 或 POST 提交，以下是一个典型查询：\nGET http://localhost:8983/solr/mycore/select?q=title:Hello\u0026amp;amp;fl=id,title\u0026amp;amp;rows=10\u0026amp;amp;sort=score desc q：查询字符串。 fl：返回字段。 rows：结果条数。 sort：排序规则。 4.3.1 请求入口 如第二篇所述，请求被 SolrDispatchFilter 拦截，创建 HttpSolrCall，根据路径 /select 路由到 SearchHandler。\n4.3.2 SearchHandler 的角色 SearchHandler 是查询操作的总指挥，位于 org.apache.solr.handler.component 包中。其核心方法是 handleRequestBody：\n1 2 3 4 5 6 public class SearchHandler extends RequestHandlerBase { @Override public void …","date":1709910085,"description":"","fuzzywordcount":2e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"a8624817c369d7d0f3990ed667621c77","publishdate":1709910085,"relpermalink":"/posts/solr/solr4/","section":"posts","summary":"\u003ch2 id=\"第4篇查询解析与执行\"\u003e\u003cstrong\u003e第4篇：查询解析与执行\u003c/strong\u003e\u003c/h2\u003e\n\u003ch3 id=\"41-前言\"\u003e\u003cstrong\u003e4.1 前言\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e在上一篇文章中，我们详细剖析了 SOLR 的索引构建与更新机制，理解了数据如何被高效存储到 Lucene 索引中。现在，我们将视线转向 SOLR 的另一核心功能：\u003cstrong\u003e查询解析与执行\u003c/strong\u003e。查询是 SOLR 的“门面”，它决定了用户能否快速、准确地找到所需数据。本篇将从查询的生命周期入手，逐步揭示 SOLR 如何将用户输入的查询字符串转化为高效的搜索操作，并通过源码分析关键实现细节。\u003c/p\u003e","tags":["Solr"],"title":"SOLR深度源码系列解读专栏（四）：查询解析与执行","url":"https://yinlongfei.com/posts/solr/solr4/","wordcount":1988},{"categories":"posts","content":"结语：从源码看Redis的设计哲学 1. 引言 通过前七篇的源码解析，我们从Redis的整体架构、核心数据结构、事件驱动模型，到内存管理、持久化、主从复制与集群模式，逐步揭开了Redis高性能与简洁性的秘密。本篇将总结这些技术细节，提炼Redis的设计哲学，并探讨如何将源码学习成果应用到实际开发中。\n2. Redis的核心设计哲学 2.1 单线程的极致简洁 源码体现：事件循环（ae.c）与单线程模型避免了多线程的锁竞争和上下文切换开销。 哲学：在内存操作场景下，单线程通过非阻塞I/O和高效数据结构足以应对高并发，复杂性并非性能的必要代价。 权衡：牺牲了多核利用率，适用于I/O密集而非CPU密集任务。 2.2 数据结构的精妙设计 源码体现：SDS（sds.c）、字典（dict.c）、跳表（t_zset.c）等结构针对不同场景优化。 哲学：为每种操作选择最适合的数据结构，追求时间与空间的平衡。例如，跳表的随机性避免了平衡树的复杂调整，SDS的空间预分配提升了拼接效率。 启示：性能优化需从需求出发，而非盲目追求通用性。 2.3 高性能与可靠性的折衷 源码体现：RDB（rdb.c）与AOF（aof.c）的持久化机制，主从复制（replication.c）的异步设计。 哲学：性能优先，但提供可配置的可靠性选项。RDB适合快速恢复，AOF保证数据完整性，用户可根据场景选择。 权衡：异步复制可能丢失少量数据，但显著提升吞吐量。 2.4 模块化与可扩展性 源码体现：集群模式（cluster.c）的分片设计，内存分配器（zmalloc.c）的可替换性。 哲学：保持核心简洁，同时为扩展预留接口。集群通过16384槽实现分布式，内存管理支持jemalloc等切换。 启示：好的设计应易于维护和扩展，而非一味堆砌功能。 3. 单线程模型的局限与优势 优势： 无锁操作：内存操作无需同步，效率极高。 调试简单：单线程逻辑清晰，易于跟踪（如用gdb分析aeProcessEvents()）。 资源占用低：无需线程池管理，开销小。 局限： CPU利用率：无法充分利用多核，计算密集任务（如大范围排序）较慢。 阻塞风险：慢查询（如KEYS *）可能影响整体响应。 4. 源码学习的实际应用 性能优化：借鉴SDS的预分配和字典的渐进式rehash，优化自己的字符串或哈希表实现。 架构设计：参考事件循环，设计轻 …","date":1709823685,"description":"","fuzzywordcount":1200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"293737f19679ce50886fe12c7c1f66ed","publishdate":1709823685,"relpermalink":"/posts/redis/redis8/","section":"posts","summary":"\u003ch3 id=\"结语从源码看redis的设计哲学\"\u003e结语：从源码看Redis的设计哲学\u003c/h3\u003e\n\u003ch4 id=\"1-引言\"\u003e1. 引言\u003c/h4\u003e\n\u003cp\u003e通过前七篇的源码解析，我们从Redis的整体架构、核心数据结构、事件驱动模型，到内存管理、持久化、主从复制与集群模式，逐步揭开了Redis高性能与简洁性的秘密。本篇将总结这些技术细节，提炼Redis的设计哲学，并探讨如何将源码学习成果应用到实际开发中。\u003c/p\u003e","tags":["源码","redis"],"title":"Redis 源码硬核解析系列专题 - 结语：从源码看Redis的设计哲学","url":"https://yinlongfei.com/posts/redis/redis8/","wordcount":1178},{"categories":"posts","content":"第七篇：主从复制与集群模式 1. 引言 Redis通过主从复制实现高可用性，通过集群模式实现数据分片和分布式扩展。本篇将深入剖析主从复制（replication.c）和Redis Cluster（cluster.c）的源码实现，揭示其同步机制、故障转移和分片逻辑。\n2. 主从复制 2.1 主从同步概述 作用：从节点复制主节点数据，提供读扩展和容错。 方式： 全量同步（Full Resync）：初次同步或数据差异过大。 增量同步（Partial Resync）：通过复制偏移量同步增量命令。 2.2 全量同步（syncCommand()） 代码片段（replication.c）：\n1 2 3 4 5 6 7 8 9 void syncCommand(client *c) { if (server.masterhost == NULL) { // 主节点处理 if (c-\u0026amp;gt;flags \u0026amp;amp; CLIENT_SLAVE) return; c-\u0026amp;gt;flags |= CLIENT_SLAVE; listAddNodeTail(server.slaves, c); replicationSendNewline(c); replicationSendRdb(c); // 发送RDB文件 } } 硬核解析：\nCLIENT_SLAVE：标记从节点客户端。 replicationSendRdb()：主节点生成RDB快照并发送。 2.3 增量同步（PSYNC） 代码片段（replication.c）：\n1 2 3 4 5 6 7 8 void replicationPSync(client *c, char *replid, long long offset) { if (memcmp(replid, server.replid, CONFIG_RUN_ID_SIZE) == 0 \u0026amp;amp;\u0026amp;amp; offset \u0026amp;gt;= server.repl_backlog_first_byte_offset) { replicationSendContinuation(c, offset); // 增量同步 } else { replicationSendFullResync(c); // 全量同步 } } 硬核解析：\nreplid：复制ID，标识主节点实例。 …","date":1709737285,"description":"","fuzzywordcount":1400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"555bcfe598a50182259e1ab7524ba2eb","publishdate":1709737285,"relpermalink":"/posts/redis/redis7/","section":"posts","summary":"\u003ch3 id=\"第七篇主从复制与集群模式\"\u003e第七篇：主从复制与集群模式\u003c/h3\u003e\n\u003ch4 id=\"1-引言\"\u003e1. 引言\u003c/h4\u003e\n\u003cp\u003eRedis通过主从复制实现高可用性，通过集群模式实现数据分片和分布式扩展。本篇将深入剖析主从复制（\u003ccode\u003ereplication.c\u003c/code\u003e）和Redis Cluster（\u003ccode\u003ecluster.c\u003c/code\u003e）的源码实现，揭示其同步机制、故障转移和分片逻辑。\u003c/p\u003e","tags":["源码","redis"],"title":"Redis 源码硬核解析系列专题 - 第七篇：主从复制与集群模式","url":"https://yinlongfei.com/posts/redis/redis7/","wordcount":1339},{"categories":"posts","content":"扩展篇：Gossip协议的具体实现 1. 引言 Redis Cluster使用Gossip协议实现节点间的状态同步和一致性维护。Gossip协议是一种去中心化的通信机制，通过节点间的“谣言传播”方式交换信息，具有高容错性和扩展性。本篇将深入剖析Redis中Gossip协议的具体实现，包括消息格式、传播机制和故障检测逻辑。\n2. Gossip协议在Redis中的作用 状态同步：确保每个节点了解集群中所有节点的状态（如在线、槽分配）。 故障检测：通过心跳检测发现节点失败，触发故障转移。 去中心化：无需主控节点，适应动态集群变化。 3. 核心结构与消息格式 3.1 集群节点结构 代码片段（cluster.h）：\n1 2 3 4 5 6 7 8 9 typedef struct clusterNode { char name[CLUSTER_NAMELEN]; // 节点ID int flags; // 状态（如CLUSTER_NODE_FAIL） uint16_t port; // 端口 unsigned char slots[16384/8]; // 槽位图 mstime_t ping_sent; // 上次发送PING时间 mstime_t pong_received; // 上次收到PONG时间 clusterLink *link; // 与该节点的连接 } clusterNode; 硬核解析：\nping_sent/pong_received：用于心跳检测。 link：保存TCP连接和发送缓冲区。 3.2 Gossip消息格式 代码片段（cluster.h）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 typedef struct clusterMsg { char sig[4]; // \u0026amp;#34;RCmb\u0026amp;#34; uint32_t totlen; // 消息总长度 uint16_t ver; // 协议版本 uint16_t type; // 消息类型（如CLUSTERMSG_TYPE_PING） char sender[CLUSTER_NAMELEN]; // 发送者ID unsigned char myslots[16384/8]; // 发送者槽位图 char master[CLUSTER_NAMELEN]; // 主节点ID（若为 …","date":1709737285,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"b90f16e4fdad884a6b2c4d55ed32182b","publishdate":1709737285,"relpermalink":"/posts/redis/redis7-k/","section":"posts","summary":"\u003ch3 id=\"扩展篇gossip协议的具体实现\"\u003e扩展篇：Gossip协议的具体实现\u003c/h3\u003e\n\u003ch4 id=\"1-引言\"\u003e1. 引言\u003c/h4\u003e\n\u003cp\u003eRedis Cluster使用Gossip协议实现节点间的状态同步和一致性维护。Gossip协议是一种去中心化的通信机制，通过节点间的“谣言传播”方式交换信息，具有高容错性和扩展性。本篇将深入剖析Redis中Gossip协议的具体实现，包括消息格式、传播机制和故障检测逻辑。\u003c/p\u003e","tags":["源码","redis"],"title":"Redis 源码硬核解析系列专题 - 扩展篇：Gossip协议的具体实现","url":"https://yinlongfei.com/posts/redis/redis7-k/","wordcount":1669},{"categories":"posts","content":"第六篇：内存管理与持久化机制 1. 引言 Redis作为一个内存数据库，其内存管理和持久化机制直接影响性能和数据可靠性。Redis通过自定义内存分配器优化内存使用，同时提供RDB和AOF两种持久化方式保证数据不丢失。本篇将深入剖析Redis的内存管理（zmalloc.c）以及RDB（rdb.c）和AOF（aof.c）的实现细节。\n2. 内存管理 2.1 Redis的内存分配器 Redis默认使用jemalloc（可在deps/中找到），也支持tcmalloc或标准libc。自定义封装在zmalloc.c中。\n代码片段（zmalloc.h）：\n1 2 3 4 void *zmalloc(size_t size); void *zrealloc(void *ptr, size_t size); void zfree(void *ptr); size_t zmalloc_size(void *ptr); 硬核解析：\nzmalloc()：调用jemalloc分配内存，记录使用量。 zmalloc_size()：返回实际分配块大小，用于内存统计。 优势：减少碎片，提升分配效率。 代码片段（zmalloc.c）：\n1 2 3 4 5 6 7 void *zmalloc(size_t size) { void *ptr = je_malloc(size + PREFIX_SIZE); if (!ptr) zmalloc_oom_handler(size); *((size_t*)ptr) = size; // 记录大小 update_zmalloc_stat_alloc(size + PREFIX_SIZE); return (char*)ptr + PREFIX_SIZE; } 硬核解析：\nPREFIX_SIZE：额外空间存储元数据（通常8字节）。 update_zmalloc_stat_alloc()：更新全局内存统计。 3. 持久化机制 Redis提供两种持久化方式：RDB（快照）和AOF（日志）。\n3.1 RDB持久化（rdb.c） RDB通过生成内存数据的快照保存到磁盘。\n代码片段（rdbSave()）：\n1 2 3 4 5 6 int rdbSave(char *filename, rdbSaveInfo *rsi) { rio rdb; …","date":1709650885,"description":"","fuzzywordcount":1500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"3fb882298b5c4a910ef65c55ba65b58c","publishdate":1709650885,"relpermalink":"/posts/redis/redis6/","section":"posts","summary":"\u003ch3 id=\"第六篇内存管理与持久化机制\"\u003e第六篇：内存管理与持久化机制\u003c/h3\u003e\n\u003ch4 id=\"1-引言\"\u003e1. 引言\u003c/h4\u003e\n\u003cp\u003eRedis作为一个内存数据库，其内存管理和持久化机制直接影响性能和数据可靠性。Redis通过自定义内存分配器优化内存使用，同时提供RDB和AOF两种持久化方式保证数据不丢失。本篇将深入剖析Redis的内存管理（\u003ccode\u003ezmalloc.c\u003c/code\u003e）以及RDB（\u003ccode\u003erdb.c\u003c/code\u003e）和AOF（\u003ccode\u003eaof.c\u003c/code\u003e）的实现细节。\u003c/p\u003e","tags":["源码","redis"],"title":"Redis 源码硬核解析系列专题 - 第六篇：内存管理与持久化机制","url":"https://yinlongfei.com/posts/redis/redis6/","wordcount":1402},{"categories":"posts","content":"第五篇：事件驱动模型与网络层 1. 引言 Redis的高性能很大程度上依赖其事件驱动模型和高效的网络层实现。基于单线程的事件循环，Redis能够处理大量并发连接而无需多线程开销。本篇将深入剖析Redis的事件循环框架（ae.c）和网络处理机制（networking.c），揭示其如何实现高并发。\n2. 事件驱动模型概览 Redis的事件循环基于ae.c，支持两种事件：\n文件事件（File Event）：处理客户端socket的读写。 时间事件（Time Event）：执行定时任务（如过期键清理）。 底层I/O多路复用机制根据系统选择：\nLinux：epoll（默认）。 BSD/macOS：kqueue。 Solaris：evport。 其他：select。 3. 事件循环的核心结构 代码片段（ae.h）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 typedef struct aeEventLoop { int maxfd; // 最大文件描述符 aeFileEvent *events; // 文件事件数组 aeFiredEvent *fired; // 已触发事件数组 aeTimeEvent *timeEventHead; // 时间事件链表 int stop; // 停止标志 void *apidata; // 多路复用API数据（如epoll） } aeEventLoop; typedef struct aeFileEvent { int mask; // 事件类型（AE_READABLE | AE_WRITABLE） aeFileProc *rfileProc; // 读回调 aeFileProc *wfileProc; // 写回调 void *clientData; // 客户端数据 } aeFileEvent; 硬核解析：\nevents：文件事件表，索引为fd。 fired：记录触发的事件。 timeEventHead：单链表存储定时任务。 Mermaid结构图：\nclassDiagram class aeEventLoop { -maxfd: int -events: aeFileEvent* -fired: aeFiredEvent* -timeEventHead: aeTimeEvent* -stop: int …","date":1709564485,"description":"","fuzzywordcount":1500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"1ff9a16725ad4c0b938d653ddf8e0c3f","publishdate":1709564485,"relpermalink":"/posts/redis/redis5/","section":"posts","summary":"\u003ch3 id=\"第五篇事件驱动模型与网络层\"\u003e第五篇：事件驱动模型与网络层\u003c/h3\u003e\n\u003ch4 id=\"1-引言\"\u003e1. 引言\u003c/h4\u003e\n\u003cp\u003eRedis的高性能很大程度上依赖其事件驱动模型和高效的网络层实现。基于单线程的事件循环，Redis能够处理大量并发连接而无需多线程开销。本篇将深入剖析Redis的事件循环框架（\u003ccode\u003eae.c\u003c/code\u003e）和网络处理机制（\u003ccode\u003enetworking.c\u003c/code\u003e），揭示其如何实现高并发。\u003c/p\u003e","tags":["源码","redis"],"title":"Redis 源码硬核解析系列专题 - 第五篇：事件驱动模型与网络层","url":"https://yinlongfei.com/posts/redis/redis5/","wordcount":1476},{"categories":"posts","content":"第四篇：核心数据结构之跳表（Skip List） 1. 引言 跳表（Skip List）是一种高效的动态数据结构，在Redis中用于实现有序集合（ZSET），支持快速的范围查询和插入删除操作。相比传统平衡树（如AVL或红黑树），跳表的实现更简单且性能优异。本篇将深入剖析Redis跳表的源码实现，包括结构定义、插入删除逻辑和随机层高生成。\n2. 跳表在Redis中的应用 用途：ZSET的核心数据结构，存储元素和分数（score），支持按分数排序。 特性：结合链表的简单性和二分查找的高效性，平均时间复杂度为O(log n)。 3. 跳表的结构体定义 跳表的实现位于src/server.h和src/t_zset.c中。以下是核心结构：\n代码片段（server.h）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 typedef struct zskiplistNode { sds ele; // 元素（SDS字符串） double score; // 分数 struct zskiplistNode *backward; // 后退指针 struct zskiplistLevel { struct zskiplistNode *forward; // 前进指针 unsigned long span; // 跨度（到下个节点的距离） } level[]; // 层数组（柔性数组） } zskiplistNode; typedef struct zskiplist { struct zskiplistNode *header; // 头节点 struct zskiplistNode *tail; // 尾节点 unsigned long length; // 节点数 int level; // 最大层数 } zskiplist; 硬核解析：\nzskiplistNode：每个节点包含元素、分数和多层前进指针（level[]）。 level[i].forward：指向该层下一个节点。 span：记录跨越的节点数，用于范围查询。 backward：后退指针，便于双向遍历。 zskiplist：管理整个跳表，header不存储数据，仅作为起点。 Mermaid结构图：\nclassDiagram class zskiplist { -header: …","date":1709478085,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"ef6d8b12228e6faa4d3bcd3b43d0ccda","publishdate":1709478085,"relpermalink":"/posts/redis/redis4/","section":"posts","summary":"\u003ch3 id=\"第四篇核心数据结构之跳表skip-list\"\u003e第四篇：核心数据结构之跳表（Skip List）\u003c/h3\u003e\n\u003ch4 id=\"1-引言\"\u003e1. 引言\u003c/h4\u003e\n\u003cp\u003e跳表（Skip List）是一种高效的动态数据结构，在Redis中用于实现有序集合（ZSET），支持快速的范围查询和插入删除操作。相比传统平衡树（如AVL或红黑树），跳表的实现更简单且性能优异。本篇将深入剖析Redis跳表的源码实现，包括结构定义、插入删除逻辑和随机层高生成。\u003c/p\u003e","tags":["源码","redis"],"title":"Redis 源码硬核解析系列专题 - 第四篇：核心数据结构之跳表（Skip List）","url":"https://yinlongfei.com/posts/redis/redis4/","wordcount":1714},{"categories":"posts","content":"第三篇：核心数据结构之字典（Dict） 1. 引言 字典（Dict）是Redis的核心数据结构之一，用于实现键值存储（Redis数据库的核心）和内部元数据管理（如客户端状态）。Redis的字典基于哈希表实现，支持高效的增删改查操作。本篇将深入剖析其源码实现，包括哈希表结构、冲突解决和渐进式rehash机制。\n2. 字典的结构体定义 字典的定义在src/dict.h和src/dict.c中。以下是核心结构：\n代码片段（dict.h）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 typedef struct dictEntry { void *key; // 键 union { void *val; // 值 uint64_t u64; int64_t s64; double d; } v; struct dictEntry *next; // 链表，解决哈希冲突 } dictEntry; typedef struct dictht { dictEntry **table; // 哈希表数组 unsigned long size; // 哈希表大小 unsigned long sizemask; // 大小掩码，用于计算索引 unsigned long used; // 已使用槽数 } dictht; typedef struct dict { dictType *type; // 类型特定函数（如自定义哈希） void *privdata; // 私有数据 dictht ht[2]; // 两个哈希表，用于rehash long rehashidx; // rehash进度，-1表示未进行 } dict; 硬核解析：\ndictEntry：键值对节点，next指针形成链表解决冲突。 dictht：哈希表，size是2的幂次，sizemask = size - 1。 dict：包含两个哈希表ht[0]和ht[1]，支持渐进式rehash。 Mermaid结构图：\nclassDiagram class dict { -type: dictType* -privdata: void* -ht[2]: dictht -rehashidx: long } class dictht { …","date":1709391685,"description":"","fuzzywordcount":1600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"cef44c416b4aee08b0e13cd6db08f400","publishdate":1709391685,"relpermalink":"/posts/redis/redis3/","section":"posts","summary":"\u003ch3 id=\"第三篇核心数据结构之字典dict\"\u003e第三篇：核心数据结构之字典（Dict）\u003c/h3\u003e\n\u003ch4 id=\"1-引言\"\u003e1. 引言\u003c/h4\u003e\n\u003cp\u003e字典（Dict）是Redis的核心数据结构之一，用于实现键值存储（Redis数据库的核心）和内部元数据管理（如客户端状态）。Redis的字典基于哈希表实现，支持高效的增删改查操作。本篇将深入剖析其源码实现，包括哈希表结构、冲突解决和渐进式rehash机制。\u003c/p\u003e","tags":["源码","redis"],"title":"Redis 源码硬核解析系列专题 - 第三篇：核心数据结构之字典（Dict）","url":"https://yinlongfei.com/posts/redis/redis3/","wordcount":1522},{"categories":"posts","content":"第3篇：索引构建与更新机制 3.1 前言 在上一篇文章中，我们从宏观视角剖析了 SOLR 的整体架构，了解了请求如何从客户端到达服务端并通过核心组件处理。现在，我们将聚焦于 SOLR 的一个核心功能：索引构建与更新。无论是单机模式还是分布式环境，索引是 SOLR 提供高效搜索的基础。本篇将从索引的生命周期入手，逐步揭示 SOLR 如何将文档转化为可搜索的数据，并通过源码分析关键实现细节。\n索引的构建和更新涉及多个组件协作，包括客户端请求解析、更新处理逻辑、Lucene 的底层索引操作，以及事务日志和提交策略的优化。通过本篇，你将掌握 SOLR 索引的核心机制，为后续优化和定制奠定基础。\n3.2 索引的生命周期 SOLR 的索引过程可以分为以下几个阶段：\n客户端提交：通过 HTTP 请求（如 POST JSON）发送文档。 请求分发：SOLR 接收并路由到更新处理器。 文档处理：解析文档、应用 Schema 规则。 索引写入：将文档写入 Lucene 索引。 提交与同步：确保数据持久化并对查询可见。 在分布式环境下，还会涉及分片分配和副本同步，但本篇以单机模式为主，后续会扩展到 SolrCloud。\n3.3 客户端提交：从请求开始 索引过程始于客户端提交文档。SOLR 支持多种格式（如 JSON、XML、CSV），以下以 JSON 为例：\nPOST http://localhost:8983/solr/mycore/update?commit=true Content-Type: application/json [ {\u0026amp;#34;id\u0026amp;#34;: \u0026amp;#34;1\u0026amp;#34;, \u0026amp;#34;title\u0026amp;#34;: \u0026amp;#34;Hello SOLR\u0026amp;#34;, \u0026amp;#34;content\u0026amp;#34;: \u0026amp;#34;This is a test document\u0026amp;#34;} ] 3.3.1 请求入口 如第二篇所述，请求首先被 SolrDispatchFilter 拦截，创建 HttpSolrCall，并根据路径 /update 路由到 UpdateHandler。\n3.3.2 UpdateHandler 的角色 UpdateHandler 是更新操作的总指挥，位于 org.apache.solr.update 包中。它的核心方法是 handleRequestBody：\n1 2 3 4 5 …","date":1709391685,"description":"","fuzzywordcount":2200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"3845942afaa90ced901678390954214f","publishdate":1709391685,"relpermalink":"/posts/solr/solr3/","section":"posts","summary":"\u003ch2 id=\"第3篇索引构建与更新机制\"\u003e\u003cstrong\u003e第3篇：索引构建与更新机制\u003c/strong\u003e\u003c/h2\u003e\n\u003ch3 id=\"31-前言\"\u003e\u003cstrong\u003e3.1 前言\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e在上一篇文章中，我们从宏观视角剖析了 SOLR 的整体架构，了解了请求如何从客户端到达服务端并通过核心组件处理。现在，我们将聚焦于 SOLR 的一个核心功能：\u003cstrong\u003e索引构建与更新\u003c/strong\u003e。无论是单机模式还是分布式环境，索引是 SOLR 提供高效搜索的基础。本篇将从索引的生命周期入手，逐步揭示 SOLR 如何将文档转化为可搜索的数据，并通过源码分析关键实现细节。\u003c/p\u003e","tags":["Solr"],"title":"SOLR深度源码系列解读专栏（三）：索引构建与更新机制","url":"https://yinlongfei.com/posts/solr/solr3/","wordcount":2110},{"categories":"posts","content":"第二篇：核心数据结构之SDS（Simple Dynamic String） 1. 引言 Redis没有直接使用C语言的标准字符串（以\\0结尾的字符数组），而是自定义了SDS（Simple Dynamic String）。SDS是Redis的基础数据结构之一，广泛用于键值存储、命令参数等场景。本篇将深入剖析SDS的实现原理、优势以及源码细节。\n2. 为什么不用C标准字符串？ C字符串存在以下问题：\n缓冲区溢出：strcat等操作可能越界。 长度计算：需要遍历到\\0，时间复杂度O(n)。 内存管理：频繁的拼接和释放效率低下。 SDS通过额外的元数据和优化策略，解决了这些问题，成为Redis高性能的基石。\n3. SDS的结构体定义 SDS的定义在src/sds.h和src/sds.c中。Redis 3.2之后引入了多种SDS类型以节省内存，但核心思想一致。我们以最基本的SDS结构为例：\n代码片段（sds.h）：\n1 2 3 4 5 6 7 typedef char *sds; struct sdshdr { unsigned int len; // 已使用长度 unsigned int free; // 未使用长度 char buf[]; // 实际存储数据的柔性数组 }; len：记录字符串的实际长度，避免遍历。 free：记录剩余可用空间，支持动态扩展。 buf：存储字符串内容，紧跟结构体。 硬核点：SDS的内存布局是连续的，sds指针直接指向buf，而通过指针偏移可以访问sdshdr。\nMermaid内存布局图：\nclassDiagram class SDS { -len: uint -free: uint -buf: char[] } note for SDS \u0026amp;#34;sds指针指向buf起始地址\u0026amp;#34; 4. SDS的核心操作解析 4.1 创建SDS（sdsnew()） 代码片段（sds.c）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 sds sdsnew(const char *init) { size_t initlen = (init == NULL) ? 0 : strlen(init); return sdsnewlen(init, initlen); } sds sdsnewlen(const void …","date":1709305285,"description":"","fuzzywordcount":1600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"2bef963b56986303b9ba671e88e841f9","publishdate":1709305285,"relpermalink":"/posts/redis/redis2/","section":"posts","summary":"\u003ch3 id=\"第二篇核心数据结构之sdssimple-dynamic-string\"\u003e第二篇：核心数据结构之SDS（Simple Dynamic String）\u003c/h3\u003e\n\u003ch4 id=\"1-引言\"\u003e1. 引言\u003c/h4\u003e\n\u003cp\u003eRedis没有直接使用C语言的标准字符串（以\u003ccode\u003e\\0\u003c/code\u003e结尾的字符数组），而是自定义了SDS（Simple Dynamic String）。SDS是Redis的基础数据结构之一，广泛用于键值存储、命令参数等场景。本篇将深入剖析SDS的实现原理、优势以及源码细节。\u003c/p\u003e","tags":["源码","redis"],"title":"Redis 源码硬核解析系列专题 - 第二篇：核心数据结构之SDS（Simple Dynamic String）","url":"https://yinlongfei.com/posts/redis/redis2/","wordcount":1579},{"categories":"posts","content":"第一篇：Redis源码入门与整体架构 1. 引言 Redis作为一个高性能的内存键值数据库，其源码以简洁高效著称。通过解析Redis源码，我们可以深入理解其单线程模型、事件驱动机制以及模块化设计的精髓。本篇将从Redis的源码目录结构入手，剖析其整体架构，并聚焦启动流程和事件循环的核心实现。\n2. Redis源码目录结构解析 Redis的源码位于GitHub仓库（假设你在2025年3月29日获取的是最新版本），主要目录结构如下：\nsrc/: 核心源代码，包括服务器实现、数据结构、网络处理等。 deps/: 依赖库，如jemalloc（内存分配）、lua（脚本支持）。 tests/: 测试用例。 utils/: 工具脚本，如生成集群配置。 硬核点：src/目录下的server.c是Redis服务器的入口文件，包含main()函数，是我们解析的起点。\n3. 主函数入口与启动流程 Redis的启动始于server.c中的main()函数。以下是其简化流程：\n初始化服务器配置：加载默认配置并解析命令行参数。 初始化全局状态：设置全局变量（如server.clients链表）。 启动事件循环：调用aeMain()进入主循环。 代码片段（server.c中的main()）：\n1 2 3 4 5 6 7 int main(int argc, char **argv) { initServerConfig(); // 初始化配置 if (argc \u0026amp;gt;= 2) loadServerConfig(argv[1], NULL); // 加载配置文件 initServer(); // 初始化服务器状态 aeMain(server.el); // 启动事件循环 return 0; } 硬核解析：\ninitServerConfig()：设置默认端口（6379）、最大客户端数等。 initServer()：创建事件循环对象（server.el）、绑定信号处理、初始化数据库。 aeMain()：进入事件循环，处理I/O和定时任务。 Mermaid流程图（启动流程）：\ngraph TD A[\u0026amp;#34;main()\u0026amp;#34;] --\u0026amp;gt; B[\u0026amp;#34;initServerConfig()\u0026amp;#34;] B --\u0026amp;gt; C[\u0026amp;#34;loadServerConfig()\u0026amp;#34;] C …","date":1709305285,"description":"","fuzzywordcount":1500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c7e7e3899b225b338ac9d8328ed6c973","publishdate":1709305285,"relpermalink":"/posts/redis/redis1/","section":"posts","summary":"\u003ch3 id=\"第一篇redis源码入门与整体架构\"\u003e第一篇：Redis源码入门与整体架构\u003c/h3\u003e\n\u003ch4 id=\"1-引言\"\u003e1. 引言\u003c/h4\u003e\n\u003cp\u003eRedis作为一个高性能的内存键值数据库，其源码以简洁高效著称。通过解析Redis源码，我们可以深入理解其单线程模型、事件驱动机制以及模块化设计的精髓。本篇将从Redis的源码目录结构入手，剖析其整体架构，并聚焦启动流程和事件循环的核心实现。\u003c/p\u003e","tags":["源码","redis"],"title":"Redis 源码硬核解析系列专题 - 第一篇：Redis源码入门与整体架构","url":"https://yinlongfei.com/posts/redis/redis1/","wordcount":1458},{"categories":"posts","content":"2.1 前言 在上一篇文章中，我们已经完成了 SOLR 的源码环境搭建，成功运行了一个简单的实例，并初步浏览了源码目录结构。现在，我们将目光转向 SOLR 的整体架构，探索它如何将复杂的功能组织成一个高效的搜索系统。通过本篇，你将了解 SOLR 的核心组件是如何协作的，请求是如何从客户端到达服务器并返回结果的，以及源码中哪些关键类扮演了重要角色。这不仅是后续深入分析的基础，也是理解 SOLR 设计思想的起点。\nSOLR 的架构设计兼顾了性能、扩展性和易用性。无论是单机部署还是分布式环境（SolrCloud），其核心思想都围绕着“高效索引”和“快速查询”展开。本文将从高层视图逐步深入到源码细节，带你一窥 SOLR 的全貌。\n2.2 SOLR 的整体架构 2.2.1 高层视图 SOLR 的架构可以分为三个主要层次：\n客户端层：通过 HTTP 请求（通常是 RESTful API）与 SOLR 交互，支持多种语言（如 Java 的 SolrJ、Python 的 pysolr 等）。 服务端层：SOLR 的核心运行时，包括嵌入式 Jetty 服务器、请求分发逻辑和核心组件。 存储层：基于 Lucene 的索引文件系统，负责持久化数据。 从功能上看，SOLR 的架构可以用下图简要表示（文字描述替代图形）：\n客户端请求（HTTP） → SolrDispatchFilter（请求入口） → CoreContainer（核心容器） → SolrCore（具体核心） → Lucene（索引与搜索） 2.2.2 核心概念解析 在深入源码之前，我们需要理解 SOLR 中的几个关键概念，它们贯穿整个架构：\nCore：一个独立的核心，包含自己的索引、配置（solrconfig.xml 和 schema.xml）和数据。通常用于单机模式。 Collection：分布式环境下的逻辑概念，一个 Collection 可以分布在多个节点上，包含多个 Shard。 Shard：Collection 的分片，每个 Shard 是一个独立的索引单元。 Replica：Shard 的副本，用于高可用性和负载均衡。 SolrCloud：SOLR 的分布式模式，通过 ZooKeeper 管理集群状态。 这些概念在源码中以类和数据结构的形式体现，后文会逐一分析。\n2.2.3 单机 vs 分布式 单机模式： …","date":1709218885,"description":"","fuzzywordcount":2600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"0b799c50100d4e0e3147923ee24282fb","publishdate":1709218885,"relpermalink":"/posts/solr/solr2/","section":"posts","summary":"\u003ch3 id=\"21-前言\"\u003e\u003cstrong\u003e2.1 前言\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e在上一篇文章中，我们已经完成了 SOLR 的源码环境搭建，成功运行了一个简单的实例，并初步浏览了源码目录结构。现在，我们将目光转向 SOLR 的整体架构，探索它如何将复杂的功能组织成一个高效的搜索系统。通过本篇，你将了解 SOLR 的核心组件是如何协作的，请求是如何从客户端到达服务器并返回结果的，以及源码中哪些关键类扮演了重要角色。这不仅是后续深入分析的基础，也是理解 SOLR 设计思想的起点。\u003c/p\u003e","tags":["Solr"],"title":"SOLR深度源码系列解读专栏（二）：SOLR 的架构总览","url":"https://yinlongfei.com/posts/solr/solr2/","wordcount":2541},{"categories":"posts","content":"前言：为什么解析Redis源码？ Redis 作为一个高性能的内存数据库，其源码简洁高效，值得深入学习。 目标读者：对C语言、数据结构、操作系统有一定基础，想深入理解Redis底层实现的开发者。 学习收获：掌握Redis核心数据结构、内存管理、网络模型等关键技术的实现细节。 第一篇：Redis源码入门与整体架构 内容要点： Redis源码的目录结构解析（src/、deps/等）。 主函数入口（main()在server.c中）及启动流程。 Redis服务器的核心模块概览：事件循环、客户端管理、数据库实现。 硬核解析： 从ae.c事件循环入手，理解Redis单线程模型的底层逻辑。 配置文件加载与初始化过程（config.c）。 代码片段示例： 主事件循环aeMain()的实现。 第二篇：核心数据结构之SDS（Simple Dynamic String） 内容要点： 为什么不用C标准字符串？SDS的优势（安全性、性能）。 SDS的结构体定义（sds.h）。 内存分配与释放策略。 硬核解析： SDS的创建（sdsnew()）、扩展（sdscat()）和释放（sdsfree()）源码。 空间预分配和惰性释放的实现细节。 代码片段示例： struct sdshdr结构体的字段解析。 第三篇：核心数据结构之字典（Dict） 内容要点： Redis字典的用途（键值存储、数据库核心）。 哈希表结构（dict.h）与渐进式rehash机制。 硬核解析： 哈希冲突解决（链地址法）与扩容缩容逻辑。 dictAdd()、dictFind()的实现细节。 rehash的触发条件与逐步迁移过程。 代码片段示例： dict.c中_dictRehashStep()的单步rehash实现。 第四篇：核心数据结构之跳表（Skip List） 内容要点： 跳表在Redis中的应用场景（有序集合ZSET）。 跳表的定义与特性（server.h中的zskiplist）。 硬核解析： 跳表节点插入（zslInsert()）与删除（zslDelete()）的实现。 随机层高生成算法（zslRandomLevel()）。 时间复杂度分析与性能优化。 代码片段示例： 跳表前进指针的更新逻辑。 第五篇：事件驱动模型与网络层 内容要点： Redis的事件循环框架（ae.c）。 I/O多路复用的实 …","date":1709132485,"description":"","fuzzywordcount":1500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"56ee333895b6399fc2a57de1b9a93184","publishdate":1709132485,"relpermalink":"/posts/redis/redistoc/","section":"posts","summary":"\u003ch4 id=\"前言为什么解析redis源码\"\u003e前言：为什么解析Redis源码？\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eRedis 作为一个高性能的内存数据库，其源码简洁高效，值得深入学习。\u003c/li\u003e\n\u003cli\u003e目标读者：对C语言、数据结构、操作系统有一定基础，想深入理解Redis底层实现的开发者。\u003c/li\u003e\n\u003cli\u003e学习收获：掌握Redis核心数据结构、内存管理、网络模型等关键技术的实现细节。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"第一篇redis源码入门与整体架构\"\u003e第一篇：Redis源码入门与整体架构\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e内容要点\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003eRedis源码的目录结构解析（\u003ccode\u003esrc/\u003c/code\u003e、\u003ccode\u003edeps/\u003c/code\u003e等）。\u003c/li\u003e\n\u003cli\u003e主函数入口（\u003ccode\u003emain()\u003c/code\u003e在\u003ccode\u003eserver.c\u003c/code\u003e中）及启动流程。\u003c/li\u003e\n\u003cli\u003eRedis服务器的核心模块概览：事件循环、客户端管理、数据库实现。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e硬核解析\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e从\u003ccode\u003eae.c\u003c/code\u003e事件循环入手，理解Redis单线程模型的底层逻辑。\u003c/li\u003e\n\u003cli\u003e配置文件加载与初始化过程（\u003ccode\u003econfig.c\u003c/code\u003e）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代码片段示例\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e主事件循环\u003ccode\u003eaeMain()\u003c/code\u003e的实现。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"第二篇核心数据结构之sdssimple-dynamic-string\"\u003e第二篇：核心数据结构之SDS（Simple Dynamic String）\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e内容要点\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e为什么不用C标准字符串？SDS的优势（安全性、性能）。\u003c/li\u003e\n\u003cli\u003eSDS的结构体定义（\u003ccode\u003esds.h\u003c/code\u003e）。\u003c/li\u003e\n\u003cli\u003e内存分配与释放策略。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e硬核解析\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003eSDS的创建（\u003ccode\u003esdsnew()\u003c/code\u003e）、扩展（\u003ccode\u003esdscat()\u003c/code\u003e）和释放（\u003ccode\u003esdsfree()\u003c/code\u003e）源码。\u003c/li\u003e\n\u003cli\u003e空间预分配和惰性释放的实现细节。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代码片段示例\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003estruct sdshdr\u003c/code\u003e结构体的字段解析。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"第三篇核心数据结构之字典dict\"\u003e第三篇：核心数据结构之字典（Dict）\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e内容要点\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003eRedis字典的用途（键值存储、数据库核心）。\u003c/li\u003e\n\u003cli\u003e哈希表结构（\u003ccode\u003edict.h\u003c/code\u003e）与渐进式rehash机制。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e硬核解析\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e哈希冲突解决（链地址法）与扩容缩容逻辑。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edictAdd()\u003c/code\u003e、\u003ccode\u003edictFind()\u003c/code\u003e的实现细节。\u003c/li\u003e\n\u003cli\u003erehash的触发条件与逐步迁移过程。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代码片段示例\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edict.c\u003c/code\u003e中\u003ccode\u003e_dictRehashStep()\u003c/code\u003e的单步rehash实现。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"第四篇核心数据结构之跳表skip-list\"\u003e第四篇：核心数据结构之跳表（Skip List）\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e内容要点\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e跳表在Redis中的应用场景（有序集合ZSET）。\u003c/li\u003e\n\u003cli\u003e跳表的定义与特性（\u003ccode\u003eserver.h\u003c/code\u003e中的\u003ccode\u003ezskiplist\u003c/code\u003e）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e硬核解析\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e跳表节点插入（\u003ccode\u003ezslInsert()\u003c/code\u003e）与删除（\u003ccode\u003ezslDelete()\u003c/code\u003e）的实现。\u003c/li\u003e\n\u003cli\u003e随机层高生成算法（\u003ccode\u003ezslRandomLevel()\u003c/code\u003e）。\u003c/li\u003e\n\u003cli\u003e时间复杂度分析与性能优化。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e代码片段示例\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e跳表前进指针的更新逻辑。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"第五篇事件驱动模型与网络层\"\u003e第五篇：事件驱动模型与 …\u003c/h4\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ul\u003e","tags":["源码","redis"],"title":"Redis 源码硬核解析系列专题","url":"https://yinlongfei.com/posts/redis/redistoc/","wordcount":1466},{"categories":"posts","content":"1.1 SOLR 是什么？ Apache SOLR 是一个基于 Apache Lucene 的高性能开源搜索平台。它不仅继承了 Lucene 强大的全文搜索能力，还通过封装和扩展，提供了企业级的功能，比如分布式搜索（SolrCloud）、RESTful API、动态 Schema 管理等。自 2004 年由 CNET 工程师 Yonik Seeley 首次开发并于 2006 年捐献给 Apache 基金会以来，SOLR 已广泛应用于电商、日志分析、内容管理等领域。\n从本质上看，SOLR 是 Lucene 的“服务化”版本。Lucene 提供了底层的索引和搜索能力，而 SOLR 在其之上增加了配置管理、HTTP 接口、集群支持等特性，使其更易于部署和使用。\n核心功能概览 索引管理：支持动态添加、更新、删除文档。 查询能力：丰富的查询语法，包括模糊搜索、范围查询、分面搜索等。 高可用性：通过 SolrCloud 实现分布式部署和故障转移。 扩展性：支持插件机制，允许用户自定义功能。 1.2 为什么要阅读 SOLR 源码？ 理解原理：掌握 SOLR 的内部机制，比如查询如何优化、索引如何高效存储。 定制开发：通过源码定制功能，满足特定业务需求。 问题排查：快速定位性能瓶颈或 Bug。 学习设计：借鉴 SOLR 的架构设计思想，提升自身技术能力。 通过源码，我们可以回答诸如“为什么查询慢？”、“分布式环境下数据一致性如何保证？”等问题，而这些答案往往隐藏在代码的细节中。\n1.3 获取 SOLR 源码 SOLR 的源码托管在 Apache 的 Git 仓库中。最新稳定版本可能有所更新，但我们以 9.x 系列为例（假设 9.4 为当前稳定版）。以下是获取源码的步骤：\n步骤 1：克隆源码 1 2 git clone https://gitbox.apache.org/repos/asf/lucene-solr.git cd lucene-solr 这会下载完整的 Lucene 和 SOLR 项目（它们共享一个仓库）。 如果只关心 SOLR，可以专注于 solr/ 目录。 步骤 2：切换到指定版本（可选） 查看可用版本：\n1 git tag 切换到 9.4（示例）：\n1 git checkout tags/solr-9.4.0 步骤 3：安装依赖 SOLR 使用 Java 开发，推 …","date":1709132485,"description":"","fuzzywordcount":2200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"d178ca71f7c16c5b756180ff9e2f318d","publishdate":1709132485,"relpermalink":"/posts/solr/solr1/","section":"posts","summary":"\u003ch3 id=\"11-solr-是什么\"\u003e\u003cstrong\u003e1.1 SOLR 是什么？\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eApache SOLR 是一个基于 Apache Lucene 的高性能开源搜索平台。它不仅继承了 Lucene 强大的全文搜索能力，还通过封装和扩展，提供了企业级的功能，比如分布式搜索（SolrCloud）、RESTful API、动态 Schema 管理等。自 2004 年由 CNET 工程师 Yonik Seeley 首次开发并于 2006 年捐献给 Apache 基金会以来，SOLR 已广泛应用于电商、日志分析、内容管理等领域。\u003c/p\u003e","tags":["Solr"],"title":"SOLR深度源码系列解读专栏（一）：SOLR 简介与源码环境搭建","url":"https://yinlongfei.com/posts/solr/solr1/","wordcount":2142},{"categories":"posts","content":"SOLR深度源码系列解读专栏 专栏简介 Apache SOLR 是一个基于 Lucene 的开源搜索平台，以其高性能、分布式能力和丰富的功能而著称。本专栏旨在通过阅读和剖析 SOLR 的源码，深入理解其架构设计、核心组件以及实现细节，帮助开发者掌握 SOLR 的内部机制，提升定制化开发和问题排查能力。专栏将结合实际代码片段、运行流程分析和实践案例，逐步揭开 SOLR 的“神秘面纱”。\n目标读者 对 SOLR 感兴趣的初学者，希望快速入门并理解其原理。 中高级开发者，计划深入定制 SOLR 或优化其性能。 搜索技术爱好者，想从源码层面理解一个工业级搜索系统的实现。 专栏大纲 以下是专栏的初步规划，每篇作为一个独立章节，循序渐进展开。\n第1篇：SOLR 简介与源码环境搭建 内容： SOLR 的历史与定位：从 Lucene 到 SOLR 的演变。 SOLR 的核心功能：索引、查询、高亮、分片等。 源码下载与编译：如何获取最新 SOLR 源码并搭建调试环境。 源码目录结构概览：快速定位关键模块。 目标：让读者建立对 SOLR 的初步认知并准备好开发环境。 示例：编译并运行一个简单的 SOLR 实例，查看启动日志。 第2篇：SOLR 的架构总览 内容： SOLR 的整体架构：客户端、服务器、核心组件的关系。 关键概念解析：Core、Collection、Shard、Replica。 请求处理流程：从 HTTP 请求到响应的高层视图。 源码入口：SolrDispatchFilter 和 HttpSolrCall 的作用。 目标：理解 SOLR 的宏观设计，建立源码阅读的全局视角。 示例：跟踪一个查询请求的生命周期。 第3篇：索引构建与更新机制 内容： 索引的核心类：IndexWriter 和 SolrIndexWriter。 Document 的添加与更新流程：从客户端提交到 Lucene 索引。 事务日志与提交策略：softCommit vs hardCommit。 源码分析：UpdateHandler 和 DirectUpdateHandler2。 目标：掌握 SOLR 如何高效构建和管理索引。 示例：通过代码调试跟踪一个文档的索引过程。 第4篇：查询解析与执行 内容： 查询的生命周期：从 Query String 到结果返回。 查询解析器：QueryParser …","date":1709046085,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"a32a83da5f762116d165c9da1f818823","publishdate":1709046085,"relpermalink":"/posts/solr/solrtoc/","section":"posts","summary":"\u003ch3 id=\"solr深度源码系列解读专栏\"\u003e\u003cstrong\u003eSOLR深度源码系列解读专栏\u003c/strong\u003e\u003c/h3\u003e\n\u003ch4 id=\"专栏简介\"\u003e\u003cstrong\u003e专栏简介\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eApache SOLR 是一个基于 Lucene 的开源搜索平台，以其高性能、分布式能力和丰富的功能而著称。本专栏旨在通过阅读和剖析 SOLR 的源码，深入理解其架构设计、核心组件以及实现细节，帮助开发者掌握 SOLR 的内部机制，提升定制化开发和问题排查能力。专栏将结合实际代码片段、运行流程分析和实践案例，逐步揭开 SOLR 的“神秘面纱”。\u003c/p\u003e","tags":["Solr"],"title":"SOLR深度源码系列解读专栏","url":"https://yinlongfei.com/posts/solr/solrtoc/","wordcount":1750},{"categories":"posts","content":"Spring Batch 专题系列目录 Spring Batch 简介与核心概念 介绍 Spring Batch 的背景、用途和核心概念（Job、Step、Chunk、ItemReader、ItemProcessor、ItemWriter 等）。 使用 Mermaid 绘制 Spring Batch 的基本架构图。 快速入门：构建第一个 Spring Batch 作业 搭建 Spring Batch 环境，创建一个简单的批处理作业。 使用 Mermaid 绘制作业流程图。 Spring Batch 的核心组件详解 深入讲解 Job、Step、Tasklet、Chunk 模型，以及 ItemReader、ItemProcessor、ItemWriter 的实现。 使用 Mermaid 展示 Chunk 模型的处理流程。 配置与调度 Spring Batch 作业 讲解 Spring Batch 的配置方式（XML 和 Java 配置），以及如何通过 Spring Scheduler 或外部调度器触发作业。 使用 Mermaid 绘制调度流程图。 错误处理与重试机制 介绍 Spring Batch 的错误处理、跳过（Skip）、重试（Retry）和重启（Restart）机制。 使用 Mermaid 展示错误处理流程。 并行处理与性能优化 讲解多线程 Step、分区（Partitioning）、并行 Job 和性能调优技巧。 使用 Mermaid 绘制分区架构图。 Spring Batch 与数据库集成 演示如何使用 Spring Batch 处理数据库读写（JDBC、JPA、MyBatis）。 使用 Mermaid 展示数据库交互流程。 Spring Batch 高级主题：扩展与定制 自定义 Reader、Processor、Writer，监听器（Listener）、作业参数传递等。 使用 Mermaid 绘制自定义组件的调用链。 Spring Batch 在生产环境中的最佳实践 部署、监控、日志记录、作业管理、容器化（Docker）等。 使用 Mermaid 绘制生产环境架构图。 Spring Batch 与 Spring Boot 和 Spring Cloud 集成 结合 Spring Boot 简化开发，集成 Spring Cloud Data Flow 实现分布 …","date":1709046085,"description":"","fuzzywordcount":700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"1d1dc66d809a39b6da0491dc7e8fb01f","publishdate":1709046085,"relpermalink":"/posts/spring/spring-batch/springbatchtoc/","section":"posts","summary":"\u003ch2 id=\"spring-batch-专题系列目录\"\u003eSpring Batch 专题系列目录\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eSpring Batch 简介与核心概念\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e介绍 Spring Batch 的背景、用途和核心概念（Job、Step、Chunk、ItemReader、ItemProcessor、ItemWriter 等）。\u003c/li\u003e\n\u003cli\u003e使用 Mermaid 绘制 Spring Batch 的基本架构图。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e\u003cstrong\u003e快速入门：构建第一个 Spring Batch 作业\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e搭建 Spring Batch 环境，创建一个简单的批处理作业。\u003c/li\u003e\n\u003cli\u003e使用 Mermaid 绘制作业流程图。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e\u003cstrong\u003eSpring Batch 的核心组件详解\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e深入讲解 Job、Step、Tasklet、Chunk 模型，以及 ItemReader、ItemProcessor、ItemWriter 的实现。\u003c/li\u003e\n\u003cli\u003e使用 Mermaid 展示 Chunk 模型的处理流程。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003e\u003cstrong\u003e配置与调度 Spring Batch 作业\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e讲解 Spring Batch 的配置方式（XML 和 Java 配置），以及如何通过 Spring Scheduler 或外部调度器触发作业。\u003c/li\u003e\n\u003cli\u003e使用 Mermaid 绘制调度流程图。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"5\"\u003e\n\u003cli\u003e\u003cstrong\u003e错误处理与重试机制\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e介绍 Spring Batch 的错误处理、跳过（Skip）、重试（Retry）和重启（Restart）机制。\u003c/li\u003e\n\u003cli\u003e使用 Mermaid 展示错误处理流程。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"6\"\u003e\n\u003cli\u003e\u003cstrong\u003e并行处理与性能优化\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e讲解多线程 Step、分区（Partitioning）、并行 Job 和性能调优技巧。\u003c/li\u003e\n\u003cli\u003e使用 Mermaid 绘制分区架构图。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"7\"\u003e\n\u003cli\u003e\u003cstrong\u003eSpring Batch 与数据库集成\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e演示如何使用 Spring Batch 处理数据库读写（JDBC、JPA、MyBatis）。\u003c/li\u003e\n\u003cli\u003e使用 Mermaid 展示数据库交互流程。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"8\"\u003e\n\u003cli\u003e\u003cstrong\u003eSpring Batch 高级主题：扩展与定制\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e自定义 Reader、Processor、Writer，监听器（Listener）、作业参数传递等。\u003c/li\u003e\n\u003cli\u003e使用 Mermaid 绘制自定义组件的调用链。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"9\"\u003e\n\u003cli\u003e\u003cstrong\u003eSpring Batch 在生产环境中的最佳实践\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e部署、监控、日志记录、作业管理、容器化（Docker）等。\u003c/li\u003e\n\u003cli\u003e使用 Mermaid 绘制生产环境架构图。\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"10\"\u003e\n\u003cli\u003e\u003cstrong\u003eSpring Batch 与 Spring Boot 和 Spring Cloud 集成\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e结合 Spring …\u003c/li\u003e\u003c/ul\u003e","tags":["Spring","Spring Batch"],"title":"Spring Batch 专题系列目录","url":"https://yinlongfei.com/posts/spring/spring-batch/springbatchtoc/","wordcount":652},{"categories":"posts","content":"Lucene作为信息检索领域的基石，经过二十多年的发展，依然是许多搜索系统（如Elasticsearch、Solr）的核心。然而，随着数据规模的增长和搜索需求的多样化，Lucene也面临新的挑战。本篇将回顾其演进，剖析现存局限性，并探讨未来的可能性。\n一、Lucene的版本演进与新特性 Lucene的每一次版本迭代都带来了性能提升和新功能，以下是几个关键里程碑：\nLucene 2.x（2006） 引入分段机制和IndexWriter，奠定现代架构基础。 Lucene 4.x（2012） 添加DocValues，优化字段数据访问。 支持插件化Codec，提升存储灵活性。 Lucene 7.x（2017） 默认采用BM25替代TF-IDF，提升相关性。 优化倒排索引压缩（如ForUtil）。 Lucene 9.x（2021至今） 引入向量字段（KnnVectorField），初步支持向量搜索。 增强多线程性能，优化IndexSearcher。 新特性亮点 向量搜索：9.0引入的KnnVectorField允许存储高维向量，支持K近邻（KNN）查询，为语义搜索铺路。 性能优化：Lucene90Codec进一步压缩存储，减少I/O开销。 二、局限性：挑战与瓶颈 尽管Lucene功能强大，但在现代场景下仍有一些局限性。\n分布式支持的缺失\n现状：Lucene是单机库，分布式能力依赖上层封装（如Elasticsearch）。 问题：无法原生处理跨节点索引和查询，限制了其在大规模集群中的直接应用。 影响：开发者需自行实现分片和同步逻辑。 实时性挑战\n现状：分段机制和合并开销导致索引更新有延迟（Near-Real-Time需手动刷新）。 问题：在高频写入场景下（如日志系统），无法做到毫秒级实时。 对比：Elasticsearch通过refresh_interval缓解，但本质仍受Lucene限制。 复杂查询的性能瓶颈\n现状：通配符、模糊查询等依赖词典遍历，计算开销高。 问题：在大索引下，响应时间可能显著增加。 解决方向：需依赖外部缓存或预计算。 向量搜索的初级阶段\n现状：当前仅支持HNSW（层次导航小世界）算法，功能有限。 问题：无法与专用向量数据库（如Faiss、Annoy）竞争。 三、社区动态的兴趣点 Lucene由Apache社区维护，活跃度较高，近期动态聚焦于性能。\n社区趋 …","date":1644155094,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"d81dcee73e57c6c8ed2d95a79511cbc6","publishdate":1644155094,"relpermalink":"/posts/luence/lucene6/","section":"posts","summary":"\u003cp\u003eLucene作为信息检索领域的基石，经过二十多年的发展，依然是许多搜索系统（如Elasticsearch、Solr）的核心。然而，随着数据规模的增长和搜索需求的多样化，Lucene也面临新的挑战。本篇将回顾其演进，剖析现存局限性，并探讨未来的可能性。\u003c/p\u003e","tags":["Lucene","Analyzer","Similarity","分词","分词器","TokenFilter"],"title":"Lucene硬核解析专题系列（六）：Lucene的未来与局限性","url":"https://yinlongfei.com/posts/luence/lucene6/","wordcount":1634},{"categories":"posts","content":"Lucene作为一个灵活的信息检索库，提供了丰富的扩展点，允许开发者根据需求定制功能。本篇将深入剖析如何自定义Analyzer和Similarity，并通过一个小型搜索应用的实战案例，展示Lucene的实际应用能力。\n一、自定义Analyzer：分词器与TokenFilter的实现 Analyzer是Lucene处理文本的核心组件，负责将原始文本转化为可索引的词项（Term）。\n默认Analyzer StandardAnalyzer：支持基本分词、停用词过滤和小写转换。 示例：输入“Lucene is Awesome!” → 输出：[lucene, awesome] 自定义Analyzer 假设我们需要一个支持中文分词并过滤特定词的Analyzer。\n实现步骤\n分词器（Tokenizer）：使用中文分词库（如IKAnalyzer或jieba的Java实现）。 过滤器（TokenFilter）：添加自定义逻辑。 代码示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import org.apache.lucene.analysis.Analyzer; import org.apache.lucene.analysis.TokenStream; import org.apache.lucene.analysis.Tokenizer; import org.apache.lucene.analysis.core.LowerCaseFilter; import org.apache.lucene.analysis.standard.StandardTokenizer; public class CustomChineseAnalyzer extends Analyzer { @Override protected TokenStreamComponents createComponents(String fieldName) { // 使用StandardTokenizer作为基础（可替换为中文分词器） Tokenizer tokenizer = new StandardTokenizer(); // 添加小写 …","date":1644068694,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"9d21bc524f62a9083af9b9d67ff2bf1c","publishdate":1644068694,"relpermalink":"/posts/luence/lucene5/","section":"posts","summary":"\u003cp\u003eLucene作为一个灵活的信息检索库，提供了丰富的扩展点，允许开发者根据需求定制功能。本篇将深入剖析如何自定义\u003ccode\u003eAnalyzer\u003c/code\u003e和\u003ccode\u003eSimilarity\u003c/code\u003e，并通过一个小型搜索应用的实战案例，展示Lucene的实际应用能力。\u003c/p\u003e","tags":["Lucene","Analyzer","Similarity","分词","分词器","TokenFilter"],"title":"Lucene硬核解析专题系列（五）：Lucene的扩展与实战","url":"https://yinlongfei.com/posts/luence/lucene5/","wordcount":1673},{"categories":"posts","content":"Lucene的高效性不仅源于其底层数据结构和算法，还得益于在实际应用中对性能的精心优化。本篇将从索引合并、内存管理、多线程搜索等方面，揭示Lucene如何应对高负载场景，并提供调优思路，帮助开发者充分发挥其潜力。\n一、索引合并（Merge Policy）与性能权衡 Lucene的索引由多个分段组成，随着数据写入，分段数量增加会导致查询性能下降。索引合并是将小分段合并为大分段的过程，由MergePolicy控制。\n合并的必要性 查询效率：分段越多，查询时需要遍历的倒排索引越多，性能下降。 资源占用：小分段占用更多文件句柄和内存。 默认策略：TieredMergePolicy 工作原理： 将分段按大小分层（Tier）。 优先合并同一层内的小分段。 参数： maxMergeAtOnce：一次最多合并的分段数（默认10）。 segmentsPerTier：每层分段数（默认10）。 优点：平衡了合并频率和资源消耗。 代价：合并期间会占用额外磁盘空间和I/O。 调优建议 增大缓冲区 通过IndexWriterConfig.setRAMBufferSizeMB增加内存缓冲区（默认16MB），减少频繁刷新生成的小分段。 示例：config.setRAMBufferSizeMB(64)。 调整合并阈值 增大maxMergedSegmentMB（默认5GB），减少大分段合并频率。 异步合并 使用ConcurrentMergeScheduler，在后台并行合并，避免阻塞写入。 硬核点：合并算法剖析 TieredMergePolicy的合并选择基于成本函数：\n成本公式：考虑分段大小、文档数和删除比例。 优化目标：最小化I/O和CPU开销，同时保持分段数量可控。 二、内存管理：FieldCache与DocValues的对比 Lucene在查询和排序时需要访问字段数据，内存管理直接影响性能。\nFieldCache 用途：早期用于存储未索引但需排序的字段（如数值、日期）。 实现：将字段值加载到内存，构建反向映射（DocID → Value）。 缺点： 初始化开销大，尤其在字段值多时。 不支持动态更新，索引变更后需重建。 DocValues 用途：替代FieldCache，提供列式存储。 实现： 在索引时预计算，存储为磁盘上的列式数据。 支持数值、字符串等多种类型。 优点： 按需加载，减少内存占 …","date":1643982294,"description":"","fuzzywordcount":2200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"379c254156ab9616da69a9a3842536bf","publishdate":1643982294,"relpermalink":"/posts/luence/lucene4/","section":"posts","summary":"\u003cp\u003eLucene的高效性不仅源于其底层数据结构和算法，还得益于在实际应用中对性能的精心优化。本篇将从索引合并、内存管理、多线程搜索等方面，揭示Lucene如何应对高负载场景，并提供调优思路，帮助开发者充分发挥其潜力。\u003c/p\u003e","tags":["调优","优化"],"title":"Lucene硬核解析专题系列（四）：性能优化与调优","url":"https://yinlongfei.com/posts/luence/lucene4/","wordcount":2167},{"categories":"posts","content":"Lucene的索引构建为高效搜索奠定了基础，而查询解析与执行则是将用户意图转化为实际结果的关键环节。本篇将从查询的解析开始，逐步深入到查询类型、评分模型和执行流程，揭示Lucene搜索能力的底层原理。\n一、查询语法与QueryParser的工作原理 Lucene的查询过程始于用户输入的搜索字符串，例如“人工智能 AND 机器学习”。这一字符串需要被解析为Lucene能够理解的结构化对象。\nQueryParser的作用 QueryParser是Lucene提供的查询解析器，负责将文本查询转化为Query对象。\n输入：用户输入的查询字符串。 输出：一个Query对象（如BooleanQuery、TermQuery）。 解析流程 分词\n使用与索引时相同的Analyzer，将查询字符串分解为词项。例如：\n输入：“人工智能 AND 机器学习” 分词后：[\u0026amp;quot;人工智能\u0026amp;quot;, \u0026amp;quot;AND\u0026amp;quot;, \u0026amp;quot;机器学习\u0026amp;quot;] 语法分析\n识别操作符：如AND、OR、NOT。 处理特殊语法：如+(必须)、-(排除)、*(通配符)。 示例：\u0026amp;quot;人工智能 AND 机器学习\u0026amp;quot;解析为\u0026amp;quot;人工智能\u0026amp;quot;和\u0026amp;quot;机器学习\u0026amp;quot;的AND组合。 构建Query树\n将词项和操作符组织为树状结构：\nBooleanQuery 子节点1：TermQuery(\u0026amp;quot;人工智能\u0026amp;quot;) 子节点2：TermQuery(\u0026amp;quot;机器学习\u0026amp;quot;) 连接符：MUST 代码示例 1 2 3 QueryParser parser = new QueryParser(\u0026amp;#34;content\u0026amp;#34;, new StandardAnalyzer()); Query query = parser.parse(\u0026amp;#34;人工智能 AND 机器学习\u0026amp;#34;); System.out.println(query); // 输出：content:人工智能 content:机器学习 二、查询类型剖析 Lucene支持多种查询类型，每种类型针对不同的搜索需求。\nTermQuery\n用途：精确匹配单个词项。 示例：TermQuery(term=\u0026amp;quot;lucene\u0026amp;quot;)查找包含“lucene”的文档。 实现：直接在倒排索引中查找 …","date":1643895894,"description":"","fuzzywordcount":2100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"bc14feac3aaf58e7e57ddedf10cb61f2","publishdate":1643895894,"relpermalink":"/posts/luence/lucene3/","section":"posts","summary":"\u003cp\u003eLucene的索引构建为高效搜索奠定了基础，而查询解析与执行则是将用户意图转化为实际结果的关键环节。本篇将从查询的解析开始，逐步深入到查询类型、评分模型和执行流程，揭示Lucene搜索能力的底层原理。\u003c/p\u003e","tags":["Lucene","Document","Field","Query"],"title":"Lucene硬核解析专题系列（三）：查询解析与执行","url":"https://yinlongfei.com/posts/luence/lucene3/","wordcount":2093},{"categories":"posts","content":"Lucene的高效搜索能力源于其精心设计的索引构建过程。上一篇文章介绍了Lucene的核心概念和倒排索引的基本结构，这一篇将带你深入索引创建的底层实现，从文档输入到磁盘存储的全流程，剖析分段机制和压缩技术的奥秘。\n一、索引写入流程：从Document到IndexWriter Lucene的索引构建始于将数据转化为可搜索的结构。这一过程由IndexWriter驱动，它是索引创建的核心类。\n流程概览 输入文档\n用户创建一个Document对象，包含若干Field。例如：\n1 2 3 Document doc = new Document(); doc.add(new TextField(\u0026amp;#34;title\u0026amp;#34;, \u0026amp;#34;Lucene in Action\u0026amp;#34;, Store.YES)); doc.add(new TextField(\u0026amp;#34;content\u0026amp;#34;, \u0026amp;#34;A book about search\u0026amp;#34;, Store.NO)); 写入索引\n通过IndexWriter将文档添加到索引：\n1 2 3 IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(analyzer)); writer.addDocument(doc); writer.close(); 这里，directory指定索引存储路径（如磁盘或内存），analyzer负责分词。\n分词与分析\nAnalyzer对每个字段的内容进行处理，生成词项（Term）。例如，“Lucene in Action”可能被分解为：\n\u0026amp;quot;lucene\u0026amp;quot; \u0026amp;quot;in\u0026amp;quot; \u0026amp;quot;action\u0026amp;quot; 构建倒排索引\n分词后的词项被组织成倒排索引，写入临时缓冲区，最终持久化到磁盘。\n关键角色：IndexWriter 缓冲区管理：IndexWriter维护一个内存缓冲区（默认16MB），暂存文档数据。 提交与刷新：调用commit()将缓冲区数据写入磁盘，生成一个新分段。 二、分段（Segment）机制：为什么这么设计？ Lucene的索引不是一个单一文件，而是由多个独立的分段组成。每个分段是一个完整的倒排索引，可以独立查询。\n分段的生命周期 创建：当内存缓冲区满或调用flush() …","date":1643809494,"description":"","fuzzywordcount":2100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"36cdbc3c2ea213b657f4b01dce042e60","publishdate":1643809494,"relpermalink":"/posts/luence/lucene2/","section":"posts","summary":"\u003cp\u003eLucene的高效搜索能力源于其精心设计的索引构建过程。上一篇文章介绍了Lucene的核心概念和倒排索引的基本结构，这一篇将带你深入索引创建的底层实现，从文档输入到磁盘存储的全流程，剖析分段机制和压缩技术的奥秘。\u003c/p\u003e","tags":["Lucene","倒排索引","索引","Document","Field","Query"],"title":"Lucene硬核解析专题系列（二）：索引构建的底层实现","url":"https://yinlongfei.com/posts/luence/lucene2/","wordcount":2008},{"categories":"posts","content":"Lucene是一个强大的开源信息检索库，广泛应用于搜索引擎、数据分析和文本处理领域。作为Elasticsearch和Solr的核心引擎，Lucene以其高效的索引和查询能力闻名。本篇将带你走进Lucene的世界，探索它的基本原理和核心组件，为后续深入剖析奠定基础。\n一、Lucene简介 Lucene诞生于1999年，由Doug Cutting开发，后来捐赠给了Apache软件基金会。它不是一个开箱即用的搜索引擎，而是一个底层库，提供了构建搜索功能的工具。它的定位类似于数据库中的存储引擎，专注于高效的文本索引和检索。\n核心能力： 全文搜索：支持复杂的查询语法。 高性能：得益于倒排索引和优化的存储结构。 灵活性：可定制分词、评分和存储策略。 应用场景：从简单的本地文件搜索，到支撑分布式搜索引擎的底层。 相比其他工具，Lucene更像一把“瑞士军刀”，需要开发者手动组装，但也因此赋予了极高的自由度。\n二、核心组件概览 Lucene的架构围绕几个关键概念展开，它们是理解其工作原理的基石。\n索引（Index）\n索引是Lucene存储和検索数据的核心结构，类似于书的目录。它包含所有可搜索的内容，通常存储在磁盘上。Lucene的索引是分段（Segment）组织的，每个段是一个独立的可查询单元。\n文档（Document）\n文档是索引的基本单位，相当于数据库中的一行数据。它由多个字段组成，每个字段存储特定类型的内容（如标题、正文、时间戳）。\n字段（Field）\n字段是文档的组成部分，可以看作键值对。字段有不同的属性，比如是否需要索引、是否存储原始值、是否分词等。例如，一个博客文章可能有“标题”和“内容”两个字段。\n查询（Query）\n查询是用户搜索意图的表达。Lucene支持多种查询类型，如精确匹配（TermQuery）、多条件组合（BooleanQuery）和短语搜索（PhraseQuery）。\n这些组件共同构成了Lucene的基本模型：数据以文档形式输入，经过处理存入索引，最终通过查询检索。\n三、基本工作流程 Lucene的核心功能可以概括为三个步骤：\n索引构建 输入：一系列文档（例如网页、PDF）。 过程：对文档内容分词（Tokenization），提取关键词（Term），构建倒排索引。 输出：存储在磁盘上的索引文件。 查询解析 输入：用户输入的搜索词（如“人工智能”）。 过 …","date":1643723094,"description":"","fuzzywordcount":1900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"658c157f96cb4fd8062902eb57cbcf40","publishdate":1643723094,"relpermalink":"/posts/luence/lucene1/","section":"posts","summary":"\u003cp\u003eLucene是一个强大的开源信息检索库，广泛应用于搜索引擎、数据分析和文本处理领域。作为Elasticsearch和Solr的核心引擎，Lucene以其高效的索引和查询能力闻名。本篇将带你走进Lucene的世界，探索它的基本原理和核心组件，为后续深入剖析奠定基础。\u003c/p\u003e","tags":["Lucene","倒排索引","Index","Document","Field","Query"],"title":"Lucene硬核解析专题系列（一）：Lucene入门与核心概念","url":"https://yinlongfei.com/posts/luence/lucene1/","wordcount":1838},{"categories":"posts","content":"Lucene硬核解析专题系列框架 第一篇：Lucene入门与核心概念 目标：为读者奠定基础，理解Lucene是什么以及它的核心功能。 内容： Lucene简介：历史、定位（信息检索库而非完整搜索引擎）。 核心组件概览：索引（Index）、文档（Document）、字段（Field）、查询（Query）。 基本工作流程：索引构建 -\u0026amp;gt; 查询解析 -\u0026amp;gt; 结果排序。 与其他工具的关系（如Elasticsearch、Solr）。 硬核点：剖析Lucene的倒排索引（Inverted Index）基本结构。 第二篇：索引构建的底层实现 目标：深入Lucene索引的创建过程，揭示其高效性的秘密。 内容： 索引写入流程：从Document到IndexWriter。 分段（Segment）机制：为什么Lucene使用分段存储？ 倒排索引的构造：Term、Posting List与压缩技术。 文件格式解析：.cfs、.si等文件的用途。 硬核点：代码级分析Lucene90Codec中的存储优化。 第三篇：查询解析与执行 目标：探索Lucene如何将用户查询转化为高效的搜索操作。 内容： 查询语法与QueryParser的工作原理。 查询类型剖析：TermQuery、BooleanQuery、PhraseQuery等。 评分机制：TF-IDF与BM25的实现细节。 查询执行流程：从Searcher到TopDocs。 硬核点：手算一个BM25评分示例，展示Lucene的数学内核。 第四篇：性能优化与调优 目标：揭示Lucene在高并发、高吞吐场景下的优化策略。 内容： 索引合并（Merge Policy）与性能权衡。 内存管理：FieldCache与DocValues的对比。 多线程搜索：IndexSearcher的线程安全设计。 常见瓶颈与解决方案：I/O、CPU、内存。 硬核点：剖析TieredMergePolicy的合并算法。 第五篇：Lucene的扩展与实战 目标：从理论到实践，展示Lucene的灵活性与应用。 内容： 自定义Analyzer：分词器与TokenFilter的实现。 插件机制：如何扩展Similarity或Codec。 实战案例：构建一个小型搜索应用。 Lucene生态：与Elasticsearch的源码对比。 硬核点：手写一个自定 …","date":1643291094,"description":"","fuzzywordcount":1100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"6f08113ffe58ecce892d6612d08f2929","publishdate":1643291094,"relpermalink":"/posts/luence/lucenetoc/","section":"posts","summary":"\u003ch3 id=\"lucene硬核解析专题系列框架\"\u003eLucene硬核解析专题系列框架\u003c/h3\u003e\n\u003ch4 id=\"第一篇lucene入门与核心概念\"\u003e第一篇：Lucene入门与核心概念\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e目标\u003c/strong\u003e：为读者奠定基础，理解Lucene是什么以及它的核心功能。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e内容\u003c/strong\u003e：\n\u003col\u003e\n\u003cli\u003eLucene简介：历史、定位（信息检索库而非完整搜索引擎）。\u003c/li\u003e\n\u003cli\u003e核心组件概览：索引（Index）、文档（Document）、字段（Field）、查询（Query）。\u003c/li\u003e\n\u003cli\u003e基本工作流程：索引构建 -\u0026gt; 查询解析 -\u0026gt; 结果排序。\u003c/li\u003e\n\u003cli\u003e与其他工具的关系（如Elasticsearch、Solr）。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e硬核点\u003c/strong\u003e：剖析Lucene的倒排索引（Inverted Index）基本结构。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"第二篇索引构建的底层实现\"\u003e第二篇：索引构建的底层实现\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e目标\u003c/strong\u003e：深入Lucene索引的创建过程，揭示其高效性的秘密。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e内容\u003c/strong\u003e：\n\u003col\u003e\n\u003cli\u003e索引写入流程：从Document到IndexWriter。\u003c/li\u003e\n\u003cli\u003e分段（Segment）机制：为什么Lucene使用分段存储？\u003c/li\u003e\n\u003cli\u003e倒排索引的构造：Term、Posting List与压缩技术。\u003c/li\u003e\n\u003cli\u003e文件格式解析：\u003ccode\u003e.cfs\u003c/code\u003e、\u003ccode\u003e.si\u003c/code\u003e等文件的用途。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e硬核点\u003c/strong\u003e：代码级分析\u003ccode\u003eLucene90Codec\u003c/code\u003e中的存储优化。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"第三篇查询解析与执行\"\u003e第三篇：查询解析与执行\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e目标\u003c/strong\u003e：探索Lucene如何将用户查询转化为高效的搜索操作。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e内容\u003c/strong\u003e：\n\u003col\u003e\n\u003cli\u003e查询语法与QueryParser的工作原理。\u003c/li\u003e\n\u003cli\u003e查询类型剖析：TermQuery、BooleanQuery、PhraseQuery等。\u003c/li\u003e\n\u003cli\u003e评分机制：TF-IDF与BM25的实现细节。\u003c/li\u003e\n\u003cli\u003e查询执行流程：从Searcher到TopDocs。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e硬核点\u003c/strong\u003e：手算一个BM25评分示例，展示Lucene的数学内核。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"第四篇性能优化与调优\"\u003e第四篇：性能优化与调优\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e目标\u003c/strong\u003e：揭示Lucene在高并发、高吞吐场景下的优化策略。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e内容\u003c/strong\u003e：\n\u003col\u003e\n\u003cli\u003e索引合并（Merge Policy）与性能权衡。\u003c/li\u003e\n\u003cli\u003e内存管理：FieldCache与DocValues的对比。\u003c/li\u003e\n\u003cli\u003e多线程搜索：IndexSearcher的线程安全设计。\u003c/li\u003e\n\u003cli\u003e常见瓶颈与解决方案：I/O、CPU、内存。\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e硬核点\u003c/strong\u003e：剖析\u003ccode\u003eTieredMergePolicy\u003c/code\u003e的合并算法。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"第五篇lucene的扩展与实战\"\u003e第五篇：Lucene的扩展与实战\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e目标\u003c/strong\u003e：从理论到实践，展示Lucene的灵活性与应用。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e内容\u003c/strong\u003e：\n\u003col\u003e\n\u003cli\u003e自定义Analyzer：分词器与TokenFilter的实现。\u003c/li\u003e\n\u003cli\u003e插件机制：如何扩展Similarity或Codec。\u003c/li\u003e\n\u003cli\u003e实战案例：构建一个小型搜索应用。\u003c/li\u003e\n\u003cli\u003eLucene生态：与Elasticsearch的源码对 …\u003c/li\u003e\u003c/ol\u003e\u003c/li\u003e\u003c/ul\u003e","tags":["Lucene","Analyzer","Index","Document","Field","Query"],"title":"Lucene硬核解析专题系列框架","url":"https://yinlongfei.com/posts/luence/lucenetoc/","wordcount":1063},{"categories":"posts","content":"系列专题：通用系统批量比对工具设计（第六篇：部署与测试） 一、目标 部署：实现单机和分布式环境下的部署，确保高可用性与动态扩展。 测试：验证亿级数据处理性能（≤ 4分钟，目标 ≤ 2分钟），分布式调度功能和人性化体验。 稳定性：确保系统在高负载和故障场景下的可靠性。 二、部署方案 单机部署（Docker Compose）\n适用场景：开发、测试或中小规模生产环境。 架构： 微服务：任务管理、数据加载、比对、结果生成。 组件：PostgreSQL、Kafka、Hazelcast、MinIO。 配置文件（docker-compose.yml）： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 version: \u0026amp;#39;3.8\u0026amp;#39; services: task-manager: image: task-manager:latest ports: - \u0026amp;#34;8080:8080\u0026amp;#34; environment: - SPRING_DATASOURCE_URL=jdbc:postgresql://postgresql:5432/compare_db - KAFKA_BOOTSTRAP_SERVERS=kafka:9092 depends_on: - postgresql - kafka data-loader: image: data-loader:latest environment: - KAFKA_BOOTSTRAP_SERVERS=kafka:9092 depends_on: - kafka compare-engine: image: compare-engine:latest environment: - KAFKA_BOOTSTRAP_SERVERS=kafka:9092 depends_on: - kafka result-generator: image: result-generator:latest environment: - …","date":1617330420,"description":"","fuzzywordcount":2100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"63a35477fb1980b27fbb2e0bff00aaa2","publishdate":1617330420,"relpermalink":"/posts/compare-system-design/compare-tools6/","section":"posts","summary":"\u003ch3 id=\"系列专题通用系统批量比对工具设计第六篇部署与测试\"\u003e系列专题：通用系统批量比对工具设计（第六篇：部署与测试）\u003c/h3\u003e\n\u003ch4 id=\"一目标\"\u003e一、目标\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e部署\u003c/strong\u003e：实现单机和分布式环境下的部署，确保高可用性与动态扩展。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e测试\u003c/strong\u003e：验证亿级数据处理性能（≤ 4分钟，目标 ≤ 2分钟），分布式调度功能和人性化体验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e稳定性\u003c/strong\u003e：确保系统在高负载和故障场景下的可靠性。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"二部署方案\"\u003e二、部署方案\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e单机部署（Docker Compose）\u003c/strong\u003e\u003c/p\u003e","tags":["比对工具","通用设计","技术实现"],"title":"通用系统批量比对工具设计（第六篇：部署与测试）","url":"https://yinlongfei.com/posts/compare-system-design/compare-tools6/","wordcount":2046},{"categories":"posts","content":"系列专题：通用系统批量比对工具设计（第五篇：扩展与优化） 一、目标 扩展性：支持新增数据源（如MongoDB）、新转换/比对规则及自研系统接入。 性能优化：亿级数据单表处理 ≤ 2分钟，吞吐量 ≥ 50万条/秒。 分布式部署：确保高可用性与动态扩展能力。 用户体验：优化人性化设计（如更精准的进度反馈）。 二、扩展设计 新增数据源支持\n扩展方式：通过实现SmartDataLoader接口添加新数据源。 示例：MongoDB支持 实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Service public class MongoDataLoader implements SmartDataLoader { @Autowired private MongoClient mongoClient; @Override public Stream\u0026amp;lt;Record\u0026amp;gt; loadData(DataSourceConfig config) { MongoDatabase db = mongoClient.getDatabase(config.getDatabase()); MongoCollection\u0026amp;lt;Document\u0026amp;gt; collection = db.getCollection(config.getCollection()); return StreamSupport.stream(collection.find().spliterator(), false) .map(doc -\u0026amp;gt; new Record(doc)); } @Override public Stream\u0026amp;lt;Record\u0026amp;gt; transform(Stream\u0026amp;lt;Record\u0026amp;gt; data, TransformRule rule) { KieSession session = kieContainer.newKieSession(); session.insert(rule); return data.map(record -\u0026amp;gt; { session.insert(record); session.fireAllRules(); return record; }); } } 配置： …","date":1617244020,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"ebb52ef1e34e9ae3c58febe5fad149b3","publishdate":1617244020,"relpermalink":"/posts/compare-system-design/compare-tools5/","section":"posts","summary":"\u003ch3 id=\"系列专题通用系统批量比对工具设计第五篇扩展与优化\"\u003e系列专题：通用系统批量比对工具设计（第五篇：扩展与优化）\u003c/h3\u003e\n\u003ch4 id=\"一目标\"\u003e一、目标\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e扩展性\u003c/strong\u003e：支持新增数据源（如MongoDB）、新转换/比对规则及自研系统接入。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e性能优化\u003c/strong\u003e：亿级数据单表处理 ≤ 2分钟，吞吐量 ≥ 50万条/秒。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e分布式部署\u003c/strong\u003e：确保高可用性与动态扩展能力。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e用户体验\u003c/strong\u003e：优化人性化设计（如更精准的进度反馈）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"二扩展设计\"\u003e二、扩展设计\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e新增数据源支持\u003c/strong\u003e\u003c/p\u003e","tags":["比对工具","通用设计","技术实现"],"title":"通用系统批量比对工具设计（第五篇：扩展与优化）","url":"https://yinlongfei.com/posts/compare-system-design/compare-tools5/","wordcount":1724},{"categories":"posts","content":"系列专题：通用系统批量比对工具设计（第四篇：模块设计与实现） 一、设计目标 高性能：亿级数据单表处理 ≤ 4分钟（目标 ≤ 2分钟）。 智能转换：支持XML、TXT等数据源及动态规则。 分布式调度：支持自研系统接入与任务分发。 可视化规则管理：支持编辑、权限和版本控制。 模块化：易扩展，支持新数据源和规则。 二、核心模块设计 数据加载与转换模块（Smart Data Loader）\n功能： 从多种数据源加载数据（DB、CSV、Excel、JSON、XML、TXT、API）。 执行智能转换（字段映射、清洗、类型转换）。 技术：Spring Boot + Drools（规则引擎）+ Jackson（JSON/XML）+ Netty（API）。 实现： 流式加载：使用Stream处理大数据。 动态规则：Drools解析JSON配置。 XML支持：XPATH解析嵌套结构。 TXT支持：正则表达式或分隔符解析。 代码示例： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 public interface SmartDataLoader { Stream\u0026amp;lt;Record\u0026amp;gt; loadData(DataSourceConfig config) throws Exception; Stream\u0026amp;lt;Record\u0026amp;gt; transform(Stream\u0026amp;lt;Record\u0026amp;gt; data, TransformRule rule); } @Service public class FileDataLoader implements SmartDataLoader { @Autowired private KieContainer kieContainer; // Drools规则容器 @Override public Stream\u0026amp;lt;Record\u0026amp;gt; loadData(DataSourceConfig config) throws Exception { String type = …","date":1617157620,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"bfb3b56d4d0caea00a605eaba17005fc","publishdate":1617157620,"relpermalink":"/posts/compare-system-design/compare-tools4/","section":"posts","summary":"\u003ch3 id=\"系列专题通用系统批量比对工具设计第四篇模块设计与实现\"\u003e系列专题：通用系统批量比对工具设计（第四篇：模块设计与实现）\u003c/h3\u003e\n\u003ch4 id=\"一设计目标\"\u003e一、设计目标\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e高性能\u003c/strong\u003e：亿级数据单表处理 ≤ 4分钟（目标 ≤ 2分钟）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e智能转换\u003c/strong\u003e：支持XML、TXT等数据源及动态规则。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e分布式调度\u003c/strong\u003e：支持自研系统接入与任务分发。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可视化规则管理\u003c/strong\u003e：支持编辑、权限和版本控制。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e模块化\u003c/strong\u003e：易扩展，支持新数据源和规则。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"二核心模块设计\"\u003e二、核心模块设计\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e数据加载与转换模块（Smart Data Loader）\u003c/strong\u003e\u003c/p\u003e","tags":["比对工具","通用设计","技术实现"],"title":"通用系统批量比对工具设计（第四篇：模块设计与实现）","url":"https://yinlongfei.com/posts/compare-system-design/compare-tools4/","wordcount":1731},{"categories":"posts","content":"系列专题：通用系统批量比对工具设计（第三篇：系统架构设计） 一、架构设计目标 高性能：单表亿级数据处理 ≤ 4分钟（目标 ≤ 2分钟），吞吐量 ≥ 50万条/秒。 大数据支持：流式处理、分片与分布式计算。 智能转换：动态规则解析与字段映射。 分布式能力：支持任务调度与节点协作。 人性化体验：实时反馈、进度可视化与超长时间提醒。 二、总体架构图 使用Mermaid绘制系统架构图如下：\ngraph TD A[用户界面\u0026amp;lt;br\u0026amp;gt;Web UI / API] --\u0026amp;gt;|任务提交| B[任务调度层\u0026amp;lt;br\u0026amp;gt;Distributed Scheduler] A --\u0026amp;gt;|实时反馈| L[通知服务\u0026amp;lt;br\u0026amp;gt;WebSocket / Email] B --\u0026amp;gt;|任务分发| C[任务管理服务\u0026amp;lt;br\u0026amp;gt;Task Manager] C --\u0026amp;gt;|REST调用| D[数据加载服务\u0026amp;lt;br\u0026amp;gt;Smart Data Loader] C --\u0026amp;gt;|REST调用| E[比对服务\u0026amp;lt;br\u0026amp;gt;Compare Engine] C --\u0026amp;gt;|REST调用| F[结果服务\u0026amp;lt;br\u0026amp;gt;Result Generator] D --\u0026amp;gt;|数据读取| G[数据源\u0026amp;lt;br\u0026amp;gt;DB / File / API] D --\u0026amp;gt;|转换规则| H[规则引擎\u0026amp;lt;br\u0026amp;gt;Drools] E --\u0026amp;gt;|分片处理| I[批量处理层\u0026amp;lt;br\u0026amp;gt;Spring Batch / Flow] I --\u0026amp;gt;|分布式协作| J[消息队列\u0026amp;lt;br\u0026amp;gt;Kafka] J --\u0026amp;gt;|任务分配| K[计算节点\u0026amp;lt;br\u0026amp;gt;Hazelcast] E --\u0026amp;gt;|标签管理| M[标签服务\u0026amp;lt;br\u0026amp;gt;Tag Manager] F --\u0026amp;gt;|存储与分析| N[存储层\u0026amp;lt;br\u0026amp;gt;PostgreSQL / Elasticsearch / MinIO] F --\u0026amp;gt;|输出| O[结果输出\u0026amp;lt;br\u0026amp;gt;HTML / Excel / Charts] L --\u0026amp;gt;|进度更新| A 三、架构模块详解 用户界面层（Web UI / API）\n功能： Web UI：提供任务配置界面（数据源选择、转换规则编辑）、进 …","date":1617071220,"description":"","fuzzywordcount":2800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c6daee6eeb4273f1cd40cf05c71309b5","publishdate":1617071220,"relpermalink":"/posts/compare-system-design/compare-tools3/","section":"posts","summary":"\u003ch3 id=\"系列专题通用系统批量比对工具设计第三篇系统架构设计\"\u003e系列专题：通用系统批量比对工具设计（第三篇：系统架构设计）\u003c/h3\u003e\n\u003ch4 id=\"一架构设计目标\"\u003e一、架构设计目标\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e高性能\u003c/strong\u003e：单表亿级数据处理 ≤ 4分钟（目标 ≤ 2分钟），吞吐量 ≥ 50万条/秒。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e大数据支持\u003c/strong\u003e：流式处理、分片与分布式计算。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e智能转换\u003c/strong\u003e：动态规则解析与字段映射。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e分布式能力\u003c/strong\u003e：支持任务调度与节点协作。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e人性化体验\u003c/strong\u003e：实时反馈、进度可视化与超长时间提醒。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"二总体架构图\"\u003e二、总体架构图\u003c/h4\u003e\n\u003cp\u003e使用Mermaid绘制系统架构图如下：\u003c/p\u003e","tags":["比对工具","通用设计","架构设计"],"title":"通用系统批量比对工具设计（第三篇：系统架构设计）","url":"https://yinlongfei.com/posts/compare-system-design/compare-tools3/","wordcount":2782},{"categories":"posts","content":"系列专题：通用系统批量比对工具设计（第二篇：技术选型与JHipster集成） 一、技术选型目标 根据第一篇的需求，技术选型需满足以下关键点：\n高性能：亿级数据单表处理 ≤ 4分钟（目标 ≤ 2分钟），吞吐量 ≥ 50万条/秒。 大数据支持：流式处理、分片与分布式计算。 智能转换：支持动态规则解析与字段映射。 分布式调度：集成现有框架或自研调度器。 人性化体验：实时反馈与任务管理。 快速开发：利用JHipster加速开发，减少重复工作。 二、技术栈选择 后端框架\nSpring Boot（JHipster核心） 理由：企业级开发标准，生态丰富，支持异步、批处理和微服务。 作用：提供RESTful API、依赖注入和配置管理。 Spring Batch 理由：内置分片与并行处理，适合亿级数据批量任务。 作用：实现数据分片、流式读取与写入。 Spring Data Flow 理由：支持流式处理和分布式任务编排。 作用：处理超大数据量时的流式比对。 前端框架\nAngular（JHipster默认） 理由：前后端分离，组件化开发，易于扩展UI。 作用：提供可视化配置界面和实时进度展示。 WebSocket 理由：支持服务器到客户端的实时推送。 作用：任务进度更新与超长时间提醒。 Chart.js 理由：轻量级图表库，易集成。 作用：可视化统计指标（如匹配率饼图）。 数据库与存储\nPostgreSQL 理由：开源，支持分区表和高并发查询。 作用：存储元数据、标签和比对结果。 Elasticsearch 理由：分布式搜索与聚合分析，适合大数据统计。 作用：快速生成统计指标和差异查询。 MinIO 理由：分布式对象存储，支持大文件。 作用：存储输入文件和结果报告。 分布式与高性能组件\nApache Kafka 理由：高吞吐量消息队列，支持分布式任务分发。 作用：任务调度与节点间通信。 Hazelcast 理由：分布式缓存与锁，轻量级且嵌入式。 作用：任务状态同步与热点数据缓存。 Disruptor 理由：高性能内存队列，单线程吞吐量极高。 作用：异步处理比对结果生成。 Netty 理由：异步I/O框架，适合高并发API调用。 作用：从外部API高效加载数据。 分布式调度\nXXL-JOB 理由：轻量级，开箱即用，支持分片任务。 作用：快速集成分布式调度。 Elastic-Job 理由： …","date":1616984820,"description":"","fuzzywordcount":2100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"85458fbc82537c3709b9e5f020d088ef","publishdate":1616984820,"relpermalink":"/posts/compare-system-design/compare-tools2/","section":"posts","summary":"\u003ch3 id=\"系列专题通用系统批量比对工具设计第二篇技术选型与jhipster集成\"\u003e系列专题：通用系统批量比对工具设计（第二篇：技术选型与JHipster集成）\u003c/h3\u003e\n\u003ch4 id=\"一技术选型目标\"\u003e一、技术选型目标\u003c/h4\u003e\n\u003cp\u003e根据第一篇的需求，技术选型需满足以下关键点：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e高性能\u003c/strong\u003e：亿级数据单表处理 ≤ 4分钟（目标 ≤ 2分钟），吞吐量 ≥ 50万条/秒。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e大数据支持\u003c/strong\u003e：流式处理、分片与分布式计算。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e智能转换\u003c/strong\u003e：支持动态规则解析与字段映射。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e分布式调度\u003c/strong\u003e：集成现有框架或自研调度器。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e人性化体验\u003c/strong\u003e：实时反馈与任务管理。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e快速开发\u003c/strong\u003e：利用JHipster加速开发，减少重复工作。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"二技术栈选择\"\u003e二、技术栈选择\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e后端框架\u003c/strong\u003e\u003c/p\u003e","tags":["比对工具","通用设计","技术选型"],"title":"通用系统批量比对工具设计（第二篇：技术选型与JHipster集成）","url":"https://yinlongfei.com/posts/compare-system-design/compare-tools2/","wordcount":2064},{"categories":"posts","content":"系列专题：通用系统批量比对工具设计（第一篇：需求分析与功能规划） 一、设计目标 设计一个通用的批量比对工具，支持多种数据源的智能输入与转换，能够处理无限大数据量（亿级数据单表处理时间不超过4分钟，目标2分钟以内），提供差异化结果、统计指标和人性化体验，同时具备高性能和分布式调度能力。目标是满足企业级数据比对场景，如数据迁移验证、数据一致性检查等。\n二、核心功能需求 数据输入与智能转换\n支持的数据源： 数据库：MySQL、PostgreSQL、Oracle等。 文件：CSV、Excel、JSON等。 API：RESTful或其他协议的外部数据接口。 任意组合：用户可自由选择任意两种数据源进行比对（如数据库 vs 文件、文件 vs API）。 智能转换： 可视化配置字段映射（如“source.id”映射到“target.userId”）。 支持数据清洗与类型转换（如字符串转整数、日期格式统一）。 提供规则模板和自定义规则编辑（如JSON或DSL格式）。 标签标记系统\n功能：对数据记录动态添加标签，用于标记特定状态或异常。 实现： 支持手动标签（如用户手动标记“异常”）。 支持自动标签规则（如“差异率\u0026amp;gt;10%标记为待核查”）。 标签可批量应用并持久化存储。 差异化结果与统计指标\n差异化结果： 识别新增、删除、修改的记录。 支持差异高亮显示（如字段级差异）。 统计指标： 匹配率（相同记录占比）。 差异率（差异记录占比）。 数据总量、处理时间等。 输出格式：HTML、Excel、PDF，包含可视化图表（如饼图、柱状图）。 无限大数据量支持\n性能目标：单表亿级数据（1亿条记录，假设每条记录约1KB），单次处理不超过4分钟，优选目标2分钟以内。 实现方式： 支持流式处理，避免全量加载到内存。 数据分片与并行处理。 分布式计算支持。 人性化设计\n超长时间等待提醒：任务运行超过5分钟，实时通知用户（WebSocket推送或邮件）。 任务进度可视化：前端显示实时进度条或百分比。 任务管理：支持任务暂停、中断与恢复。 用户体验：提供直观的Web界面和API两种操作方式。 高性能与分布式调度\n高性能要求： 单节点亿级数据处理 ≤ 4分钟（优选 ≤ 2分钟）。 假设硬件环境：16核CPU，64GB内存，100MB/s磁盘I/O。 分布式调度： 支持现有框 …","date":1616898420,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"f8ccbb1826ea4fed0af701b56b8ae4c4","publishdate":1616898420,"relpermalink":"/posts/compare-system-design/compare-tools1/","section":"posts","summary":"\u003ch3 id=\"系列专题通用系统批量比对工具设计第一篇需求分析与功能规划\"\u003e系列专题：通用系统批量比对工具设计（第一篇：需求分析与功能规划）\u003c/h3\u003e\n\u003ch4 id=\"一设计目标\"\u003e一、设计目标\u003c/h4\u003e\n\u003cp\u003e设计一个通用的批量比对工具，支持多种数据源的智能输入与转换，能够处理无限大数据量（亿级数据单表处理时间不超过4分钟，目标2分钟以内），提供差异化结果、统计指标和人性化体验，同时具备高性能和分布式调度能力。目标是满足企业级数据比对场景，如数据迁移验证、数据一致性检查等。\u003c/p\u003e","tags":["比对工具","通用设计","分析"],"title":"通用系统批量比对工具设计（第一篇：需求分析与功能规划）","url":"https://yinlongfei.com/posts/compare-system-design/compare-tools1/","wordcount":1757},{"categories":"posts","content":"技术专家的核心在于将知识应用于实战，解决复杂问题。本篇将从项目架构设计、高并发系统实现、问题排查到优化案例，系统讲解如何在实际项目中运用Java技术，助你在面试中展现综合能力和经验深度。\n1. 项目架构设计 良好的架构是项目成功的基石。\n分层设计\n表现层: 处理用户请求（如Spring MVC）。 业务层: 核心逻辑（Service）。 数据层: 数据库交互（DAO/Repository）。 模块化\n按功能拆分（如用户模块、订单模块），降低耦合。 示例: 简单分层架构\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // 数据层 @Repository public class UserRepository { public User findById(int id) { // 模拟数据库查询 return new User(id, \u0026amp;#34;User\u0026amp;#34; + id); } } // 业务层 @Service public class UserService { @Autowired private UserRepository userRepository; public User getUser(int id) { return userRepository.findById(id); } } // 表现层 @RestController @RequestMapping(\u0026amp;#34;/api\u0026amp;#34;) public class UserController { @Autowired private UserService userService; @GetMapping(\u0026amp;#34;/user/{id}\u0026amp;#34;) public User getUser(@PathVariable int id) { return userService.getUser(id); } } class User { private int id; private String name; // 构造器、getter、setter } 面试问题:\n问题: 如何设计一个可扩展的架构？ 答案: 使用分层设计，按业务模块化， …","date":1616812020,"description":"","fuzzywordcount":1600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"bf9cbf79cb4b0d450a42cf86169582fe","publishdate":1616812020,"relpermalink":"/posts/java-interview/java_interview8/","section":"posts","summary":"\u003cp\u003e技术专家的核心在于将知识应用于实战，解决复杂问题。本篇将从项目架构设计、高并发系统实现、问题排查到优化案例，系统讲解如何在实际项目中运用Java技术，助你在面试中展现综合能力和经验深度。\u003c/p\u003e","tags":["Java","基础"],"title":"Java技术专家面试专题系列（八）：综合实战与项目经验","url":"https://yinlongfei.com/posts/java-interview/java_interview8/","wordcount":1523},{"categories":"posts","content":"系列专题：通用系统批量比对工具设计 第一部分：需求分析与功能规划 核心功能\n数据输入与智能转换 支持多种数据源：数据库（MySQL、PostgreSQL、Oracle）、文件（CSV、Excel、JSON）、API。 任意选择两种数据源进行比对。 可视化配置转换规则（如字段映射、类型转换、清洗规则）。 标签标记系统 支持对数据记录添加标签（如“异常”、“待核查”）。 标签可动态配置，支持批量标记。 差异化结果与统计指标 生成差异化报告（新增、删除、修改）。 提供统计指标（匹配率、差异率、记录总数等）。 无限大数据量支持 单次单表亿级数据处理，性能目标：不超过4分钟（甚至更高要求，如2分钟内）。 支持流式处理和分片机制。 人性化设计 超长时间任务提醒（WebSocket推送或邮件通知）。 任务进度可视化（实时进度条）。 支持任务中断与恢复。 高性能与分布式调度 单节点亿级数据处理不超过4分钟。 支持分布式调度：集成XXL-JOB、Elastic-Job，或自研调度框架。 非功能性需求\n高性能：亿级数据单表处理 ≤ 4分钟（目标 ≤ 2分钟）。 可扩展性：支持新数据源、新规则、新调度器。 高可用性：分布式环境下任务容错与负载均衡。 第二部分：技术选型与JHipster集成 技术栈调整\n后端 Spring Boot（JHipster核心）。 Spring Batch（批量处理与分片）。 Spring Data Flow（流式处理与分布式任务管理）。 Apache Kafka（分布式消息队列）。 Hazelcast/Redis（分布式缓存与锁）。 前端 Angular（Web界面）。 WebSocket（实时进度推送）。 Chart.js/D3.js（统计指标可视化）。 数据库与存储 PostgreSQL（主数据库，支持分区表）。 Elasticsearch（大数据索引与搜索）。 MinIO（分布式文件存储，存储大文件）。 分布式调度 XXL-JOB（轻量级调度器）。 Elastic-Job（分布式任务调度）。 自研调度（基于Kafka和Spring Boot实现）。 高性能组件 Netty（异步I/O处理API数据）。 Disruptor（高性能队列，内存计算）。 JHipster配置\n应用类型：Microservices（分布式架构）。 数据库：PostgreSQL + …","date":1616812020,"description":"","fuzzywordcount":2600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"3af036e48b4998788bd4da77547abae6","publishdate":1616812020,"relpermalink":"/posts/compare-system-design/toc/","section":"posts","summary":"\u003ch3 id=\"系列专题通用系统批量比对工具设计\"\u003e系列专题：通用系统批量比对工具设计\u003c/h3\u003e\n\u003ch4 id=\"第一部分需求分析与功能规划\"\u003e第一部分：需求分析与功能规划\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e核心功能\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e数据输入与智能转换\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e支持多种数据源：数据库（MySQL、PostgreSQL、Oracle）、文件（CSV、Excel、JSON）、API。\u003c/li\u003e\n\u003cli\u003e任意选择两种数据源进行比对。\u003c/li\u003e\n\u003cli\u003e可视化配置转换规则（如字段映射、类型转换、清洗规则）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e标签标记系统\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e支持对数据记录添加标签（如“异常”、“待核查”）。\u003c/li\u003e\n\u003cli\u003e标签可动态配置，支持批量标记。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e差异化结果与统计指标\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e生成差异化报告（新增、删除、修改）。\u003c/li\u003e\n\u003cli\u003e提供统计指标（匹配率、差异率、记录总数等）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e无限大数据量支持\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e单次单表亿级数据处理，性能目标：不超过4分钟（甚至更高要求，如2分钟内）。\u003c/li\u003e\n\u003cli\u003e支持流式处理和分片机制。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e人性化设计\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e超长时间任务提醒（WebSocket推送或邮件通知）。\u003c/li\u003e\n\u003cli\u003e任务进度可视化（实时进度条）。\u003c/li\u003e\n\u003cli\u003e支持任务中断与恢复。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e高性能与分布式调度\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e单节点亿级数据处理不超过4分钟。\u003c/li\u003e\n\u003cli\u003e支持分布式调度：集成XXL-JOB、Elastic-Job，或自研调度框架。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e非功能性需求\u003c/strong\u003e\u003c/p\u003e","tags":["比对工具","通用设计"],"title":"系列专题：通用系统批量比对工具设计","url":"https://yinlongfei.com/posts/compare-system-design/toc/","wordcount":2559},{"categories":"posts","content":"设计模式和代码优化是Java技术专家的重要技能，直接影响代码的可维护性、可扩展性和性能。本篇将从常用设计模式、SOLID原则到高性能编码实践，系统讲解如何编写优雅高效的代码，助你在面试中展现设计思维和优化能力。\n1. 常用设计模式 设计模式是解决常见问题的模板，以下是几种典型模式。\n单例模式（Singleton）\n确保类只有一个实例。 实现：懒汉式、饿汉式、双重检查锁。 工厂模式（Factory）\n封装对象创建，解耦客户端与具体类。 观察者模式（Observer）\n定义一对多依赖，对象状态变化通知观察者。 示例: 双重检查锁单例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class Singleton { private static volatile Singleton instance; private Singleton() { // 防止反射创建 if (instance != null) { throw new RuntimeException(\u0026amp;#34;Instance already exists\u0026amp;#34;); } } public static Singleton getInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; } public static void main(String[] args) { Singleton s1 = Singleton.getInstance(); Singleton s2 = Singleton.getInstance(); System.out.println(s1 == s2); // 输出: true } } 面试问题:\n问题: 单例模式如何防止多线程问题？ 答案: 使用volatile防止指令重排序，双重检查锁确保线程安全。 2. SOLID原则 SOLID是面向对象设计的五大原则，提升代码质量。\n单一职责（SRP）: 一个类只负责一项职责。 开闭原 …","date":1616639220,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"dfbd6d02a4f9140dafc615a40be5c45e","publishdate":1616639220,"relpermalink":"/posts/java-interview/java_interview7/","section":"posts","summary":"\u003cp\u003e设计模式和代码优化是Java技术专家的重要技能，直接影响代码的可维护性、可扩展性和性能。本篇将从常用设计模式、SOLID原则到高性能编码实践，系统讲解如何编写优雅高效的代码，助你在面试中展现设计思维和优化能力。\u003c/p\u003e","tags":["Java","基础"],"title":"Java技术专家面试专题系列（七）：设计模式与代码优化","url":"https://yinlongfei.com/posts/java-interview/java_interview7/","wordcount":1642},{"categories":"posts","content":"微服务与分布式系统是现代Java开发的趋势，解决传统单体应用的扩展性和维护性问题。本篇将从微服务基础、Spring Cloud核心组件到分布式一致性，系统讲解相关技术，助你在面试中展现架构设计和分布式问题解决能力。\n1. 微服务架构基础 微服务将应用拆分为小型独立服务，围绕业务能力构建。\n核心特性\n独立部署: 每个服务单独运行和更新。 松耦合: 服务间通过API通信（如REST、gRPC）。 技术异构: 可使用不同语言和数据库。 优点与挑战\n优点：高扩展性、易维护。 挑战：分布式复杂性（如一致性、网络延迟）。 面试问题:\n问题: 微服务与单体应用的区别？ 答案: 微服务按业务拆分，独立部署，松耦合；单体应用集中式开发部署，紧耦合，扩展性差。 2. Spring Cloud核心组件 Spring Cloud为微服务提供了丰富的工具集。\n服务注册与发现（Eureka）\n服务注册中心，动态管理服务实例。 负载均衡（Ribbon/Feign）\n客户端负载均衡，优化请求分发。 服务网关（Spring Cloud Gateway）\n统一入口，处理路由、认证等。 熔断与降级（Hystrix/Resilience4j）\n防止服务雪崩。 示例: Eureka服务注册\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 // 服务端配置 (application.yml) spring: application: name: eureka-server eureka: client: register-with-eureka: false fetch-registry: false server: port: 8761 // 服务端主类 @SpringBootApplication @EnableEurekaServer public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); } …","date":1615948020,"description":"","fuzzywordcount":1600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"f06e9c3b5eeff4b5b5696bce054092c7","publishdate":1615948020,"relpermalink":"/posts/java-interview/java_interview6/","section":"posts","summary":"\u003cp\u003e微服务与分布式系统是现代Java开发的趋势，解决传统单体应用的扩展性和维护性问题。本篇将从微服务基础、Spring Cloud核心组件到分布式一致性，系统讲解相关技术，助你在面试中展现架构设计和分布式问题解决能力。\u003c/p\u003e","tags":["Java","SpringCloud","微服务","分布式"],"title":"Java技术专家面试专题系列（六）：微服务与分布式系统","url":"https://yinlongfei.com/posts/java-interview/java_interview6/","wordcount":1520},{"categories":"posts","content":"好的，我将根据规划，撰写Java技术专家面试专题系列的第五篇：“数据库与持久化”。这篇文章将深入探讨Java与数据库交互的核心技术，包括JDBC、ORM框架、SQL优化以及分布式事务等，结合代码示例和面试问题，帮助读者掌握持久化层的原理和实践，为技术专家面试提供全面支持。以下是完整内容：\nJava技术专家面试专题系列（五）：数据库与持久化 数据库与持久化是Java企业级开发的关键环节，涉及数据存储、访问和一致性保障。本篇将从JDBC基础、ORM框架（如MyBatis和Hibernate）、SQL优化到分布式事务，系统讲解Java持久化技术，助你在面试中展现数据库设计与优化的能力。\n1. JDBC基础与连接池 JDBC（Java Database Connectivity）是Java访问关系型数据库的基础。\n核心组件\nDriverManager: 加载数据库驱动。 Connection: 数据库连接。 Statement/PreparedStatement: 执行SQL。 ResultSet: 查询结果。 连接池\n提高连接复用效率，常见实现：HikariCP（高性能）、Druid（监控功能强）。 示例: 使用HikariCP连接数据库\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import com.zaxxer.hikari.HikariConfig; import com.zaxxer.hikari.HikariDataSource; import java.sql.Connection; import java.sql.PreparedStatement; import java.sql.ResultSet; public class JDBCDemo { public static void main(String[] args) throws Exception { HikariConfig config = new HikariConfig(); config.setJdbcUrl(\u0026amp;#34;jdbc:mysql://localhost:3306/test\u0026amp;#34;); config.setUsername(\u0026amp;#34;root\u0026amp;#34;); …","date":1615775220,"description":"","fuzzywordcount":1900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c274136a45b94b44984d4963c81e2704","publishdate":1615775220,"relpermalink":"/posts/java-interview/java_interview5/","section":"posts","summary":"\u003cp\u003e好的，我将根据规划，撰写\u003cstrong\u003eJava技术专家面试专题系列\u003c/strong\u003e的第五篇：\u003cstrong\u003e“数据库与持久化”\u003c/strong\u003e。这篇文章将深入探讨Java与数据库交互的核心技术，包括JDBC、ORM框架、SQL优化以及分布式事务等，结合代码示例和面试问题，帮助读者掌握持久化层的原理和实践，为技术专家面试提供全面支持。以下是完整内容：\u003c/p\u003e","tags":["Java","数据库","持久化"],"title":"Java技术专家面试专题系列（五）：数据库与持久化","url":"https://yinlongfei.com/posts/java-interview/java_interview5/","wordcount":1823},{"categories":"posts","content":"1. 引言 在第二篇中，我们设计了系统的整体架构，明确了JDBC驱动作为客户端入口的角色。本篇将深入探讨JDBC驱动的实现细节，确保其符合SQL ANSI 92标准，支持事务、JSON操作和高性能目标。通过与SQL解析器和内核的集成，展示从SQL输入到结果返回的完整流程。\n2. JDBC驱动的目标与功能 2.1 目标 提供标准的JDBC接口，兼容现有Java数据库工具和框架。 支持轻量化设计，无外部依赖。 集成日志管理器，记录SQL执行和事务操作。 确保高效的SQL执行和事务管理。 2.2 功能 连接管理：通过JDBC URL建立与数据库的连接。 SQL执行：支持DDL、DML和事务语句。 结果处理：返回查询结果集，支持JSON数据类型。 日志记录：记录关键操作到WAL和调试日志。 配置支持：允许切换内存/文件模式。 3. JDBC驱动的核心接口实现 JDBC驱动需要实现java.sql包中的关键接口，以下是主要实现：\n3.1 Driver 接口 作用：注册驱动并处理连接请求。 实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import java.sql.Driver; import java.sql.DriverManager; import java.sql.SQLException; public class LightweightDriver implements Driver { static { try { DriverManager.registerDriver(new LightweightDriver()); } catch (SQLException e) { throw new RuntimeException(\u0026amp;#34;Failed to register LightweightDriver\u0026amp;#34;, e); } } @Override public Connection connect(String url, java.util.Properties info) throws SQLException { if (!acceptsURL(url)) return null; return new …","date":1615560337,"description":"","fuzzywordcount":2e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"a1628e38a43d36c06e474936752de5fb","publishdate":1615560337,"relpermalink":"/posts/database/javadb/javadb-sql-parser/","section":"posts","summary":"\u003ch5 id=\"1-引言\"\u003e1. 引言\u003c/h5\u003e\n\u003cp\u003e在第二篇中，我们设计了系统的整体架构，明确了JDBC驱动作为客户端入口的角色。本篇将深入探讨JDBC驱动的实现细节，确保其符合SQL ANSI 92标准，支持事务、JSON操作和高性能目标。通过与SQL解析器和内核的集成，展示从SQL输入到结果返回的完整流程。\u003c/p\u003e","tags":["数据库","Java","轻量级"],"title":"基于Java的高性能轻量化数据库设计与实现 第三篇：JDBC驱动实现","url":"https://yinlongfei.com/posts/database/javadb/javadb-sql-parser/","wordcount":1927},{"categories":"posts","content":"1. 引言 在前三篇中，我们完成了系统架构设计和JDBC驱动的实现，支持了SQL语句的接收和初步解析。本篇将聚焦执行引擎（execution-engine模块）的实现，细化其设计与功能。执行引擎是数据库的核心组件，负责协调SQL操作的执行，桥接SQL解析器、查询优化器、存储引擎和事务管理器，确保高效完成DDL、DML和事务操作。\n2. 执行引擎的目标与功能 2.1 目标 高效执行SQL语句，支持SQL ANSI 92标准。 协调各模块（如查询优化器、存储引擎），完成复杂查询。 支持事务上下文，确保操作一致性。 优化资源使用，提供并行执行能力。 2.2 功能 DDL执行：处理CREATE TABLE、DROP TABLE等语句。 DML执行：执行INSERT、SELECT、UPDATE、DELETE。 事务支持：管理事务开始、提交和回滚。 计划执行：运行查询优化器生成的执行计划。 3. 执行引擎的核心设计 3.1 数据结构 执行上下文（ExecutionContext）：\n包含事务ID和其他运行时信息。 1 2 3 4 5 6 7 8 9 10 public class ExecutionContext { private final long txId; private final TransactionManager txManager; public ExecutionContext(long txId, TransactionManager txManager) { this.txId = txId; this.txManager = txManager; } // getter } 执行计划（QueryPlan）：\n由查询优化器生成，执行引擎直接运行（参考第六篇）。 3.2 执行模型 操作符模型：将查询分解为操作符（如扫描、过滤、连接）。 流水线执行：支持操作符间的流式处理。 并行执行：使用线程池处理大查询。 3.3 与其他模块的交互 SQL解析器：接收AST。 查询优化器：获取优化后的计划。 存储引擎：执行数据操作。 事务管理器：管理事务状态。 4. 执行引擎实现 以下是ExecutionEngine类的核心实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 …","date":1615473937,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c657bd9e6a1fd87d1cc6a5de47af1900","publishdate":1615473937,"relpermalink":"/posts/database/javadb/javadb-execution-engine/","section":"posts","summary":"\u003ch5 id=\"1-引言\"\u003e1. 引言\u003c/h5\u003e\n\u003cp\u003e在前三篇中，我们完成了系统架构设计和JDBC驱动的实现，支持了SQL语句的接收和初步解析。本篇将聚焦执行引擎（\u003ccode\u003eexecution-engine\u003c/code\u003e模块）的实现，细化其设计与功能。执行引擎是数据库的核心组件，负责协调SQL操作的执行，桥接SQL解析器、查询优化器、存储引擎和事务管理器，确保高效完成DDL、DML和事务操作。\u003c/p\u003e","tags":["数据库","Java","轻量级"],"title":"基于Java的高性能轻量化数据库设计与实现 扩展篇：执行引擎实现","url":"https://yinlongfei.com/posts/database/javadb/javadb-execution-engine/","wordcount":1674},{"categories":"posts","content":"1. 引言 在前六篇中，我们完成了JDBC驱动、存储引擎、事务管理器和查询优化器的实现，支持了SQL执行、数据存储和查询优化。本篇将聚焦元数据管理（metadata-manager模块）的实现，设计表结构、索引和统计信息的存储与访问机制。元数据管理器将为其他模块提供关键信息，支持DDL操作和查询优化。\n2. 元数据管理器的目标与功能 2.1 目标 提供表结构、索引和统计信息的集中管理。 支持SQL ANSI 92标准的DDL操作（如CREATE TABLE）。 为查询优化器提供统计数据，提升执行计划效率。 确保元数据的持久性和一致性。 2.2 功能 表定义：存储表名、列定义和约束。 索引管理：记录主键和二级索引。 统计信息：维护表行数和列选择率。 持久化：支持内存和文件存储模式。 3. 元数据管理器的核心设计 3.1 数据结构 表元数据（TableMetadata）：\n包含表名、列定义和索引信息。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class TableMetadata { private final String tableName; private final List\u0026amp;lt;ColumnDefinition\u0026amp;gt; columns; private final List\u0026amp;lt;String\u0026amp;gt; indexedColumns; private double rowCount; // 统计信息 public TableMetadata(String tableName, List\u0026amp;lt;ColumnDefinition\u0026amp;gt; columns, List\u0026amp;lt;String\u0026amp;gt; indexedColumns) { this.tableName = tableName; this.columns = columns; this.indexedColumns = indexedColumns; this.rowCount = 0; } // getter和setter } 列定义（ColumnDefinition）：\n定义列名、类型和约束。 1 2 3 4 5 6 7 8 9 10 11 12 public class ColumnDefinition { private final String name; …","date":1615387537,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c7d38baa265c341a22bec766523b8a0e","publishdate":1615387537,"relpermalink":"/posts/database/javadb/javadb7/","section":"posts","summary":"\u003ch5 id=\"1-引言\"\u003e1. 引言\u003c/h5\u003e\n\u003cp\u003e在前六篇中，我们完成了JDBC驱动、存储引擎、事务管理器和查询优化器的实现，支持了SQL执行、数据存储和查询优化。本篇将聚焦元数据管理（\u003ccode\u003emetadata-manager\u003c/code\u003e模块）的实现，设计表结构、索引和统计信息的存储与访问机制。元数据管理器将为其他模块提供关键信息，支持DDL操作和查询优化。\u003c/p\u003e","tags":["数据库","Java","轻量级"],"title":"基于Java的高性能轻量化数据库设计与实现 第七篇：元数据管理实现","url":"https://yinlongfei.com/posts/database/javadb/javadb7/","wordcount":1724},{"categories":"posts","content":"1. 引言 在前五篇中，我们完成了JDBC驱动、存储引擎和事务管理器的实现，支持了SQL执行、数据存储和事务一致性。本篇将聚焦查询优化器（query-optimizer模块）的实现，设计基于成本的优化策略，优化SQL查询的执行计划，确保高性能和资源效率。查询优化器将处理复杂查询（如JOIN、子查询），并与执行引擎和存储引擎集成。\n2. 查询优化器的目标与功能 2.1 目标 优化SQL查询的执行计划，减少计算和I/O成本。 支持SQL ANSI 92标准的复杂查询（如JOIN、GROUP BY）。 提供高效的查询性能，超越嵌入式数据库（如H2、SQLite）。 与存储引擎协作，利用索引和统计信息。 2.2 功能 计划生成：生成多种可能的执行计划。 成本估算：基于统计信息评估计划成本。 计划选择：选择最低成本的执行计划。 优化规则：应用谓词下推、JOIN顺序调整等优化。 3. 查询优化器的核心设计 3.1 数据结构 查询计划（QueryPlan）：\n表示执行计划的树形结构。 1 2 3 4 public abstract class QueryPlan { abstract double estimateCost(); abstract List\u0026amp;lt;Map\u0026amp;lt;String, Object\u0026amp;gt;\u0026amp;gt; execute(StorageEngine storage, long txId); } 操作符（Operator）：\n包括扫描（Scan）、过滤（Filter）、连接（Join）等。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class ScanOperator extends QueryPlan { private String tableName; private double rowCount; // 统计信息 public ScanOperator(String tableName, double rowCount) { this.tableName = tableName; this.rowCount = rowCount; } @Override double estimateCost() { return rowCount; } @Override …","date":1615301137,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"f0f028483705a2d67eaf467bad65fa46","publishdate":1615301137,"relpermalink":"/posts/database/javadb/javadb6/","section":"posts","summary":"\u003ch5 id=\"1-引言\"\u003e1. 引言\u003c/h5\u003e\n\u003cp\u003e在前五篇中，我们完成了JDBC驱动、存储引擎和事务管理器的实现，支持了SQL执行、数据存储和事务一致性。本篇将聚焦查询优化器（\u003ccode\u003equery-optimizer\u003c/code\u003e模块）的实现，设计基于成本的优化策略，优化SQL查询的执行计划，确保高性能和资源效率。查询优化器将处理复杂查询（如JOIN、子查询），并与执行引擎和存储引擎集成。\u003c/p\u003e","tags":["数据库","Java","轻量级"],"title":"基于Java的高性能轻量化数据库设计与实现 第六篇：查询优化器实现","url":"https://yinlongfei.com/posts/database/javadb/javadb6/","wordcount":1658},{"categories":"posts","content":"1. 引言 在前四篇中，我们完成了JDBC驱动和存储引擎的实现，支持了SQL执行、数据存储和索引管理。本篇将聚焦事务管理器（transaction-manager模块）的实现，设计MVCC机制，确保事务的隔离性、一致性和持久性。事务管理器将与存储引擎协作管理数据版本，并通过日志管理器记录WAL日志，实现高并发和故障恢复能力。\n2. 事务管理器的目标与功能 2.1 目标 实现ACID事务支持，符合SQL ANSI 92标准。 使用MVCC提供高效的并发控制，避免锁竞争。 确保数据一致性和持久性，与存储引擎和日志管理器集成。 轻量化设计，适合嵌入式场景。 2.2 功能 事务开始：分配事务ID，初始化事务状态。 版本管理：通过MVCC维护数据的多版本。 提交与回滚：处理事务的提交或回滚，更新可见版本。 并发控制：支持读写并发，确保隔离性。 3. 事务管理器的核心设计 3.1 数据结构 事务状态：\n使用Transaction类记录事务信息。 1 2 3 4 5 6 7 8 9 10 11 12 public class Transaction { private final long txId; private boolean active; private List\u0026amp;lt;Row\u0026amp;gt; undoLog; // 用于回滚 public Transaction(long txId) { this.txId = txId; this.active = true; this.undoLog = new ArrayList\u0026amp;lt;\u0026amp;gt;(); } // getter和setter } 全局状态：\n使用Map跟踪活动事务和全局版本号。 3.2 MVCC机制 每行数据（Row）包含version和txId： version：表示当前版本号，提交后递增。 txId：创建或修改该版本的事务ID。 可见性规则： 读操作：只读取txId \u0026amp;lt;= 当前事务ID且version \u0026amp;gt; 0的行。 写操作：创建新版本，保留旧版本供回滚。 3.3 WAL日志 在写操作前记录WAL日志，确保故障后可恢复。 4. 事务管理器实现 以下是TransactionManager类的核心实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 …","date":1615214737,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"9bb179c4a7711b45f7c4949b968b68e2","publishdate":1615214737,"relpermalink":"/posts/database/javadb/javadb5/","section":"posts","summary":"\u003ch5 id=\"1-引言\"\u003e1. 引言\u003c/h5\u003e\n\u003cp\u003e在前四篇中，我们完成了JDBC驱动和存储引擎的实现，支持了SQL执行、数据存储和索引管理。本篇将聚焦事务管理器（\u003ccode\u003etransaction-manager\u003c/code\u003e模块）的实现，设计MVCC机制，确保事务的隔离性、一致性和持久性。事务管理器将与存储引擎协作管理数据版本，并通过日志管理器记录WAL日志，实现高并发和故障恢复能力。\u003c/p\u003e","tags":["数据库","Java","轻量级"],"title":"基于Java的高性能轻量化数据库设计与实现 第五篇：事务管理器实现","url":"https://yinlongfei.com/posts/database/javadb/javadb5/","wordcount":1611},{"categories":"posts","content":"1. 引言 在前三篇中，我们完成了系统架构设计和JDBC驱动实现，并集成了日志管理器以支持WAL和调试日志。本篇将聚焦存储引擎（storage-engine模块）的实现，设计内存和文件存储机制，支持B+树索引和JSON数据类型，确保高性能和事务一致性。存储引擎将与执行引擎、事务管理器和元数据管理模块协作，完成数据操作。\n2. 存储引擎的目标与功能 2.1 目标 提供高效的数据存储和检索，支持内存和文件两种模式。 实现B+树索引，优化查询性能。 原生支持JSON数据类型，满足现代应用需求。 与MVCC事务和日志管理器集成，确保数据一致性和持久性。 2.2 功能 数据存储：支持表数据和索引的内存/文件存储。 索引管理：实现B+树索引，支持主键和二级索引。 JSON支持：存储和查询JSON数据。 事务支持：配合MVCC管理多版本数据。 3. 存储引擎的核心设计 3.1 数据结构 表数据：\n使用Map\u0026amp;lt;String, List\u0026amp;lt;Row\u0026amp;gt;\u0026amp;gt;存储表，键为表名，值为行列表。 每行Row包含字段值和MVCC元数据。 1 2 3 4 5 6 7 8 9 10 11 12 public class Row { private Map\u0026amp;lt;String, Object\u0026amp;gt; columns; // 支持JSON类型 private long version; // MVCC版本号 private long txId; // 事务ID public Row(Map\u0026amp;lt;String, Object\u0026amp;gt; columns, long version, long txId) { this.columns = columns; this.version = version; this.txId = txId; } // getter和setter } 索引：\n使用B+树实现，支持高效范围查询。 键为索引字段值，值为行引用或主键。 3.2 存储模式 内存模式：所有数据存储在HashMap中，适合小规模快速操作。 文件模式：使用Java NIO的内存映射文件（MappedByteBuffer）存储数据，结合WAL日志确保持久性。 3.3 JSON支持 使用javax.json解析和存储JSON数据。 支持JSON查询，如JSON_EXTRACT(data, …","date":1615128337,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"3af3598f27741cd0f9e304bb47c88b46","publishdate":1615128337,"relpermalink":"/posts/database/javadb/javadb4/","section":"posts","summary":"\u003ch5 id=\"1-引言\"\u003e1. 引言\u003c/h5\u003e\n\u003cp\u003e在前三篇中，我们完成了系统架构设计和JDBC驱动实现，并集成了日志管理器以支持WAL和调试日志。本篇将聚焦存储引擎（\u003ccode\u003estorage-engine\u003c/code\u003e模块）的实现，设计内存和文件存储机制，支持B+树索引和JSON数据类型，确保高性能和事务一致性。存储引擎将与执行引擎、事务管理器和元数据管理模块协作，完成数据操作。\u003c/p\u003e","tags":["数据库","Java","轻量级"],"title":"基于Java的高性能轻量化数据库设计与实现 第四篇：存储引擎实现","url":"https://yinlongfei.com/posts/database/javadb/javadb4/","wordcount":1779},{"categories":"posts","content":"Spring框架是Java开发的基石，以其轻量级和模块化设计广泛应用于企业级开发。本篇将从IOC容器、AOP机制、Spring Boot自动配置到事务管理和MVC流程，系统讲解Spring的核心内容，助你在面试中展现框架掌握度和问题解决能力。\n1. IOC容器与依赖注入 IOC（Inversion of Control，控制反转）是Spring的核心，通过依赖注入（DI）解耦组件。\nIOC原理\n将对象创建和管理交给容器，开发者只需声明依赖。 实现方式：XML配置、注解（@Autowired）、Java Config。 Bean生命周期\n实例化。 属性填充（依赖注入）。 初始化（@PostConstruct或InitializingBean）。 使用。 销毁（@PreDestroy或DisposableBean）。 示例: 注解方式依赖注入\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import org.springframework.context.annotation.*; import org.springframework.stereotype.Component; @Component class UserService { public String getUser() { return \u0026amp;#34;User: Alice\u0026amp;#34;; } } @Component class OrderService { private final UserService userService; @Autowired public OrderService(UserService userService) { this.userService = userService; } public String getOrder() { return \u0026amp;#34;Order with \u0026amp;#34; + userService.getUser(); } } @Configuration @ComponentScan(\u0026amp;#34;com.example\u0026amp;#34;) class AppConfig { public static void …","date":1615084020,"description":"","fuzzywordcount":2100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"5cd79e409988b2d3747d5bf9c12805af","publishdate":1615084020,"relpermalink":"/posts/java-interview/java_interview4/","section":"posts","summary":"\u003cp\u003eSpring框架是Java开发的基石，以其轻量级和模块化设计广泛应用于企业级开发。本篇将从IOC容器、AOP机制、Spring Boot自动配置到事务管理和MVC流程，系统讲解Spring的核心内容，助你在面试中展现框架掌握度和问题解决能力。\u003c/p\u003e","tags":["Java","Spring","IOC","AOP","Spring Boot","事务管理","MVC"],"title":"Java技术专家面试专题系列（四）：Spring框架核心","url":"https://yinlongfei.com/posts/java-interview/java_interview4/","wordcount":2041},{"categories":"posts","content":"1. 引言 在第二篇中，我们设计了系统的整体架构，明确了JDBC驱动作为客户端入口的角色。本篇将深入探讨JDBC驱动的实现细节，确保其符合SQL ANSI 92标准，支持事务、JSON操作和高性能目标。通过与SQL解析器和内核的集成，展示从SQL输入到结果返回的完整流程。\n2. JDBC驱动的目标与功能 2.1 目标 提供标准的JDBC接口，兼容现有Java数据库工具和框架。 支持轻量化设计，无外部依赖。 集成日志管理器，记录SQL执行和事务操作。 确保高效的SQL执行和事务管理。 2.2 功能 连接管理：通过JDBC URL建立与数据库的连接。 SQL执行：支持DDL、DML和事务语句。 结果处理：返回查询结果集，支持JSON数据类型。 日志记录：记录关键操作到WAL和调试日志。 配置支持：允许切换内存/文件模式。 3. JDBC驱动的核心接口实现 JDBC驱动需要实现java.sql包中的关键接口，以下是主要实现：\n3.1 Driver 接口 作用：注册驱动并处理连接请求。 实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import java.sql.Driver; import java.sql.DriverManager; import java.sql.SQLException; public class LightweightDriver implements Driver { static { try { DriverManager.registerDriver(new LightweightDriver()); } catch (SQLException e) { throw new RuntimeException(\u0026amp;#34;Failed to register LightweightDriver\u0026amp;#34;, e); } } @Override public Connection connect(String url, java.util.Properties info) throws SQLException { if (!acceptsURL(url)) return null; return new …","date":1615041937,"description":"","fuzzywordcount":2e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"61c9f2eec10ffc02c893dc412b84ffae","publishdate":1615041937,"relpermalink":"/posts/database/javadb/javadb3/","section":"posts","summary":"\u003ch5 id=\"1-引言\"\u003e1. 引言\u003c/h5\u003e\n\u003cp\u003e在第二篇中，我们设计了系统的整体架构，明确了JDBC驱动作为客户端入口的角色。本篇将深入探讨JDBC驱动的实现细节，确保其符合SQL ANSI 92标准，支持事务、JSON操作和高性能目标。通过与SQL解析器和内核的集成，展示从SQL输入到结果返回的完整流程。\u003c/p\u003e","tags":["数据库","Java","轻量级"],"title":"基于Java的高性能轻量化数据库设计与实现 第三篇：JDBC驱动实现","url":"https://yinlongfei.com/posts/database/javadb/javadb3/","wordcount":1927},{"categories":"posts","content":"1. Gradle构建结构（Kotlin DSL） 根目录 build.gradle.kts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 plugins { `java-library` apply false } allprojects { group = \u0026amp;#34;com.yinlongfei.lightweight.database\u0026amp;#34; version = \u0026amp;#34;1.0.0-SNAPSHOT\u0026amp;#34; } subprojects { apply(plugin = \u0026amp;#34;java-library\u0026amp;#34;) java { sourceCompatibility = JavaVersion.VERSION_17 targetCompatibility = JavaVersion.VERSION_17 } repositories { mavenCentral() } } 子模块 settings.gradle.kts 1 2 3 4 5 6 7 8 9 rootProject.name = \u0026amp;#34;lightweight-database\u0026amp;#34; include(\u0026amp;#34;jdbc-driver\u0026amp;#34;) include(\u0026amp;#34;sql-parser\u0026amp;#34;) include(\u0026amp;#34;query-optimizer\u0026amp;#34;) include(\u0026amp;#34;execution-engine\u0026amp;#34;) include(\u0026amp;#34;storage-engine\u0026amp;#34;) include(\u0026amp;#34;transaction-manager\u0026amp;#34;) include(\u0026amp;#34;metadata-manager\u0026amp;#34;) 子模块 build.gradle.kts 示例 以下是每个子模块的build.gradle.kts配置，包含外部和内部依赖：\njdbc-driver/build.gradle.kts\n1 2 3 4 5 6 dependencies { implementation(project(\u0026amp;#34;:sql-parser\u0026amp;#34;)) implementation(project(\u0026amp;#34;:execution-engine\u0026amp;#34;)) …","date":1614955537,"description":"","fuzzywordcount":900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"7c62bdae9b3a27e440229c259e0723ef","publishdate":1614955537,"relpermalink":"/posts/database/javadb/javadb2-module/","section":"posts","summary":"\u003ch3 id=\"1-gradle构建结构kotlin-dsl\"\u003e1. Gradle构建结构（Kotlin DSL）\u003c/h3\u003e\n\u003ch4 id=\"根目录-buildgradlekts\"\u003e根目录 \u003ccode\u003ebuild.gradle.kts\u003c/code\u003e\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e18\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e19\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e20\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e21\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-kotlin\" data-lang=\"kotlin\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eplugins\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"err\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ejava\u003c/span\u003e\u003cspan class=\"p\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003elibrary\u003c/span\u003e\u003cspan class=\"err\"\u003e`\u003c/span\u003e \u003cspan class=\"n\"\u003eapply\u003c/span\u003e \u003cspan class=\"k\"\u003efalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eallprojects\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003egroup\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;com.yinlongfei.lightweight.database\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eversion\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;1.0.0-SNAPSHOT\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003esubprojects\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eapply\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eplugin\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;java-library\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003ejava\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003esourceCompatibility\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eJavaVersion\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eVERSION_17\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003etargetCompatibility\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eJavaVersion\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eVERSION_17\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003erepositories\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003emavenCentral\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch4 id=\"子模块-settingsgradlekts\"\u003e子模块 \u003ccode\u003esettings.gradle.kts\u003c/code\u003e\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e9\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-kotlin\" data-lang=\"kotlin\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003erootProject\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;lightweight-database\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003einclude\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;jdbc-driver\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003einclude\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;sql-parser\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003einclude\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;query-optimizer\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003einclude\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;execution-engine\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003einclude\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;storage-engine\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003einclude\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;transaction-manager\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003einclude\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;metadata-manager\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch4 id=\"子模块-buildgradlekts-示例\"\u003e子模块 \u003ccode\u003ebuild.gradle.kts\u003c/code\u003e 示例\u003c/h4\u003e\n\u003cp\u003e以下是每个子模块的\u003ccode\u003ebuild.gradle.kts\u003c/code\u003e配置，包含外部和内部依赖：\u003c/p\u003e","tags":["数据库","Java","轻量级"],"title":"基于Java的高性能轻量化数据库设计与实现 扩展篇：模块设计","url":"https://yinlongfei.com/posts/database/javadb/javadb2-module/","wordcount":813},{"categories":"posts","content":"1. 引言 在第一篇中，我们明确了项目的目标：构建一个高性能、轻量级的嵌入式数据库，支持SQL ANSI 92标准、JDBC驱动、MVCC事务和JSON功能，并超越H2和SQLite的性能。本篇将设计系统的整体架构，划分功能模块，确定技术选型，并为实现提供清晰的结构化指导。\n2. 模块划分 系统采用模块化设计，分为以下核心组件：\nJDBC驱动（JDBC Driver） 功能：实现标准JDBC接口，桥接外部客户端与数据库内核。 职责：接收SQL语句，返回查询结果，支持连接管理和事务控制。 SQL解析器（SQL Parser） 功能：将SQL语句解析为抽象语法树（AST）。 职责：支持SQL ANSI 92语法，包括JSON相关操作。 查询优化器（Query Optimizer） 功能：根据统计信息和索引优化执行计划。 职责：选择最低成本的查询路径，提升性能。 执行引擎（Execution Engine） 功能：执行SQL操作，包括DDL、DML和事务。 职责：协调存储引擎和事务管理器，处理并行执行。 存储引擎（Storage Engine） 功能：管理数据存储和索引，支持内存和文件模式。 职责：实现高效的读写操作，支持JSON和B+树索引。 事务管理器（Transaction Manager） 功能：基于MVCC实现事务一致性。 职责：管理版本控制、并发事务和日志。 元数据管理（Metadata Manager） 功能：存储和管理表结构、索引和JSON字段定义。 职责：提供元数据查询和更新接口。 3. 技术选型 为实现高性能和轻量化目标，选择以下技术：\n开发语言：Java 17 理由：跨平台，支持现代特性（如记录类、密封类），与JDBC无缝集成。 SQL解析：ANTLR v4 理由：强大的语法解析工具，支持SQL ANSI 92标准。 数据结构： B+树：用于索引，支持高效范围查询。 RoaringBitmap：用于快速过滤和集合操作。 HashMap：内存表存储。 文件存储：Java NIO + 内存映射文件（Memory-Mapped Files） 理由：高性能I/O，减少系统调用开销。 JSON处理：JSON-P（JSR 374） 理由：轻量级，Java标准，适合嵌入式场景。 并发控制：MVCC + 自定义线程池 理由：MVCC提供高效事务并发，自定义线程池优化 …","date":1614869137,"description":"","fuzzywordcount":2200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"ac75adfaab1d5c2242bf82b14ab7f1ab","publishdate":1614869137,"relpermalink":"/posts/database/javadb/javadb2/","section":"posts","summary":"\u003ch5 id=\"1-引言\"\u003e1. 引言\u003c/h5\u003e\n\u003cp\u003e在第一篇中，我们明确了项目的目标：构建一个高性能、轻量级的嵌入式数据库，支持SQL ANSI 92标准、JDBC驱动、MVCC事务和JSON功能，并超越H2和SQLite的性能。本篇将设计系统的整体架构，划分功能模块，确定技术选型，并为实现提供清晰的结构化指导。\u003c/p\u003e","tags":["数据库","Java","轻量级"],"title":"基于Java的高性能轻量化数据库设计与实现 第二篇：系统架构设计","url":"https://yinlongfei.com/posts/database/javadb/javadb2/","wordcount":2193},{"categories":"posts","content":"JVM（Java虚拟机）是Java程序运行的核心，理解其内部机制是技术专家的必备技能。本篇将从内存划分、类加载机制、垃圾回收到性能调优工具，系统讲解JVM的运行原理和优化方法，助你在面试中展现深厚的技术功底。\n1. JVM内存划分 JVM将内存划分为多个区域，各司其职。\n堆（Heap）\n存储对象实例和数组，是GC的主要区域。 分代：新生代（Eden、Survivor）、老年代。 栈（Stack）\n每个线程独占，存储局部变量、方法调用栈帧。 栈帧包括操作数栈、局部变量表等。 方法区（Method Area）\n存储类信息、静态变量、常量池。 JDK 1.8后移至元空间（Metaspace），使用本地内存。 程序计数器（PC Register）\n记录当前线程执行的字节码位置，线程私有。 本地方法栈（Native Method Stack）\n支持Native方法调用。 示例: 查看堆内存使用\n1 2 3 4 5 6 7 8 9 public class MemoryDemo { public static void main(String[] args) { Runtime runtime = Runtime.getRuntime(); long totalMemory = runtime.totalMemory(); // 当前堆内存 long maxMemory = runtime.maxMemory(); // 最大堆内存 System.out.println(\u0026amp;#34;Total Memory: \u0026amp;#34; + totalMemory / 1024 / 1024 + \u0026amp;#34;MB\u0026amp;#34;); System.out.println(\u0026amp;#34;Max Memory: \u0026amp;#34; + maxMemory / 1024 / 1024 + \u0026amp;#34;MB\u0026amp;#34;); } } 面试问题:\n问题: 方法区和元空间的区别？ 答案: 方法区是JVM规范中的逻辑区域，JDK 1.7前由永久代实现，1.8后改为元空间，使用本地内存，避免OOM风险。 2. 类加载机制 类加载器负责将.class文件加载到JVM内存中。\n加载过程\n加载: 读取字节码到内存。 验证: 确保字节码符合规范。 准备: 为静态变量分配内存，赋默认值。 解析: 将符号引用转为直接引用。 初始化: 执行静态代码 …","date":1614824820,"description":"","fuzzywordcount":1900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"eebfcf464859c068aa3ccfcdb322beda","publishdate":1614824820,"relpermalink":"/posts/java-interview/java_interview3/","section":"posts","summary":"\u003cp\u003eJVM（Java虚拟机）是Java程序运行的核心，理解其内部机制是技术专家的必备技能。本篇将从内存划分、类加载机制、垃圾回收到性能调优工具，系统讲解JVM的运行原理和优化方法，助你在面试中展现深厚的技术功底。\u003c/p\u003e","tags":["Java","JVM","GC","性能调优"],"title":"Java技术专家面试专题系列（三）：JVM深入剖析","url":"https://yinlongfei.com/posts/java-interview/java_interview3/","wordcount":1805},{"categories":"posts","content":"1. 项目目标 本项目旨在设计并实现一个基于Java的高性能、轻量级的关系型数据库，全面支持SQL ANSI 92标准，同时提供现代数据库特性（如JSON支持和MVCC事务）。通过纯Java实现，确保跨平台性和无外部依赖，适用于嵌入式应用场景。项目的核心目标包括：\n性能最优：在嵌入式场景下，超越主流嵌入式数据库（如H2、SQLite）的性能表现。 功能完整：支持SQL ANSI 92标准的完整功能，包括DDL、DML、事务和复杂查询。 易用性：实现标准的JDBC驱动，兼容现有数据库工具和框架。 扩展性：支持JSON数据类型和现代并发控制机制，为未来功能扩展奠定基础。 2. 功能需求 2.1 SQL ANSI 92完整支持 数据定义语言（DDL）： CREATE TABLE、DROP TABLE、ALTER TABLE。 支持约束：PRIMARY KEY、FOREIGN KEY、NOT NULL等。 示例：CREATE TABLE users (id INT PRIMARY KEY, name VARCHAR(50));。 数据操纵语言（DML）： INSERT、SELECT、UPDATE、DELETE。 支持复杂查询：WHERE、ORDER BY、GROUP BY、HAVING、JOIN（INNER、LEFT、RIGHT）、UNION、子查询。 示例：SELECT name FROM users WHERE id \u0026amp;gt; 10 ORDER BY name;。 事务支持： 实现ACID属性，支持BEGIN、COMMIT、ROLLBACK。 使用MVCC（多版本并发控制）实现高效并发。 2.2 JSON支持 支持JSON数据类型的存储和操作。 提供JSON查询函数，如JSON_EXTRACT、JSON_CONTAINS。 示例：SELECT JSON_EXTRACT(data, \u0026#39;$.name\u0026#39;) FROM users WHERE JSON_EXTRACT(data, \u0026#39;$.age\u0026#39;) \u0026amp;gt; 18;。 2.3 JDBC驱动 实现标准的JDBC接口（java.sql.Driver、Connection、Statement等）。 支持通过JDBC URL连接数据库，如jdbc:lightweight:db。 兼容SQL客户端工具（如DBeaver）和Java ORM框 …","date":1614782737,"description":"","fuzzywordcount":2200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"f25c7389a3e502fe42603edee8f0ed22","publishdate":1614782737,"relpermalink":"/posts/database/javadb/javadb1/","section":"posts","summary":"\u003ch5 id=\"1-项目目标\"\u003e1. 项目目标\u003c/h5\u003e\n\u003cp\u003e本项目旨在设计并实现一个基于Java的高性能、轻量级的关系型数据库，全面支持SQL ANSI 92标准，同时提供现代数据库特性（如JSON支持和MVCC事务）。通过纯Java实现，确保跨平台性和无外部依赖，适用于嵌入式应用场景。项目的核心目标包括：\u003c/p\u003e","tags":["数据库","Java","轻量级"],"title":"基于Java的高性能轻量化数据库设计与实现 第一篇：项目概述与需求分析","url":"https://yinlongfei.com/posts/database/javadb/javadb1/","wordcount":2104},{"categories":"posts","content":"第一部分：项目概述与需求分析 目标\n实现一个轻量级、高性能的关系型数据库，全面支持SQL ANSI 92标准。 使用Java语言，支持JDBC驱动，兼容主流数据库工具。 性能目标：超越主流嵌入式数据库（如H2、SQLite）在嵌入式场景中的表现。 支持完整的事务（MVCC实现）和JSON数据类型。 功能需求\nSQL ANSI 92完整支持： DDL：CREATE/DROP/ALTER TABLE, CREATE INDEX等。 DML：INSERT, SELECT, UPDATE, DELETE（包括JOIN、子查询、聚合函数）。 查询：WHERE, ORDER BY, GROUP BY, HAVING, UNION等。 事务支持：基于MVCC（多版本并发控制）实现ACID。 JSON支持：存储、查询和操作JSON数据（如JSON_EXTRACT）。 JDBC驱动：实现标准JDBC接口，支持外部连接。 非功能需求\n高性能：优于H2、SQLite，尤其在嵌入式场景下。 轻量化：内存占用低，启动快。 可移植性：跨平台，无外部依赖。 与主流嵌入式数据库对比\nH2：纯Java实现，支持MVCC和JDBC，性能优秀，但内存占用较高。 SQLite：C语言实现，轻量但JDBC需额外桥接，JSON支持较弱。 本项目优势：纯Java、无依赖、JSON原生支持、性能调优至最优。 第二部分：系统架构设计 模块划分\nJDBC驱动：实现java.sql包的接口（如Driver、Connection、Statement）。 SQL解析器：解析SQL ANSI 92标准语句，生成AST。 查询优化器：基于成本的优化，支持MVCC和索引。 执行引擎：高效执行SQL，支持并行处理。 存储引擎：内存+文件存储，支持JSON和B+树索引。 事务管理器：基于MVCC实现并发控制。 元数据管理：存储表结构、索引和JSON字段定义。 技术选型\nJava 17+：利用现代特性（如记录类、密封类）。 数据结构：B+树（索引）、RoaringBitmap（高效过滤）、JSON-P（JSON处理）。 文件存储：Java NIO + 内存映射文件（高性能I/O）。 架构图（文字描述）\ngraph TD A[用户输入SQL] --\u0026amp;gt; B[SQL解析器] B --\u0026amp;gt;|生成| C[AST] C --\u0026amp;gt; …","date":1614696337,"description":"","fuzzywordcount":1900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"1b514dc805133f3f37297bb2334f205e","publishdate":1614696337,"relpermalink":"/posts/database/javadb/javadbtoc/","section":"posts","summary":"\u003ch4 id=\"第一部分项目概述与需求分析\"\u003e第一部分：项目概述与需求分析\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e目标\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e实现一个轻量级、高性能的关系型数据库，全面支持SQL ANSI 92标准。\u003c/li\u003e\n\u003cli\u003e使用Java语言，支持JDBC驱动，兼容主流数据库工具。\u003c/li\u003e\n\u003cli\u003e性能目标：超越主流嵌入式数据库（如H2、SQLite）在嵌入式场景中的表现。\u003c/li\u003e\n\u003cli\u003e支持完整的事务（MVCC实现）和JSON数据类型。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e功能需求\u003c/strong\u003e\u003c/p\u003e","tags":["数据库","Java","轻量级"],"title":"专题系列：基于Java的高性能轻量化数据库设计与实现","url":"https://yinlongfei.com/posts/database/javadb/javadbtoc/","wordcount":1800},{"categories":"posts","content":"并发编程是Java技术专家必须精通的领域，它直接关系到系统性能和稳定性。本篇将从线程基础、同步机制、线程池、JUC工具包到CAS与原子类，系统讲解Java并发编程的核心知识，旨在为你提供扎实的理论基础和实战能力，应对高级面试挑战。\n1. 线程基础 线程是Java并发的基础，理解其创建和生命周期至关重要。\n创建方式\n继承Thread类。 实现Runnable接口。 使用Callable和Future（带返回值）。 Lambda表达式（推荐）。 线程状态\n新建（New）、就绪（Runnable）、运行（Running）、阻塞（Blocked）、等待（Waiting）、超时等待（Timed Waiting）、终止（Terminated）。 示例: 使用Callable获取线程结果\n1 2 3 4 5 6 7 8 9 10 11 12 import java.util.concurrent.*; public class ThreadCreationDemo { public static void main(String[] args) throws Exception { ExecutorService executor = Executors.newSingleThreadExecutor(); Callable\u0026amp;lt;String\u0026amp;gt; task = () -\u0026amp;gt; \u0026amp;#34;Task completed after 1 second!\u0026amp;#34;; Future\u0026amp;lt;String\u0026amp;gt; future = executor.submit(task); Thread.sleep(1000); // 模拟延迟 System.out.println(future.get()); // 输出: Task completed after 1 second! executor.shutdown(); } } 面试问题:\n问题: Runnable和Callable的区别是什么？ 答案: Runnable无返回值，run()方法不抛异常；Callable有返回值，通过Future获取结果，call()方法可抛异常。 2. 同步机制 多线程访问共享资源时，同步机制确保数据一致性。\nsynchronized关键字\n作用于方法或代码块，保证同一时刻只有一个线程访问。 底层通 …","date":1614565620,"description":"","fuzzywordcount":2e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"ddf0db570445c7461beec32377b04077","publishdate":1614565620,"relpermalink":"/posts/java-interview/java_interview2/","section":"posts","summary":"\u003cp\u003e并发编程是Java技术专家必须精通的领域，它直接关系到系统性能和稳定性。本篇将从线程基础、同步机制、线程池、JUC工具包到CAS与原子类，系统讲解Java并发编程的核心知识，旨在为你提供扎实的理论基础和实战能力，应对高级面试挑战。\u003c/p\u003e","tags":["Java","线程","并发","JUC"],"title":"Java技术专家面试专题系列（二）：Java并发编程","url":"https://yinlongfei.com/posts/java-interview/java_interview2/","wordcount":1977},{"categories":"posts","content":"在Java技术专家的面试中，扎实的核心基础是成功的第一步。本篇将深入探讨Java的核心概念，包括基本语法、面向对象编程（OOP）、异常处理、集合框架和内存模型，并辅以示例和常见面试问题，助你在面试中脱颖而出。\n1. Java基本语法与数据类型 Java作为一门强类型语言，其语法简洁但严谨，理解基础语法是后续学习的前提。\n数据类型\n基本类型: byte（1字节）、short（2字节）、int（4字节）、long（8字节）、float（4字节）、double（8字节）、char（2字节）、boolean（1位）。 引用类型: 类、接口、数组等，存储在堆中，通过引用访问。 注意事项: 基本类型有默认值（如int为0），引用类型默认为null。 变量与常量\n使用final关键字定义常量，如final int MAX = 100;。 变量作用域：局部变量、成员变量、静态变量。 示例: 数据类型转换\n1 2 3 4 5 6 7 8 9 public class TypeCastingDemo { public static void main(String[] args) { int i = 100; long l = i; // 隐式转换 float f = 123.45f; int j = (int) f; // 显式转换，截断小数 System.out.println(\u0026amp;#34;Long: \u0026amp;#34; + l + \u0026amp;#34;, Int: \u0026amp;#34; + j); // 输出: Long: 100, Int: 123 } } 面试问题:\n问题: float和double的区别是什么？ 答案: float是单精度浮点数（32位），精度较低；double是双精度（64位），精度更高。实际开发中，推荐double，因为float可能导致精度丢失。 2. 面向对象编程（OOP）原则 Java的核心是面向对象，掌握OOP三大特性至关重要。\n封装: 通过private隐藏内部实现，提供public方法访问。 继承: 使用extends实现代码复用，子类继承父类非私有成员。 多态: 分为编译时多态（方法重载）和运行时多态（方法重写）。 示例: 多态实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 …","date":1614392820,"description":"","fuzzywordcount":2200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"2c1b839211943e2602dc542b754dbf50","publishdate":1614392820,"relpermalink":"/posts/java-interview/java_interview1/","section":"posts","summary":"\u003cp\u003e在Java技术专家的面试中，扎实的核心基础是成功的第一步。本篇将深入探讨Java的核心概念，包括基本语法、面向对象编程（OOP）、异常处理、集合框架和内存模型，并辅以示例和常见面试问题，助你在面试中脱颖而出。\u003c/p\u003e","tags":["Java","基础"],"title":"Java技术专家面试专题系列（一）：Java核心基础","url":"https://yinlongfei.com/posts/java-interview/java_interview1/","wordcount":2178},{"categories":"posts","content":"好的，以下是“MySQL 硬核解析专题”的第五篇完整内容，主题是 实战案例。这一篇将通过具体的场景和解决方案，把前四章的知识串起来，带你从问题分析到优化落地，体验 MySQL 的硬核实战过程。内容会贴近真实案例，既有技术深度，又有操作细节。让我们开始吧！\nMySQL 硬核解析专题 - 第五篇：实战案例 前四章我们聊了 MySQL 的架构、SQL 执行、性能优化和高可用分布式，现在是时候把这些“招数”用起来了。这一篇，我会带你走进两个真实场景：一张 1 亿行的表查询慢到崩溃，高并发下事务死锁频发。通过分析问题、制定方案、落地优化，看看 MySQL 怎么从“瘸腿”变“飞奔”。\n案例一：一张表 1 亿行，查询慢到怀疑人生 场景：某电商平台的 orders 表，数据量 1 亿行，字段包括 order_id（主键）、user_id、order_time、amount 等。业务跑了个查询：\n1 SELECT * FROM orders WHERE order_time \u0026amp;gt; \u0026amp;#39;2025-01-01\u0026amp;#39; ORDER BY order_time LIMIT 10; 结果耗时 20 秒，页面卡死，用户投诉不断。\n问题分析\n执行计划：跑 EXPLAIN： type: ALL rows: 100000000 key: NULL Extra: Using filesort 全表扫描 1 亿行，没用索引，排序还用文件临时表，性能崩了。 表结构：SHOW CREATE TABLE orders; 显示只有主键索引，order_time 没索引。 硬件：缓冲池 innodb_buffer_pool_size=1GB，内存不够，频繁读磁盘。 优化方案\n加索引：针对 order_time 建索引。 1 CREATE INDEX idx_time ON orders(order_time); 改 SQL：用覆盖索引，减少回表。 1 2 3 SELECT order_id, order_time FROM orders WHERE order_time \u0026amp;gt; \u0026amp;#39;2025-01-01\u0026amp;#39; ORDER BY order_time LIMIT 10; 分表：数据量太大，考虑按时间分片，比如 orders_2024、orders_2025。 调配置：缓冲池调到 8GB（假设机 …","date":1588063189,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"886076b95ecc39ca187d01de9ead9e9b","publishdate":1588063189,"relpermalink":"/posts/database/mysql/mysql5/","section":"posts","summary":"\u003cp\u003e好的，以下是“MySQL 硬核解析专题”的第五篇完整内容，主题是 \u003cstrong\u003e实战案例\u003c/strong\u003e。这一篇将通过具体的场景和解决方案，把前四章的知识串起来，带你从问题分析到优化落地，体验 MySQL 的硬核实战过程。内容会贴近真实案例，既有技术深度，又有操作细节。让我们开始吧！\u003c/p\u003e","tags":["MySQL"],"title":"MySQL 硬核解析专题 - 第五篇：实战案例","url":"https://yinlongfei.com/posts/database/mysql/mysql5/","wordcount":1684},{"categories":"posts","content":"好的，以下是“MySQL 硬核解析专题”的第四篇完整内容，主题是 高可用与分布式。这一篇将带你探索 MySQL 如何在高并发、大数据量场景下保持稳定和高效，从主从复制到读写分离，再到分库分表，给你一套硬核的高可用方案。内容会深入技术细节，同时提供实战思路。让我们开始吧！\nMySQL 硬核解析专题 - 第四篇：高可用与分布式 前几章我们聊了 MySQL 的架构、SQL 执行和性能优化，但单机 MySQL 总有极限：流量一上来就宕机，数据量一大就慢如龟爬。要解决这些问题，就得引入高可用（HA）和分布式方案。这一篇，我会带你拆解 MySQL 的高可用架构和分布式策略，让你的数据库扛得住“洪水猛兽”。\n一、主从复制：高可用的第一步 主从复制是 MySQL 高可用的基础，通过把数据从主库同步到从库，实现读写分离和故障切换。\n工作原理\n主库：每次写操作（INSERT、UPDATE、DELETE）生成 binlog（二进制日志），记录数据变更。 从库：通过两个线程同步： IO 线程：从主库拉取 binlog，存到本地 relay log（中继日志）。 SQL 线程：读取 relay log，执行 SQL 重放数据。 异步特性：默认是异步复制，主库写完就返回，从库慢慢跟上，可能有延迟。 配置实战\n主库配置（my.cnf）： 1 2 3 4 [mysqld] server-id=1 log_bin=mysql-bin binlog_format=row # 推荐 row 模式，兼容性好 从库配置（my.cnf）： 1 2 3 4 [mysqld] server-id=2 relay_log=relay-log read_only=1 # 从库只读 同步设置： 1 2 3 4 5 6 7 CHANGE MASTER TO MASTER_HOST=\u0026amp;#39;主库IP\u0026amp;#39;, MASTER_USER=\u0026amp;#39;repl_user\u0026amp;#39;, MASTER_PASSWORD=\u0026amp;#39;repl_pass\u0026amp;#39;, MASTER_LOG_FILE=\u0026amp;#39;mysql-bin.000001\u0026amp;#39;, MASTER_LOG_POS=154; # 从 binlog 起点开始 START SLAVE; 检查状态：SHOW SLAVE STATUS\\G，看 Slave_IO_Running …","date":1585730389,"description":"","fuzzywordcount":1900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"17ec2dba530b0275770dbd7f5f638801","publishdate":1585730389,"relpermalink":"/posts/database/mysql/mysql4/","section":"posts","summary":"\u003cp\u003e好的，以下是“MySQL 硬核解析专题”的第四篇完整内容，主题是 \u003cstrong\u003e高可用与分布式\u003c/strong\u003e。这一篇将带你探索 MySQL 如何在高并发、大数据量场景下保持稳定和高效，从主从复制到读写分离，再到分库分表，给你一套硬核的高可用方案。内容会深入技术细节，同时提供实战思路。让我们开始吧！\u003c/p\u003e","tags":["MySQL"],"title":"MySQL 硬核解析专题 - 第四篇：高可用与分布式","url":"https://yinlongfei.com/posts/database/mysql/mysql4/","wordcount":1864},{"categories":"posts","content":"前两章我们聊了 MySQL 的架构和 SQL 执行流程，现在到了“提速”的关键时刻。无论是单表查询慢得像乌龟爬，还是高并发下数据库喘不过气，性能优化都能救你于水火。这一篇，我会带你剖析 MySQL 的性能瓶颈，并给出硬核的优化招数，帮你把数据库调成“跑车”。\n一、索引优化：性能的基石 索引是 MySQL 提速的头号功臣，但用不好也可能是“坑”。我们从原理到实战，拆解几个硬核技巧。\ncovering index（覆盖索引）：不回表的神器\n原理：查询所需的所有字段都在索引里，存储引擎不用“回表”查数据，省一次 IO。 例子：SELECT name FROM users WHERE age = 20; 如果只有 age 的单列索引，查到 age=20 的行后，还得回表取 name。 如果建个 (age, name) 的联合索引，索引里就有 name，直接返回，效率翻倍。 硬核点：用 EXPLAIN，看 Extra 列有 Using index 就说明命中覆盖索引。 index condition pushdown（ICP，索引条件下推）：过滤提速\n原理：MySQL 5.6 引入，存储引擎在索引层就过滤掉不符合条件的数据，减少回表次数。 例子：SELECT * FROM users WHERE age \u0026amp;gt; 18 AND name LIKE \u0026#39;T%\u0026#39;; 没 ICP：用 age 索引查出所有 age \u0026amp;gt; 18 的行，回表后再过滤 name。 有 ICP：索引层先过滤 name LIKE \u0026#39;T%\u0026#39;，再回表，数据量更少。 硬核点：EXPLAIN 的 Extra 列有 Using index condition 表示启用 ICP，默认开（optimizer_switch 里 index_condition_pushdown=on）。 索引设计原则\n高选择性字段优先：比如 user_id 比 gender 更适合建索引，因为区分度高。 前缀索引：对长字符串（如 URL），用 CREATE INDEX idx_url ON table(url(10)); 只索引前 10 个字符，省空间。 避免冗余：(a, b) 的联合索引已经包含 a，别再单独建 a 的索引。 二、配置调优：让硬件发挥极致 MySQL 的性能不只靠 SQL，还得靠配置“榨干”硬件资源。以下是几个关键参数的硬核 …","date":1585384789,"description":"","fuzzywordcount":2e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"943246900266f352b5a406fca4fb0f19","publishdate":1585384789,"relpermalink":"/posts/database/mysql/mysql3/","section":"posts","summary":"\u003cp\u003e前两章我们聊了 MySQL 的架构和 SQL 执行流程，现在到了“提速”的关键时刻。无论是单表查询慢得像乌龟爬，还是高并发下数据库喘不过气，性能优化都能救你于水火。这一篇，我会带你剖析 MySQL 的性能瓶颈，并给出硬核的优化招数，帮你把数据库调成“跑车”。\u003c/p\u003e","tags":["MySQL"],"title":"MySQL 硬核解析专题 - 第三篇：性能优化的硬核技巧","url":"https://yinlongfei.com/posts/database/mysql/mysql3/","wordcount":1932},{"categories":"posts","content":"上一章我们聊了 MySQL 的架构，知道它像一个分工明确的工厂。今天我们聚焦一条 SQL 语句的“旅程”，比如 SELECT * FROM users WHERE age \u0026amp;gt; 18; 是怎么从你敲下回车，到屏幕吐出数据的。这背后藏着解析、优化和执行的硬核细节，搞懂这些，你就能写出更高效的 SQL。\n一、SQL 执行的全流程概览 MySQL 处理一条 SQL 大致经历以下几个阶段：\n连接与接收：客户端发送 SQL，连接层接管。 解析与预处理：服务层把 SQL 拆解成可执行的指令。 查询优化：优化器决定执行路径。 执行与存储引擎交互：交给存储引擎去拿数据。 结果返回：数据加工后送回客户端。 下面我们逐一拆解每个阶段，看看 MySQL 是怎么“思考”和“干活”的。\n二、详细拆解 SQL 执行过程 连接与接收：SQL 的起点\n发生了什么：你通过客户端（比如命令行、JDBC）发送 SQL，MySQL 的连接层接收请求，校验权限后分配一个线程。 细节：如果是高并发场景，线程池会派上用场，避免每次新建线程的开销。如果连接失败，你可能看到 Access denied 或 Too many connections。 硬核点：可以用 SHOW PROCESSLIST; 查看当前连接和正在执行的 SQL，State 列会显示线程的状态，比如 Sending data。 解析与预处理：从字符串到指令\n词法解析：MySQL 把 SQL 拆成一个个 token。比如 SELECT * FROM users 被拆成 SELECT、*、FROM、users。 语法解析：生成抽象语法树（AST），检查语法是否合法。如果写错了，比如 SELEC * FROM users，会抛出 You have an error in your SQL syntax。 语义检查：确保表名、列名存在，权限足够。比如 users 表不存在，就会报 Table doesn\u0026#39;t exist。 硬核点：MySQL 的解析器基于 C 写的词法分析工具（如 lex 和 yacc），效率极高，但不支持太复杂的语法（比如嵌套过深的子查询可能会卡住）。 查询优化：大脑的决策时刻\n核心任务：优化器分析 SQL，生成最优的执行计划。 怎么优化： 选择索引：比如 WHERE age \u0026amp;gt; 18，如果 age 有索引，优化器可能会用 …","date":1584261589,"description":"","fuzzywordcount":1900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"15f46cf4dd03b63b861cce528d539a8c","publishdate":1584261589,"relpermalink":"/posts/database/mysql/mysql2/","section":"posts","summary":"\u003cp\u003e上一章我们聊了 MySQL 的架构，知道它像一个分工明确的工厂。今天我们聚焦一条 SQL 语句的“旅程”，比如 \u003ccode\u003eSELECT * FROM users WHERE age \u0026gt; 18;\u003c/code\u003e 是怎么从你敲下回车，到屏幕吐出数据的。这背后藏着解析、优化和执行的硬核细节，搞懂这些，你就能写出更高效的 SQL。\u003c/p\u003e","tags":["MySQL"],"title":"MySQL 硬核解析专题 - 第二篇：SQL 执行的幕后故事","url":"https://yinlongfei.com/posts/database/mysql/mysql2/","wordcount":1893},{"categories":"posts","content":"MySQL 是目前最流行的开源关系型数据库之一，无论你是开发 CRUD 应用，还是搞大数据分析，MySQL 都可能是你的“老伙计”。但你有没有想过，它是怎么接住你的 SQL 请求，然后又快又准地吐出数据的？这篇内容就带你拆开 MySQL 的“黑盒”，看看它的核心架构和关键组件。\n一、MySQL 架构全景 MySQL 的架构可以简单分成三层：连接层、服务层和存储引擎层，再加上底下的物理存储层。每一层都有自己的职责，分工明确，像一支训练有素的团队。\n连接层：门卫与接待员\n职责：负责处理客户端的连接请求，包括认证、权限校验和连接管理。 细节：当你敲下 mysql -u root -p 并输入密码时，连接层会校验你的身份。如果通过，它会分配一个线程给你后续的查询。MySQL 支持线程池（Thread Pool），在高并发场景下能复用线程，减少创建和销毁的开销。 硬核点：可以用 SHOW VARIABLES LIKE \u0026#39;thread_handling\u0026#39;; 查看连接线程的处理模式，默认是 one-thread-per-connection，企业版支持 pool-of-threads。 服务层：大脑与调度员\n职责：解析 SQL、优化查询、生成执行计划。 细节：这里有个明星组件叫“查询优化器”（Query Optimizer）。比如你写了个 SELECT * FROM users WHERE age \u0026amp;gt; 18，优化器会决定是用 age 上的索引，还是直接全表扫描。它还会做一些“聪明事”，比如把复杂的子查询改成 JOIN。 硬核点：可以用 EXPLAIN 看优化器的决策，比如 possible_keys（可能用到的索引）和 rows（预计扫描的行数）。 存储引擎层：干活的工人\n职责：真正执行查询，把数据从磁盘取出来，或把数据写进去。 细节：MySQL 的存储引擎是可插拔的，像搭积木一样，你可以选择 InnoDB、MyISAM、Memory 等。默认的 InnoDB 支持事务和行锁，MyISAM 则擅长读多写少的场景。 硬核点：可以用 SHOW ENGINES; 查看支持的引擎，ENGINE=InnoDB 是建表时的默认选项。 物理存储层：仓库与硬盘\n职责：数据和索引最终落盘的地方。 细节：包括数据文件（.ibd）、日志文件（redo log、undo log）和索引文件。这些文 …","date":1583051989,"description":"","fuzzywordcount":1900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"acb4d20eab706407fc56316d62c54dd3","publishdate":1583051989,"relpermalink":"/posts/database/mysql/mysql1/","section":"posts","summary":"\u003cp\u003eMySQL 是目前最流行的开源关系型数据库之一，无论你是开发 CRUD 应用，还是搞大数据分析，MySQL 都可能是你的“老伙计”。但你有没有想过，它是怎么接住你的 SQL 请求，然后又快又准地吐出数据的？这篇内容就带你拆开 MySQL 的“黑盒”，看看它的核心架构和关键组件。\u003c/p\u003e","tags":["MySQL"],"title":"MySQL 硬核解析专题 - 第一篇：MySQL 基础与架构","url":"https://yinlongfei.com/posts/database/mysql/mysql1/","wordcount":1812},{"categories":"posts","content":"MySQL 硬核解析专题 第一章：MySQL 基础与架构 MySQL 是一个广泛使用的开源关系型数据库管理系统（RDBMS），它以高效、稳定和易用著称。要深入理解 MySQL，首先得搞清楚它的架构和工作原理。\nMySQL 的核心组件\n连接层：负责处理客户端的连接，包括认证、权限校验和连接池管理。比如，你用 mysql -u root -p 登录时，连接层会校验你的用户名和密码。 服务层：解析 SQL、生成执行计划、优化查询。这里有个关键组件叫“查询优化器”，它会决定你的 SQL 是走索引还是全表扫描。 存储引擎层：MySQL 的灵魂所在，不同的存储引擎决定了数据如何存储和访问。常见的引擎有 InnoDB（默认）、MyISAM、Memory 等。 物理存储层：数据最终落盘的地方，涉及文件系统和硬件。 InnoDB 引擎深入剖析\nB+树索引：InnoDB 的主键索引用的是 B+树，相比 B树，它叶子节点存数据，非叶子节点只存键值，这样能减少 IO，提升范围查询效率。 缓冲池（Buffer Pool）：内存中的一块区域，用来缓存热点数据和索引页。可以用 SHOW VARIABLES LIKE \u0026#39;innodb_buffer_pool_size\u0026#39;; 查看大小。 事务与 MVCC：InnoDB 支持 ACID 事务，通过多版本并发控制（MVCC）实现读写不阻塞。简单说，就是每个事务看到的是一份数据快照，而不是实时变化的数据。 第二章：SQL 执行的幕后故事 一条简单的 SELECT * FROM users WHERE age \u0026amp;gt; 18; 是如何执行的？让我们拆开看看。\nSQL 解析与优化\n词法解析：把 SQL 拆成一个个 token，比如 SELECT、FROM。 语法解析：生成抽象语法树（AST），确保语句合法。 查询优化：优化器分析多种执行路径，比如是用 age 上的索引，还是直接扫全表。可以用 EXPLAIN 查看执行计划。 执行流程\n查询缓存（8.0 之前）：如果启用了查询缓存，会先查缓存。 存储引擎执行：优化器选好路径后，交给 InnoDB 去拿数据。 返回结果：数据从磁盘或缓冲池取出，经过服务层处理后返回客户端。 第三章：性能优化的硬核技巧 MySQL 慢查询是开发者的噩梦，怎么优化？以下是几个硬核方法。\n索引优化\n覆盖索引：让查询只访问索引，不回表。 …","date":1582879189,"description":"","fuzzywordcount":1300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"37b4f4b29967040878102550087654d0","publishdate":1582879189,"relpermalink":"/posts/database/mysql/mysqltoc/","section":"posts","summary":"\u003ch3 id=\"mysql-硬核解析专题\"\u003eMySQL 硬核解析专题\u003c/h3\u003e\n\u003ch4 id=\"第一章mysql-基础与架构\"\u003e第一章：MySQL 基础与架构\u003c/h4\u003e\n\u003cp\u003eMySQL 是一个广泛使用的开源关系型数据库管理系统（RDBMS），它以高效、稳定和易用著称。要深入理解 MySQL，首先得搞清楚它的架构和工作原理。\u003c/p\u003e","tags":["MySQL"],"title":"MySQL 硬核解析专题","url":"https://yinlongfei.com/posts/database/mysql/mysqltoc/","wordcount":1280},{"categories":"posts","content":"引言 CMDB的最终目标是为业务服务，而非仅仅停留在技术层面。经过前五篇的探讨，我们已经了解了CMDB的设计、实现、治理和优化，本文将转向其实际应用，揭示CMDB如何在故障管理、变更管理和云原生环境中发挥作用，并通过行业案例展示其价值。让我们走进CMDB的业务世界，看它如何成为IT与业务之间的桥梁。\n一、典型场景 CMDB的应用贯穿IT管理的多个环节，以下是几个关键场景：\n1.1 故障管理：快速定位根源 场景：系统宕机时，运维团队需快速识别受影响的范围。 CMDB作用： 通过拓扑图查看故障CI（如服务器）的上下游依赖。 关联事件日志，定位根因（如数据库瓶颈）。 收益：缩短平均修复时间（MTTR），减少业务损失。 1.2 变更管理：评估影响范围 场景：升级应用程序前，需评估潜在风险。 CMDB作用： 查询依赖该应用的CI（如服务器、数据库）。 模拟变更影响，生成风险报告。 收益：降低变更失败率，提升系统稳定性。 1.3 云原生环境：动态管理复杂性 场景：容器化环境中，资源频繁创建和销毁。 CMDB作用： 集成K8s API，实时更新Pod、Service等CI。 提供动态拓扑，追踪微服务依赖。 收益：支持敏捷开发，保障服务可用性。 二、行业案例 CMDB的应用因行业而异，以下是两个典型案例。\n2.1 金融行业：支持高可用性需求 背景：某银行核心交易系统需7×24小时运行，任何中断都会造成重大损失。 CMDB应用： 资产管理：记录所有服务器、网络设备及其配置。 故障恢复：宕机时，通过CMDB快速切换至备用节点。 合规性：记录变更历史，满足监管审计要求。 实施细节： 数据库：PostgreSQL存储CI属性，Neo4j管理关系。 采集：集成Nagios自动发现，每5分钟同步。 结果：故障恢复时间从30分钟缩短至10分钟，年损失减少数百万。 启示：金融行业需强调CMDB的实时性和可靠性。 2.2 电商行业：快速扩展中的作用 背景：某电商平台在促销季（如“双十一”）需快速扩容。 CMDB应用： 容量规划：分析现有资源利用率，预测扩容需求。 服务映射：梳理微服务间的依赖，确保扩容不影响业务。 自动化部署：与CI/CD流水线集成，动态更新CMDB。 实施细节： 技术栈：MongoDB存储动态CI，Redis缓存热点数据。 集成：通过AWS API采集云资源，每小时更新。 结果：促 …","date":1569759537,"description":"","fuzzywordcount":1500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"68e958a514da7436bb13903d7424159a","publishdate":1569759537,"relpermalink":"/posts/cmdb/cmdb6/","section":"posts","summary":"\u003ch4 id=\"引言\"\u003e引言\u003c/h4\u003e\n\u003cp\u003eCMDB的最终目标是为业务服务，而非仅仅停留在技术层面。经过前五篇的探讨，我们已经了解了CMDB的设计、实现、治理和优化，本文将转向其实际应用，揭示CMDB如何在故障管理、变更管理和云原生环境中发挥作用，并通过行业案例展示其价值。让我们走进CMDB的业务世界，看它如何成为IT与业务之间的桥梁。\u003c/p\u003e","tags":["CMDB","配置管理","故障管理","变更管理","云原生"],"title":"CMDB设计专题系列 第六篇：CMDB的业务应用与案例","url":"https://yinlongfei.com/posts/cmdb/cmdb6/","wordcount":1498},{"categories":"posts","content":"引言 CMDB的建设并非终点，如何在上线后保持其活力和高效性才是真正的挑战。在前几篇文章中，我们探讨了CMDB的设计原则、技术实现和数据治理，本文将转向运维与优化，分享如何通过日常管理、性能提升和持续改进，确保CMDB始终为IT管理和业务决策提供可靠支持。\n一、日常运维 CMDB上线后的首要任务是保持数据的实时性与可用性。\n1.1 数据同步与实时更新 同步机制： 定时同步：每日与监控系统（如Zabbix）或云平台（如AWS）同步CI数据。 事件驱动：通过Webhook监听外部变更（如设备下线）实时更新。 实现方式： 部署ETL（提取-转换-加载）工具，从源系统拉取数据。 示例：一个简单的Python脚本定期检查服务器状态： import requests response = requests.get(\u0026amp;#34;http://monitor-api/status\u0026amp;#34;) for server in response.json(): update_cmdb(server[\u0026amp;#34;id\u0026amp;#34;], server[\u0026amp;#34;status\u0026amp;#34;]) 注意事项：避免频繁同步影响性能，设置合理的更新频率。 1.2 异常检测与告警 异常类型： CI状态异常：如“运行中”的服务器未响应。 关系异常：如依赖的数据库已废弃。 解决方案： 配置规则引擎，定期扫描CMDB数据。 集成告警系统（如Prometheus Alertmanager），推送异常通知。 示例告警： Alert: Server-001 offline but marked as running 二、性能优化 随着CI数量和关系复杂度的增加，CMDB性能可能成为瓶颈。\n2.1 查询优化 索引：为高频查询字段（如CI名称、状态）建立索引。 示例SQL：CREATE INDEX idx_ci_name ON ci_table(name); 分区：按CI类型或区域分表，提升查询速度。 预聚合：为常用统计（如“在线服务器数量”）生成视图，减少实时计算。 2.2 缓存策略 热点数据缓存： 用Redis存储频繁访问的CI（如核心服务拓扑）。 示例：SET ci:001 \u0026#39;{\u0026amp;quot;name\u0026amp;quot;: \u0026amp;quot;Server-001\u0026amp;quot;, \u0026amp;quot;status\u0026amp;quot;: …","date":1568981937,"description":"","fuzzywordcount":1400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"6ee83535766af994a78c32a844c60560","publishdate":1568981937,"relpermalink":"/posts/cmdb/cmdb5/","section":"posts","summary":"\u003ch4 id=\"引言\"\u003e引言\u003c/h4\u003e\n\u003cp\u003eCMDB的建设并非终点，如何在上线后保持其活力和高效性才是真正的挑战。在前几篇文章中，我们探讨了CMDB的设计原则、技术实现和数据治理，本文将转向运维与优化，分享如何通过日常管理、性能提升和持续改进，确保CMDB始终为IT管理和业务决策提供可靠支持。\u003c/p\u003e","tags":["CMDB","配置管理"],"title":"CMDB设计专题系列 第五篇：CMDB的运维与优化","url":"https://yinlongfei.com/posts/cmdb/cmdb5/","wordcount":1346},{"categories":"posts","content":"引言 CMDB的成功不仅取决于设计和技术实现，更在于数据的质量和可持续性。一个充满错误、过时或不一致数据的CMDB不仅无法发挥价值，还可能误导决策。在前几篇文章中，我们探讨了CMDB的价值、设计原则和技术实现，本文将聚焦数据治理——如何通过流程、技术和组织手段，确保CMDB成为可靠的“单一事实来源”。\n一、数据质量管理 数据质量是CMDB的生命线，治理的第一步是确保数据的准确性、一致性和完整性。\n1.1 数据清洗 CMDB数据可能来自多个来源（如自动发现工具、手动录入），难免出现问题：\n重复：同一服务器在不同系统中被记录多次。 缺失：关键属性（如IP地址）未填写。 不一致：一台设备的状态在监控系统中是“在线”，在CMDB中却是“下线”。 解决方法： 去重：通过唯一标识（如设备序列号、资产编号）合并重复CI。 补全：设置必填字段，或通过关联系统补全数据。 校验：定期比对CMDB与实际环境，识别差异。 1.2 数据验证 确保数据输入时的正确性：\n格式检查：如IP地址必须符合“xxx.xxx.xxx.xxx”格式。 逻辑校验：如“运行中”的CI不能依赖“已废弃”的CI。 自动化脚本：编写规则引擎，实时验证数据。例如： if (ci.status == \u0026amp;#34;running\u0026amp;#34; \u0026amp;amp;\u0026amp;amp; dependency.status == \u0026amp;#34;retired\u0026amp;#34;) { alert(\u0026amp;#34;依赖关系异常\u0026amp;#34;); } 二、生命周期管理 CI并非一成不变，治理需覆盖其全生命周期。\n2.1 CI的创建、更新与废弃 创建：新设备上线时，通过审批流程录入CMDB。 更新：状态或属性变化时（如版本升级），自动或手动同步。 废弃：设备下线后标记为“退役”，保留历史记录。 流程示例： 运维人员提交“新服务器上线”请求。 系统自动发现并录入CI。 审核通过后生效。 2.2 版本控制与历史追踪 版本控制：每次CI变更生成新版本，记录修改时间和原因。 历史追踪：保留变更日志，便于审计和回溯。 实现方式： 用数据库表存储版本（如“ci_history”表）。 示例表结构： ci_id | attribute | old_value | new_value | timestamp | operator 1 | status | offline | online | …","date":1568895537,"description":"","fuzzywordcount":1600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"e1049af6ddb66d14d7a8af879b83d47d","publishdate":1568895537,"relpermalink":"/posts/cmdb/cmdb4/","section":"posts","summary":"\u003ch4 id=\"引言\"\u003e引言\u003c/h4\u003e\n\u003cp\u003eCMDB的成功不仅取决于设计和技术实现，更在于数据的质量和可持续性。一个充满错误、过时或不一致数据的CMDB不仅无法发挥价值，还可能误导决策。在前几篇文章中，我们探讨了CMDB的价值、设计原则和技术实现，本文将聚焦数据治理——如何通过流程、技术和组织手段，确保CMDB成为可靠的“单一事实来源”。\u003c/p\u003e","tags":["CMDB","数据治理","CI"],"title":"CMDB设计专题系列 第四篇：CMDB的数据治理","url":"https://yinlongfei.com/posts/cmdb/cmdb4/","wordcount":1548},{"categories":"posts","content":"引言 在前两篇文章中，我们明确了CMDB的核心价值和设计原则。然而，一个优秀的CMDB不仅需要理论支撑，更需要通过技术手段将其变为现实。从数据库选型到数据采集，再到系统架构，CMDB的实现过程充满了技术挑战和决策。本文将带你走进CMDB的技术世界，探讨如何将其从概念转化为可用的工具。\n一、技术选型 CMDB的实现首先需要选择合适的技术栈，这直接影响系统的性能、扩展性和维护成本。\n1.1 数据库选择 CMDB的核心是数据存储，数据库的选择至关重要：\n关系型数据库（如MySQL、PostgreSQL） 优点：结构化数据支持良好，适合属性明确的CI；事务一致性强。 缺点：复杂关系（如多对多）查询效率较低，扩展性有限。 适用场景：中小型企业，CI类型和关系较简单。 NoSQL数据库（如MongoDB、Neo4j） MongoDB：文档型数据库，适合灵活的CI属性扩展。 Neo4j：图数据库，擅长处理CI之间的复杂关系（如拓扑结构）。 优点：高扩展性，支持动态模型。 缺点：学习曲线较陡，事务支持可能不如关系型数据库。 适用场景：大型企业或云原生环境，需要频繁查询关系。 混合方案：用关系型数据库存储CI属性，用图数据库存储关系。 建议：初期可选择MySQL快速上手，随着关系复杂度增加，逐步引入Neo4j。\n1.2 工具选择 除了自建CMDB，企业还可以借助现有工具：\n开源工具： iTop：基于ITIL，支持CI管理和关系建模，适合中小企业。 Ralph：轻量级资产管理工具，可扩展为CMDB。 优点：免费，社区支持。 缺点：功能有限，定制化需开发。 商业解决方案： ServiceNow：功能强大，集成ITSM全流程。 BMC Atrium：企业级CMDB，适合复杂环境。 优点：开箱即用，支持丰富。 缺点：成本高，依赖供应商。 自建 vs 现成：若业务需求独特或预算有限，自建更灵活；若追求快速部署，商业工具更高效。 二、数据采集与集成 CMDB的价值在于数据的全面性和准确性，如何采集和整合数据是关键。\n2.1 自动发现工具 手动录入数据显然不现实，自动发现是CMDB的生命线：\n网络发现：如Nagios、Zabbix，扫描IP段获取设备信息。 云发现：AWS Config、Azure Resource Manager，采集云资源。 应用发现：通过代理（如Chef、Puppet）获取软 …","date":1568290737,"description":"","fuzzywordcount":1900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"e65f50794f3c9530d016215ec02e7761","publishdate":1568290737,"relpermalink":"/posts/cmdb/cmdb3/","section":"posts","summary":"\u003ch4 id=\"引言\"\u003e引言\u003c/h4\u003e\n\u003cp\u003e在前两篇文章中，我们明确了CMDB的核心价值和设计原则。然而，一个优秀的CMDB不仅需要理论支撑，更需要通过技术手段将其变为现实。从数据库选型到数据采集，再到系统架构，CMDB的实现过程充满了技术挑战和决策。本文将带你走进CMDB的技术世界，探讨如何将其从概念转化为可用的工具。\u003c/p\u003e","tags":["CMDB","配置管理","MySQL"],"title":"CMDB设计专题系列 第三篇：CMDB的技术实现","url":"https://yinlongfei.com/posts/cmdb/cmdb3/","wordcount":1872},{"categories":"posts","content":"引言 在上一篇文章中，我们介绍了CMDB的基本概念和核心价值。作为IT管理的“活地图”，CMDB的成功不仅依赖于技术实现，更源于清晰的设计原则。一个优秀的设计能确保CMDB既满足当前需求，又具备未来扩展的能力。本文将聚焦CMDB的核心设计原则，探讨如何构建一个模块化、可扩展且实用的配置管理数据库。\n一、模块化与层次化设计 CMDB的核心在于管理配置项（CI）及其关系，而模块化与层次化是设计的基础。\n1.1 配置项（CI）的定义与分类 配置项（CI）是CMDB的最小单元，可以是任何需要管理的IT资源。常见的CI类型包括：\n硬件：服务器、网络设备、存储设备等。 软件：操作系统、应用程序、中间件等。 服务：Web服务、数据库服务等。 逻辑实体：业务流程、文档、合同等。 设计时需明确：\n颗粒度：CI定义过细（如每个硬盘）会导致管理复杂，过粗（如整个数据中心）则失去意义。建议根据业务需求选择适当颗粒度。 分类体系：通过层次化分类（如“硬件 \u0026amp;gt; 服务器 \u0026amp;gt; 物理服务器”）提高可管理性。 1.2 CI之间的关系建模 CI的价值在于它们之间的关系。常见关系包括：\n依赖关系：如“应用程序A依赖数据库B”。 包含关系：如“服务器C包含操作系统D”。 连接关系：如“交换机E连接服务器F”。 设计时需：\n定义关系的类型和方向（如单向或双向）。 确保关系的可追溯性，例如通过拓扑图可视化。 1.3 模块化设计的好处 将CI和关系模块化，可以：\n独立维护每个模块，降低耦合。 按需扩展，例如新增云服务模块时不影响现有体系。 二、数据模型设计 CMDB本质是一个数据系统，其核心是数据模型的设计。\n2.1 属性设计 每个CI需要一组属性来描述其特征。设计属性时：\n必要性：选择关键属性（如名称、IP地址、版本号、状态），避免冗余。 标准化：确保属性命名和格式一致（如“IP”而非“ip_address”）。 动态性：支持属性扩展，例如为新设备类型添加“云厂商”字段。 示例：一台服务器的属性可能包括：\n名称：Server-001 IP地址：192.168.1.10 状态：在线 所有者：IT部门 2.2 关系设计 关系的建模需要考虑：\n一对一：如“虚拟机与操作系统”。 一对多：如“服务器与多个应用程序”。 多对多：如“多个服务依赖多个数据库”。 建议使用关系表或图数据库（如Neo4j）存储复杂关 …","date":1568031537,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"06602ce70338a28352b48331c1a2629d","publishdate":1568031537,"relpermalink":"/posts/cmdb/cmdb2/","section":"posts","summary":"\u003ch4 id=\"引言\"\u003e引言\u003c/h4\u003e\n\u003cp\u003e在上一篇文章中，我们介绍了CMDB的基本概念和核心价值。作为IT管理的“活地图”，CMDB的成功不仅依赖于技术实现，更源于清晰的设计原则。一个优秀的设计能确保CMDB既满足当前需求，又具备未来扩展的能力。本文将聚焦CMDB的核心设计原则，探讨如何构建一个模块化、可扩展且实用的配置管理数据库。\u003c/p\u003e","tags":["CMDB","配置管理"],"title":"CMDB设计专题系列 第二篇：CMDB的核心设计原则","url":"https://yinlongfei.com/posts/cmdb/cmdb2/","wordcount":1726},{"categories":"posts","content":"引言 在现代IT环境中，基础设施的复杂性与日俱增：从传统的物理服务器到虚拟化，再到如今的クラウド、容器和微服务，IT资产和服务的数量与类型呈指数级增长。如何有效地管理这些资源，确保系统的高可用性，并支持业务快速迭代？答案之一便是CMDB——配置管理数据库（Configuration Management Database）。本文将带你走进CMDB的世界，探讨它的定义、价值以及设计过程中的核心挑战。\n一、什么是CMDB？ CMDB，全称配置管理数据库，是IT服务管理（ITSM）中的核心组件，用于存储和管理IT环境中的配置项（Configuration Item，简称CI）及其关系。简单来说，CMDB是一个“活的地图”，记录了企业IT基础设施的全貌。\n1.1 定义与组成 配置项（CI）：CMDB的基本单元，可以是硬件（如服务器、路由器）、软件（如操作系统、应用程序）、服务（如数据库服务、Web服务），甚至是文档（如设计图纸、合同）。 关系：CI之间的连接，比如“服务器A运行应用程序B”或“数据库C依赖存储D”。 属性：每个CI的详细信息，如名称、IP地址、版本号、所有者等。 1.2 与ITIL的关系 CMDB的概念源于ITIL（信息技术基础架构库），是ITIL配置管理流程的核心工具。ITIL强调通过CMDB实现IT资源的透明化管理，从而支持变更管理、事件管理等流程。虽然CMDB常与ITIL绑定，但它的应用早已超越ITIL框架，成为现代IT管理的通用工具。\n1.3 CMDB与资产管理的区别 很多人容易混淆CMDB和资产管理。简单来说：\n资产管理关注资源的物理或财务属性，比如设备的采购成本、折旧情况。 CMDB更关注资源的逻辑关系和运行状态，比如一台服务器如何支撑某个业务应用。 两者可以互补，但CMDB的视角更偏向技术与服务。 二、CMDB的核心价值 CMDB不仅仅是一个数据库，它的价值在于为IT管理和业务决策提供支持。以下是几个关键点：\n2.1 单一事实来源（Single Source of Truth） 在一个复杂的IT环境中，信息分散在多个系统（如监控工具、票务系统、文档）中，难免出现数据不一致。CMDB通过集中管理配置数据，确保所有团队基于相同的事实工作。例如，当发生故障时，运维人员可以快速确认受影响的系统范围，而不是依赖过时的Excel表格。\n2.2 支持IT服务 …","date":1567426737,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"7129efb64e57f62e59ab13f4f0173bc4","publishdate":1567426737,"relpermalink":"/posts/cmdb/cmdb1/","section":"posts","summary":"\u003ch4 id=\"引言\"\u003e引言\u003c/h4\u003e\n\u003cp\u003e在现代IT环境中，基础设施的复杂性与日俱增：从传统的物理服务器到虚拟化，再到如今的クラウド、容器和微服务，IT资产和服务的数量与类型呈指数级增长。如何有效地管理这些资源，确保系统的高可用性，并支持业务快速迭代？答案之一便是CMDB——配置管理数据库（Configuration Management Database）。本文将带你走进CMDB的世界，探讨它的定义、价值以及设计过程中的核心挑战。\u003c/p\u003e","tags":["CMDB","配置管理","ITSM","ITIL","资产管理"],"title":"CMDB设计专题系列 第一篇：CMDB概述与核心价值","url":"https://yinlongfei.com/posts/cmdb/cmdb1/","wordcount":1782},{"categories":"posts","content":"CMDB设计专题系列：从概念到实践 第一篇：CMDB概述与核心价值 什么是CMDB？ 定义：配置管理数据库（Configuration Management Database）的概念。 与ITIL（信息技术基础架构库）的关系。 CMDB与资产管理、变更管理的区别与联系。 CMDB的核心价值 提供IT环境的单一事实来源（Single Source of Truth）。 支持IT服务管理（ITSM）、运维自动化和决策分析。 案例：CMDB在企业中的典型应用场景（如故障排查、容量规划）。 设计CMDB的挑战 数据一致性、准确性和实时性。 如何平衡复杂性与实用性。 第二篇：CMDB的核心设计原则 模块化与层次化设计 配置项（CI）的定义与分类（如硬件、软件、服务、文档等）。 CI之间的关系建模（依赖、关联、层级）。 数据模型设计 属性设计：如何定义CI的关键属性（名称、版本、状态、所有者等）。 关系设计：一对一、一对多、多对多的关系处理。 扩展性：支持未来新增CI类型的需求。 设计原则 标准化：遵循行业标准（如ITIL、ISO 20000）。 灵活性：适应不同规模企业的需求。 可视化：数据如何支持图形化展现（如拓扑图）。 第三篇：CMDB的技术实现 技术选型 数据库选择：关系型（如MySQL、PostgreSQL）还是NoSQL（如MongoDB、Neo4j）。 工具选择：开源CMDB工具（如iTop、Ralph）与商业解决方案（如ServiceNow）的对比。 数据采集与集成 自动发现工具（如Zabbix、Nagios）的集成。 API设计：与现有IT系统的对接。 数据导入：手动录入与自动化采集的平衡。 架构设计 单体架构 vs 微服务架构。 高可用性与分布式设计的考虑。 示例：一个简单的CMDB架构图。 第四篇：CMDB的数据治理 数据质量管理 数据清洗：处理重复、缺失、不一致的CI。 数据验证：确保CI属性和关系的准确性。 生命周期管理 CI的创建、更新、废弃流程。 版本控制与历史追踪。 权限与访问控制 谁可以查看、编辑CMDB数据？ 基于角色的访问控制（RBAC）设计。 审计与合规性 如何记录操作日志。 满足法律法规和企业政策的要求。 第五篇：CMDB的运维与优化 日常运维 数据同步与实时更新机制。 异常检测与告警（如CI状态异常）。 性能优化 查询优化：处理大规 …","date":1567081137,"description":"","fuzzywordcount":1300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"67ddb4d17dee88db5ede6046f8c1b0be","publishdate":1567081137,"relpermalink":"/posts/cmdb/cmdbtoc/","section":"posts","summary":"\u003ch3 id=\"cmdb设计专题系列从概念到实践\"\u003eCMDB设计专题系列：从概念到实践\u003c/h3\u003e\n\u003ch4 id=\"第一篇cmdb概述与核心价值\"\u003e第一篇：CMDB概述与核心价值\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e什么是CMDB？\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e定义：配置管理数据库（Configuration Management Database）的概念。\u003c/li\u003e\n\u003cli\u003e与ITIL（信息技术基础架构库）的关系。\u003c/li\u003e\n\u003cli\u003eCMDB与资产管理、变更管理的区别与联系。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCMDB的核心价值\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e提供IT环境的单一事实来源（Single Source of Truth）。\u003c/li\u003e\n\u003cli\u003e支持IT服务管理（ITSM）、运维自动化和决策分析。\u003c/li\u003e\n\u003cli\u003e案例：CMDB在企业中的典型应用场景（如故障排查、容量规划）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e设计CMDB的挑战\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e数据一致性、准确性和实时性。\u003c/li\u003e\n\u003cli\u003e如何平衡复杂性与实用性。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch4 id=\"第二篇cmdb的核心设计原则\"\u003e第二篇：CMDB的核心设计原则\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e模块化与层次化设计\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e配置项（CI）的定义与分类（如硬件、软件、服务、文档等）。\u003c/li\u003e\n\u003cli\u003eCI之间的关系建模（依赖、关联、层级）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e数据模型设计\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e属性设计：如何定义CI的关键属性（名称、版本、状态、所有者等）。\u003c/li\u003e\n\u003cli\u003e关系设计：一对一、一对多、多对多的关系处理。\u003c/li\u003e\n\u003cli\u003e扩展性：支持未来新增CI类型的需求。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e设计原则\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e标准化：遵循行业标准（如ITIL、ISO 20000）。\u003c/li\u003e\n\u003cli\u003e灵活性：适应不同规模企业的需求。\u003c/li\u003e\n\u003cli\u003e可视化：数据如何支持图形化展现（如拓扑图）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch4 id=\"第三篇cmdb的技术实现\"\u003e第三篇：CMDB的技术实现\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e技术选型\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e数据库选择：关系型（如MySQL、PostgreSQL）还是NoSQL（如MongoDB、Neo4j）。\u003c/li\u003e\n\u003cli\u003e工具选择：开源CMDB工具（如iTop、Ralph）与商业解决方案（如ServiceNow）的对比。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e数据采集与集成\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e自动发现工具（如Zabbix、Nagios）的集成。\u003c/li\u003e\n\u003cli\u003eAPI设计：与现有IT系统的对接。\u003c/li\u003e\n\u003cli\u003e数据导入：手动录入与自动化采集的平衡。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e架构设计\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e单体架构 vs 微服务架构。\u003c/li\u003e\n\u003cli\u003e高可用性与分布式设计的考虑。\u003c/li\u003e\n\u003cli\u003e示例：一个简单的CMDB架构图。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch4 id=\"第四篇cmdb的数据治理\"\u003e第四篇：CMDB的数据治理\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e数据质量管理\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e数据清洗：处理重复、缺失、不一致的CI。\u003c/li\u003e\n\u003cli\u003e数据验证：确保CI属性和关系的准确性。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e生命周期管理\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eCI的创建、更新、废弃流程。\u003c/li\u003e\n\u003cli\u003e版本控制与历史追踪。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e权限与访问控制\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e谁可以查看、编辑CMDB数据？\u003c/li\u003e\n\u003cli\u003e基于角色的访问控制（RBAC）设计。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e审计与合规性\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e如何记录操作日志。\u003c/li\u003e\n\u003cli\u003e满足法律法规和企业政策的要求。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch4 id=\"第五篇cmdb的运维与优化\"\u003e第五篇：CMDB …\u003c/h4\u003e","tags":["CMDB","配置管理"],"title":"CMDB设计专题系列：从概念到实践","url":"https://yinlongfei.com/posts/cmdb/cmdbtoc/","wordcount":1231},{"categories":"posts","content":"postcss 的一大特点是，具体的编译插件甚至是css书写风格，可以根据自己的需要进行安装，选择自己需要的特性：嵌套，函数，变量。自动补全，CSS新特性等等，而不用像less或者scss一样的大型全家桶，因此不需要专门学习less或者sass的语阿伐了，只要选择自己喜欢的特性，可以只写css文件，但依旧可以写嵌套或者函数，然后根据情况选择和是的插件就行了。\npostcss.config.js配置 配置简单，只是用了autoprefixer，进行浏览器兼容补全\n1 2 3 4 5 module.exports = { plugins: [ require(\u0026amp;#39;autoprefixer\u0026amp;#39;) ] } webpack 配合 在packjson.json 中配置webpackloader，具体配置如下\n1 \u0026amp;#34;postcss-loader\u0026amp;#34;: \u0026amp;#34;3.0.0\u0026amp;#34;, 配合scss做一些工作，比如mincss配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 { test: /\\.scss$/, use: [\u0026amp;#39;to-string-loader\u0026amp;#39;, \u0026amp;#39;css-loader\u0026amp;#39;, { loader: \u0026amp;#39;sass-loader\u0026amp;#39;, options: { implementation: sass } }], exclude: /(vendor\\.scss|global\\.scss)/ }, { test: /(vendor\\.scss|global\\.scss)/, use: [ { loader: MiniCssExtractPlugin.loader, options: { publicPath: \u0026amp;#39;../\u0026amp;#39; } }, \u0026amp;#39;css-loader\u0026amp;#39;, \u0026amp;#39;postcss-loader\u0026amp;#39;, { loader: \u0026amp;#39;sass-loader\u0026amp;#39;, options: { implementation: sass } } ] }, { test: …","date":1558786737,"description":"","fuzzywordcount":500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"250e11a0c23699547297514c58f52b36","publishdate":1558786737,"relpermalink":"/posts/jhipster/jhipster-postcss.config/","section":"posts","summary":"\u003cp\u003epostcss 的一大特点是，具体的编译插件甚至是css书写风格，可以根据自己的需要进行安装，选择自己需要的特性：嵌套，函数，变量。自动补全，CSS新特性等等，而不用像less或者scss一样的大型全家桶，因此不需要专门学习less或者sass的语阿伐了，只要选择自己喜欢的特性，可以只写css文件，但依旧可以写嵌套或者函数，然后根据情况选择和是的插件就行了。\u003c/p\u003e","tags":["jhipster","postcss"],"title":"Jhipster 项目之架构分析之postcss.config.js","url":"https://yinlongfei.com/posts/jhipster/jhipster-postcss.config/","wordcount":416},{"categories":"posts","content":"上手Knative的 - 第2部分 在我之前的文章中 ，我谈到了 Knative Serving ，用于快速部署和无服务器容器的自动扩展。 如果您希望HTTP呼叫同步触发您的服务，Knative Serving非常棒。 但是，在无服务器的微服务世界中，异步触发器更常见且更有用。 那是 Knative Eventing 发挥作用的时候。\n在Hands on Knative系列的第二部分中，我想介绍Knative Eventing并在我的 Knative Tutorial 中展示如何将其与各种服务集成的 一些示例 。\n什么是Knative Eventing？ Knative Eventing与Knative Serving携手合作，为松散耦合的事件驱动服务提供原语。 典型的Knative Eventing架构如下所示：\n有4个主要组成部分：\nSource （aka Producer）从实际源读取事件并将下游转发到Channel或更不常见地直接转发到Service。 频道 从源接收事件，保存到其底层存储（稍后将详细介绍）并向所有订户扇出。 订阅 桥接通道和服务（或另一个通道）。 服务 （又名消费者）是消费事件流的Knative服务。 让我们更详细地看一下这些。\n来源，渠道和订阅 Knative Eventing的最终目标是将事件从源路由到服务，并使用我之前提到的原语来实现：Source，Channel和Subscription。\nSource 从实际源读取事件并将其转发到下游。 截至今天，Knative支持从 Kubernetes ， GitHub ， Google Cloud Pub / Sub ， AWS SQS主题 ， 容器 和 CronJobs中 读取事件 。\n一旦事件被拉入Knative，它需要保存在内存中或更耐用的地方，如Kafka或Google Cloud Pub / Sub。 通道 发生了这种情况**。** 它有多种 实现 来支持不同的选项。\n来自频道，该活动将传递给所有感兴趣的Knative Services或其他频道。 这可能是一对一或扇出。 订阅 确定了此传递的性质，并且充当了Channel和Knative服务之间的桥梁。\n现在我们已经了解了Knative事件的基础知识，让我们来看一个具体的例子。\nHello World Eventing 对 …","date":1551788337,"description":"上手Knative的 - 第2部分","fuzzywordcount":2700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"0d5ac28ae2dc02847972b88626371f27","publishdate":1551788337,"relpermalink":"/posts/translations/serveless/knative/hands-on-knative-part-2/","section":"posts","summary":"\u003ch1 id=\"上手knative的---第2部分\"\u003e上手Knative的 - 第2部分\u003c/h1\u003e\n\u003cp\u003e在我\u003ca href=\"https://yinlongfei.com/posts/hands-on-knative-part-1/\"\u003e之前的文章中\u003c/a\u003e ，我谈到了 \u003ca href=\"https://github.com/knative/docs/tree/master/serving\"\u003eKnative Serving\u003c/a\u003e ，用于快速部署和无服务器容器的自动扩展。 如果您希望HTTP呼叫同步触发您的服务，Knative Serving非常棒。 但是，在无服务器的微服务世界中，异步触发器更常见且更有用。 那是 \u003ca href=\"https://github.com/knative/docs/tree/master/eventing\"\u003eKnative Eventing\u003c/a\u003e 发挥作用的时候。\u003c/p\u003e","tags":["Knative","kubernetes"],"title":"上手Knative的 - 第2部分","url":"https://yinlongfei.com/posts/translations/serveless/knative/hands-on-knative-part-2/","wordcount":2628},{"categories":"posts","content":"上手Knative的 - 第1部分 我最近一直在研究 Knative 。这个博客系列由3部分组成，我想解释一下我的学习内容并展示我在GitHub上发布的Knative Tutorial 中的示例 。\n什么是Knative？ Knative 是一个开源构建块的集合，用于在Kubernetes上运行的serverless容器。\n在这一点上，你可能想知道：“Kubernetes，serverless，发生了什么？”但是，当你想到它时，它是有道理的。Kubernetes是非常受欢迎的容器管理平台。serverless是应用程序开发人员想要运行其代码的方式。Knative将两个世界与一组构建块结合在一起。\n谈到构建块，它由3个主要组件组成：\nKnative Serving 用于快速部署和serverless容器的自动扩展。 Knative Eventing针对松散耦合的事件驱动服务的。 Knative Build 用于无痛的代码到容器的注册表工作流程。 让我们从Knative Serving开始吧。\n什么是Knative Serving？ 简而言之，Knative Serving允许serverless容器的快速部署和自动扩展。您只需指定要部署的容器，Knative将详细说明如何创建该容器并将流量路由到该容器。将serverless容器部署为Knative服务后，您将获得自动扩展，每个配置更改的revision，不同revision之间的流量分配等功能。\n你好世界服务 要将代码部署为Knative服务，您需要：\n包含您的代码并将镜像推送到公共注册表。 创建一个服务yaml文件，告诉Knative在哪里可以找到容器镜像及其具有的任何配置。 在我的Knative教程的 Hello World服务 中，我详细描述了这些步骤，但回顾一下，这是最小的Knative服务定义的 service-v1.yaml 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 apiVersion: serving.knative.dev/v1alpha1 kind: Service metadata: name: helloworld-csharp namespace: default spec: runLatest: configuration: …","date":1551701937,"description":"上手Knative的 - 第1部分","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"0fbbd5c8b0910e4c86be2f6f3ea3c33a","publishdate":1551701937,"relpermalink":"/posts/translations/serveless/knative/hands-on-knative-part-1/","section":"posts","summary":"\u003ch1 id=\"上手knative的---第1部分\"\u003e上手Knative的 - 第1部分\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"https://ws1.sinaimg.cn/large/61411417ly1g0r1zpj6jjj205k05kaa3.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e我最近一直在研究 \u003ca href=\"https://github.com/knative/docs\"\u003eKnative\u003c/a\u003e 。这个博客系列由3部分组成，我想解释一下我的学习内容并展示我在GitHub上发布的\u003ca href=\"https://github.com/meteatamel/knative-tutorial\"\u003eKnative Tutorial\u003c/a\u003e 中的示例 。\u003c/p\u003e","tags":["Knative","kubernetes"],"title":"上手Knative的 - 第1部分","url":"https://yinlongfei.com/posts/translations/serveless/knative/hands-on-knative-part-1/","wordcount":1679},{"categories":"posts","content":"Gatling 系列专题（第六篇）：最佳实践与测试策略优化 前言 经过前五篇的探索，我们从 Gatling 的基础安装到 CI/CD 集成与分布式测试，逐步构建了对这款性能测试工具的全面认知。本篇作为系列的收尾，将总结使用 Gatling 的最佳实践，并提供优化测试策略的实用建议，帮助你在实际项目中发挥其最大价值。\n最佳实践总结 脚本设计\n模块化：将 HTTP 协议配置、场景和数据源分离，便于复用和维护。例如，将公共配置提取到单独文件中： 1 2 3 object Config { val httpProtocol = http.baseUrl(\u0026amp;#34;https://example.com\u0026amp;#34;) } 动态数据：使用 Feeder（如 CSV、JSON）模拟真实用户输入，避免硬编码。 检查点：为每个关键请求添加 check，验证状态码或响应内容，确保测试有效性。 负载模式\n逐步递增：使用 rampUsers 模拟真实流量增长，避免瞬间压垮服务器。 场景分层：为不同用户行为设置独立场景（如登录用户 vs 匿名用户），分别测试。 预热阶段：在正式测试前加入低负载预热（如 constantUsersPerSec(1).during(30.seconds)），让服务器缓存和连接池稳定。 资源管理\n调整 JVM 参数：对于大规模测试，修改 gatling.conf 或启动脚本，增加内存（如 -Xmx4g）。 避免本地干扰：在专用测试机上运行 Gatling，避免与开发环境竞争资源。 清理结果：定期删除旧报告，防止磁盘占满。 报告与分析\n自定义指标：在脚本中添加特定断言，关注业务关键点（如支付成功率）。 基线对比：保存每次测试的报告，建立性能基线，检测退化。 团队共享：将报告上传到 CI/CD 或云存储，便于协作。 优化测试策略 明确测试目标\n容量测试：确定系统最大承受用户数（例如，找到吞吐量下降的拐点）。 压力测试：模拟超出正常负载的场景，观察崩溃点。 稳定性测试：长时间运行（如 24 小时），检测内存泄漏或连接问题。 贴近真实场景\n用户行为建模：参考生产日志，分析真实用户的请求频率和路径。 地理分布：在分布式测试中模拟不同地区的延迟（需配合网络工具）。 设备多样性：通过 userAgentHeader 模拟不同浏览器或移动设备。 迭代优化\n小步快跑：从少量用户开始， …","date":1551615537,"description":"","fuzzywordcount":1400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"11e6510764a24d710944badb9c4711e0","publishdate":1551615537,"relpermalink":"/posts/test/gatling/gatling6/","section":"posts","summary":"\u003ch3 id=\"gatling-系列专题第六篇最佳实践与测试策略优化\"\u003eGatling 系列专题（第六篇）：最佳实践与测试策略优化\u003c/h3\u003e\n\u003ch4 id=\"前言\"\u003e前言\u003c/h4\u003e\n\u003cp\u003e经过前五篇的探索，我们从 Gatling 的基础安装到 CI/CD 集成与分布式测试，逐步构建了对这款性能测试工具的全面认知。本篇作为系列的收尾，将总结使用 Gatling 的最佳实践，并提供优化测试策略的实用建议，帮助你在实际项目中发挥其最大价值。\u003c/p\u003e","tags":["测试","性能测试","gatling","自动化"],"title":"Gatling 系列专题（第六篇）：最佳实践与测试策略优化","url":"https://yinlongfei.com/posts/test/gatling/gatling6/","wordcount":1304},{"categories":"posts","content":"Gatling 系列专题（第五篇）：CI/CD 集成与分布式测试 前言 通过前四篇，我们已经掌握了 Gatling 的安装、脚本编写和报告分析。现在，让我们将性能测试提升到新高度：将其融入持续集成与持续部署（CI/CD）流程，并探索分布式测试以应对大规模负载。本篇将帮助你实现自动化性能验证，确保应用在每次迭代中都能保持高效。\n为什么需要 CI/CD 集成？ 在现代开发中，代码频繁变更可能无意中引入性能问题。手动运行 Gatling 测试效率低下且容易遗漏。将 Gatling 集成到 CI/CD 管道，可以：\n自动化测试：每次提交或部署时自动验证性能。 快速反馈：及时发现性能退化。 质量保障：确保上线版本满足性能标准。 步骤 1：准备 Gatling 项目 Maven 或 SBT 项目： Gatling 支持 Maven 和 SBT（Scala 构建工具）。推荐使用 Maven 创建一个独立的 Gatling 项目。 示例 pom.xml： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026amp;lt;project\u0026amp;gt; \u0026amp;lt;modelVersion\u0026amp;gt;4.0.0\u0026amp;lt;/modelVersion\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;com.example\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;gatling-tests\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;1.0-SNAPSHOT\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;dependencies\u0026amp;gt; \u0026amp;lt;dependency\u0026amp;gt; \u0026amp;lt;groupId\u0026amp;gt;io.gatling.highcharts\u0026amp;lt;/groupId\u0026amp;gt; \u0026amp;lt;artifactId\u0026amp;gt;gatling-charts-highcharts\u0026amp;lt;/artifactId\u0026amp;gt; \u0026amp;lt;version\u0026amp;gt;3.10.0\u0026amp;lt;/version\u0026amp;gt; \u0026amp;lt;/dependency\u0026amp;gt; \u0026amp;lt;/dependencies\u0026amp;gt; \u0026amp;lt;build\u0026amp;gt; \u0026amp;lt;plugins\u0026amp;gt; \u0026amp;lt;plugin\u0026amp;gt; …","date":1551529137,"description":"","fuzzywordcount":1200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"a1202897419574bb7f787140c35d9c28","publishdate":1551529137,"relpermalink":"/posts/test/gatling/gatling5/","section":"posts","summary":"\u003ch3 id=\"gatling-系列专题第五篇cicd-集成与分布式测试\"\u003eGatling 系列专题（第五篇）：CI/CD 集成与分布式测试\u003c/h3\u003e\n\u003ch4 id=\"前言\"\u003e前言\u003c/h4\u003e\n\u003cp\u003e通过前四篇，我们已经掌握了 Gatling 的安装、脚本编写和报告分析。现在，让我们将性能测试提升到新高度：将其融入持续集成与持续部署（CI/CD）流程，并探索分布式测试以应对大规模负载。本篇将帮助你实现自动化性能验证，确保应用在每次迭代中都能保持高效。\u003c/p\u003e","tags":["测试","性能测试","gatling","自动化"],"title":"Gatling 系列专题（第五篇）：CI/CD 集成与分布式测试","url":"https://yinlongfei.com/posts/test/gatling/gatling5/","wordcount":1118},{"categories":"posts","content":"Gatling 系列专题（第四篇）：解读测试报告与分析性能瓶颈 前言 在前三篇中，我们学习了 Gatling 的安装、基础脚本编写以及复杂场景设计。现在，测试已经运行完成，数据摆在面前——如何从 Gatling 生成的报告中提取有价值的信息？本篇将带你深入解读测试报告，分析关键指标，并识别潜在的性能瓶颈。\nGatling 报告在哪里？ 每次运行测试后，Gatling 会在 user-files/results 目录下生成一个以时间戳命名的文件夹（如 simulation-20250323123456）。打开其中的 index.html，即可在浏览器中查看交互式报告。报告分为几个核心部分：\n全局概览（Global Information） 请求统计（Statistics） 响应时间分布（Response Time Distribution） 详细指标（Indicators） 核心指标解读 请求总数与成功率\n总数：测试期间发送的所有请求数。 成功（OK）：状态码为 2xx 的请求。 失败（KO）：状态码为 4xx、5xx 或超时。 分析要点：如果失败率高，可能是服务器过载或 API 配置错误。 响应时间（Response Time）\n平均值：所有请求的平均耗时。 百分位数（Percentiles）：如 95th（95% 请求的响应时间）、99th。 分析要点：关注高百分位数（如 99th），它们反映最差的用户体验。超过 1-2 秒可能需要优化。 吞吐量（Requests per Second）\n表示每秒处理的请求数。 分析要点：吞吐量低可能意味着服务器处理能力不足。 活跃用户（Active Users）\n显示测试期间并发的虚拟用户数。 分析要点：与预期负载模式对比，确保注入逻辑正确。 报告中的可视化图表 响应时间分布图：展示响应时间的范围和频率。如果曲线偏向右侧（长尾），说明存在慢请求。 请求时间线：按时间轴显示成功与失败请求的变化趋势。突发的失败高峰可能与服务器崩溃有关。 吞吐量图：反映系统在不同负载下的稳定性。 示例分析：一个真实的报告 假设我们运行了第三篇中的 UserJourneySimulation，结果如下：\n请求总数：5000，成功率：98% 平均响应时间：300ms，95th：800ms，99th：1500ms 吞吐量：峰值 150 req/s 失败请 …","date":1551442737,"description":"","fuzzywordcount":1400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"54dc6b6be70ed9c0bcd412943986bcc2","publishdate":1551442737,"relpermalink":"/posts/test/gatling/gatling4/","section":"posts","summary":"\u003ch3 id=\"gatling-系列专题第四篇解读测试报告与分析性能瓶颈\"\u003eGatling 系列专题（第四篇）：解读测试报告与分析性能瓶颈\u003c/h3\u003e\n\u003ch4 id=\"前言\"\u003e前言\u003c/h4\u003e\n\u003cp\u003e在前三篇中，我们学习了 Gatling 的安装、基础脚本编写以及复杂场景设计。现在，测试已经运行完成，数据摆在面前——如何从 Gatling 生成的报告中提取有价值的信息？本篇将带你深入解读测试报告，分析关键指标，并识别潜在的性能瓶颈。\u003c/p\u003e","tags":["测试","性能测试","gatling","自动化"],"title":"Gatling 系列专题（第四篇）：解读测试报告与分析性能瓶颈","url":"https://yinlongfei.com/posts/test/gatling/gatling4/","wordcount":1389},{"categories":"posts","content":"Gatling 系列专题（第三篇）：编写复杂脚本与模拟真实用户行为 前言 在前两篇中，我们介绍了 Gatling 的背景并完成了安装与初次测试。现在，是时候深入探索它的核心功能——通过脚本模拟真实用户行为。无论是测试登录流程、搜索功能还是下单场景，Gatling 都能帮助你设计贴近现实的测试。本篇将带你从简单请求升级到复杂场景，掌握脚本编写的关键技巧。\n脚本基础回顾 Gatling 的测试脚本由三个主要部分组成：\nHTTP 协议配置：定义目标地址、请求头等。 场景（Scenario）：描述用户行为，如点击、提交表单。 负载设置（SetUp）：指定用户数量和注入模式。 在第二篇中，我们用一个简单的 GET 请求测试了首页。现在，让我们扩展它，模拟一个完整的用户旅程。\n场景设计：模拟用户登录与浏览 假设我们要测试一个电商网站，用户需要登录、浏览商品并查看详情。以下是一个示例脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 import io.gatling.core.Predef._ import io.gatling.http.Predef._ import scala.concurrent.duration._ class UserJourneySimulation extends Simulation { // HTTP 协议配置 val httpProtocol = http .baseUrl(\u0026amp;#34;https://example-ecommerce.com\u0026amp;#34;) .acceptHeader(\u0026amp;#34;application/json, text/html\u0026amp;#34;) .userAgentHeader(\u0026amp;#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64)\u0026amp;#34;) // 用户行为场景 val scn = scenario(\u0026amp;#34;UserJourney\u0026amp;#34;) .exec(http(\u0026amp;#34;Visit Home Page\u0026amp;#34;) .get(\u0026amp;#34;/\u0026amp;#34;)) .pause(2) // 模拟用户停留 2 …","date":1551356337,"description":"","fuzzywordcount":1200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c86bb35b5b245ffe39e17f08fdb6b530","publishdate":1551356337,"relpermalink":"/posts/test/gatling/gatling3/","section":"posts","summary":"\u003ch3 id=\"gatling-系列专题第三篇编写复杂脚本与模拟真实用户行为\"\u003eGatling 系列专题（第三篇）：编写复杂脚本与模拟真实用户行为\u003c/h3\u003e\n\u003ch4 id=\"前言\"\u003e前言\u003c/h4\u003e\n\u003cp\u003e在前两篇中，我们介绍了 Gatling 的背景并完成了安装与初次测试。现在，是时候深入探索它的核心功能——通过脚本模拟真实用户行为。无论是测试登录流程、搜索功能还是下单场景，Gatling 都能帮助你设计贴近现实的测试。本篇将带你从简单请求升级到复杂场景，掌握脚本编写的关键技巧。\u003c/p\u003e","tags":["测试","性能测试","gatling","自动化"],"title":"Gatling 系列专题（第三篇）：编写复杂脚本与模拟真实用户行为","url":"https://yinlongfei.com/posts/test/gatling/gatling3/","wordcount":1132},{"categories":"posts","content":"Gatling 系列专题（第二篇）：安装与初次体验 Gatling 前言 在第一篇中，我们了解了 Gatling 的背景、核心特点以及它在性能测试中的价值。现在，让我们迈出第一步：安装 Gatling 并运行一个简单的测试。通过本篇，你将学会如何准备环境、启动 Gatling，以及体验它的基本功能。\n安装 Gatling 的准备 Gatling 是一个跨平台的工具，支持 Windows、macOS 和 Linux。安装它并不复杂，但需要满足以下基本条件：\nJava 环境：Gatling 依赖 Java 运行时环境（JRE），推荐使用 Java 11 或更高版本。 检查 Java 是否安装：打开终端，输入 java -version，若未安装，可从 Oracle 官网 或 OpenJDK 下载。 硬件要求：至少 2GB 可用内存和 500MB 磁盘空间，具体需求视测试规模而定。 步骤 1：下载 Gatling 访问 Gatling 官方网站：gatling.io。 点击“Download”或直接前往开源版本的下载页面。 选择最新版本（截至 2025 年 3 月 23 日，推荐使用 3.x 系列，如 3.10.x），下载 ZIP 文件（例如 gatling-charts-highcharts-bundle-3.10.0.zip）。 解压文件到你喜欢的位置，例如 C:\\Gatling（Windows）或 /opt/gatling（Linux/macOS）。 解压后，目录结构如下：\nbin/：包含启动脚本（gatling.sh 或 gatling.bat）。 lib/：核心库文件。 conf/：配置文件。 user-files/：存放测试脚本和数据。 步骤 2：验证安装 打开终端（Windows 用户可使用 CMD 或 PowerShell）。 导航到 Gatling 的 bin 目录，例如： 1 cd /opt/gatling/gatling-charts-highcharts-bundle-3.10.0/bin 运行启动脚本： Linux/macOS：./gatling.sh Windows：gatling.bat 如果看到 Gatling 的欢迎界面和示例测试列表，说明安装成功。 步骤 3：运行第一个测试 Gatling 自带了一些示例脚本，我们可以用它们来体验功能。 …","date":1551269937,"description":"","fuzzywordcount":1300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"e6b191e0279457962efd7bf63bcdbcc9","publishdate":1551269937,"relpermalink":"/posts/test/gatling/gatling2/","section":"posts","summary":"\u003ch3 id=\"gatling-系列专题第二篇安装与初次体验-gatling\"\u003eGatling 系列专题（第二篇）：安装与初次体验 Gatling\u003c/h3\u003e\n\u003ch4 id=\"前言\"\u003e前言\u003c/h4\u003e\n\u003cp\u003e在第一篇中，我们了解了 Gatling 的背景、核心特点以及它在性能测试中的价值。现在，让我们迈出第一步：安装 Gatling 并运行一个简单的测试。通过本篇，你将学会如何准备环境、启动 Gatling，以及体验它的基本功能。\u003c/p\u003e","tags":["测试","性能测试","gatling","自动化"],"title":"Gatling 系列专题（第二篇）：安装与初次体验 Gatling","url":"https://yinlongfei.com/posts/test/gatling/gatling2/","wordcount":1279},{"categories":"posts","content":"Gatling 系列专题（第一篇）：走进性能测试利器 Gatling 什么是 Gatling？ 在现代软件开发中，性能测试是确保应用能够应对高并发、提供稳定服务的关键环节。而 Gatling，正是一款为此而生的开源负载测试工具。它最初由法国开发者 Stéphane Landelle 于 2011 年创建，旨在提供一款高效、直观且强大的工具，帮助团队验证 Web 应用的性能表现。\nGatling 基于 Scala 语言开发，利用 Akka 和 Netty 等高性能框架，采用异步非阻塞的架构设计。这使得它在模拟大量虚拟用户时，能够比许多传统工具更高效地利用系统资源。无论是测试简单的 API 接口，还是复杂的用户交互流程，Gatling 都能胜任。\nGatling 的起源与目标 Gatling 的诞生源于对现有工具（如 JMeter）局限性的反思。传统工具在高并发场景下往往会因线程阻塞而消耗大量资源，导致测试结果失真或硬件需求过高。Gatling 的设计目标是：\n高性能：通过异步机制减少资源占用。 开发者友好：提供代码化的测试脚本，便于版本管理和复用。 直观结果：生成易读的测试报告，帮助快速定位问题。 从最初的开源项目到如今被广泛应用于企业级性能测试，Gatling 已经成为 DevOps 和质量保证领域的重要工具。\n核心特点一览 脚本化测试：使用 Scala 语言的 DSL（领域特定语言），测试场景编写既灵活又可读。 协议支持：默认支持 HTTP/HTTPS，扩展支持 WebSocket、JMS 等。 负载模拟：轻松定义用户注入模式，如突发流量或逐步增长。 报告生成：内置 HTML 报告，展示响应时间、吞吐量、错误率等关键指标。 开源免费：社区驱动，免费使用，同时提供付费的企业版（Gatling Enterprise）以满足更高需求。 适合谁使用？ 开发人员：希望通过代码管理测试逻辑并集成到 CI/CD 流程。 测试工程师：需要模拟真实用户行为并分析性能瓶颈。 企业团队：对大规模分布式测试或复杂场景有需求。 一个简单的开始 假设我们要测试一个网站的首页性能，可以用 Gatling 编写如下脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import io.gatling.core.Predef._ import …","date":1551183537,"description":"","fuzzywordcount":1100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"7fc83512e0cf317db0d2574eca0f7720","publishdate":1551183537,"relpermalink":"/posts/test/gatling/gatling1/","section":"posts","summary":"\u003ch3 id=\"gatling-系列专题第一篇走进性能测试利器-gatling\"\u003eGatling 系列专题（第一篇）：走进性能测试利器 Gatling\u003c/h3\u003e\n\u003ch4 id=\"什么是-gatling\"\u003e什么是 Gatling？\u003c/h4\u003e\n\u003cp\u003e在现代软件开发中，性能测试是确保应用能够应对高并发、提供稳定服务的关键环节。而 Gatling，正是一款为此而生的开源负载测试工具。它最初由法国开发者 Stéphane Landelle 于 2011 年创建，旨在提供一款高效、直观且强大的工具，帮助团队验证 Web 应用的性能表现。\u003c/p\u003e","tags":["测试","性能测试","gatling","自动化"],"title":"Gatling 系列专题（第一篇）：走进性能测试利器 Gatling","url":"https://yinlongfei.com/posts/test/gatling/gatling1/","wordcount":1044},{"categories":"posts","content":"Gatling 系列专题：性能测试的利器 1. Gatling 简介 Gatling 是一款强大的开源负载测试工具，专为开发者和测试人员设计，用于评估 Web 应用程序在高并发场景下的性能。它由 Scala 语言编写，基于 Akka 和 Netty 等高性能框架，支持脚本化测试场景，能够模拟数千甚至数万用户同时访问系统。Gatling 的核心优势在于其高性能、可扩展性以及直观的测试报告。\n2. 为什么选择 Gatling？ 易于上手：Gatling 使用 DSL（领域特定语言），开发者可以通过 Scala 编写可读性强的测试脚本。 高效性能：相比传统工具如 JMeter，Gatling 的异步非阻塞架构能更高效地利用资源。 实时报告：测试完成后，Gatling 自动生成详细的 HTML 报告，展示响应时间、吞吐量等关键指标。 CI/CD 集成：它与 Jenkins、GitLab CI 等工具无缝集成，适合现代 DevOps 流程。 3. Gatling 的核心功能 HTTP 协议支持：模拟 GET、POST 等请求，支持 WebSocket 和 SSE。 场景设计：通过链式 API 定义用户行为，如登录、浏览、下单等。 负载模式：支持多种注入模式，例如恒定用户数、突发流量或逐步增加的负载。 断言与检查：验证响应状态码、内容或性能指标是否符合预期。 4. 快速入门示例 以下是一个简单的 Gatling 测试脚本示例，用于模拟 100 个用户在 60 秒内访问某网站：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import io.gatling.core.Predef._ import io.gatling.http.Predef._ import scala.concurrent.duration._ class BasicSimulation extends Simulation { val httpProtocol = http .baseUrl(\u0026amp;#34;https://example.com\u0026amp;#34;) .acceptHeader(\u0026amp;#34;text/html,application/json\u0026amp;#34;) val scn = scenario(\u0026amp;#34;BasicScenario\u0026amp;#34;) …","date":1551097137,"description":"","fuzzywordcount":800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"262a5f7cab417b341b6c8bd86174fb64","publishdate":1551097137,"relpermalink":"/posts/test/gatling/gatlingtoc/","section":"posts","summary":"\u003ch3 id=\"gatling-系列专题性能测试的利器\"\u003eGatling 系列专题：性能测试的利器\u003c/h3\u003e\n\u003ch4 id=\"1-gatling-简介\"\u003e1. Gatling 简介\u003c/h4\u003e\n\u003cp\u003eGatling 是一款强大的开源负载测试工具，专为开发者和测试人员设计，用于评估 Web 应用程序在高并发场景下的性能。它由 Scala 语言编写，基于 Akka 和 Netty 等高性能框架，支持脚本化测试场景，能够模拟数千甚至数万用户同时访问系统。Gatling 的核心优势在于其高性能、可扩展性以及直观的测试报告。\u003c/p\u003e","tags":["测试","性能测试","gatling","自动化"],"title":"Gatling 系列专题：性能测试的利器","url":"https://yinlongfei.com/posts/test/gatling/gatlingtoc/","wordcount":701},{"categories":"posts","content":"由于我选择的项目前端开发框架用的angular，那么jhipster前端angular利用到了官方的angular-cli来解决问题，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 { \u0026amp;#34;$schema\u0026amp;#34;: \u0026amp;#34;./node_modules/@angular/cli/lib/config/schema.json\u0026amp;#34;, \u0026amp;#34;version\u0026amp;#34;: 1, \u0026amp;#34;newProjectRoot\u0026amp;#34;: \u0026amp;#34;projects\u0026amp;#34;, \u0026amp;#34;projects\u0026amp;#34;: { \u0026amp;#34;demo\u0026amp;#34;: { \u0026amp;#34;root\u0026amp;#34;: \u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;sourceRoot\u0026amp;#34;: \u0026amp;#34;src/main/webapp\u0026amp;#34;, \u0026amp;#34;projectType\u0026amp;#34;: \u0026amp;#34;application\u0026amp;#34;, \u0026amp;#34;architect\u0026amp;#34;: {} } }, \u0026amp;#34;defaultProject\u0026amp;#34;: \u0026amp;#34;demo\u0026amp;#34;, \u0026amp;#34;cli\u0026amp;#34;: { \u0026amp;#34;packageManager\u0026amp;#34;: \u0026amp;#34;npm\u0026amp;#34; }, \u0026amp;#34;schematics\u0026amp;#34;: { \u0026amp;#34;@schematics/angular:component\u0026amp;#34;: { \u0026amp;#34;inlineStyle\u0026amp;#34;: true, \u0026amp;#34;inlineTemplate\u0026amp;#34;: false, \u0026amp;#34;spec\u0026amp;#34;: false, \u0026amp;#34;prefix\u0026amp;#34;: \u0026amp;#34;jhi\u0026amp;#34;, \u0026amp;#34;styleExt\u0026amp;#34;: \u0026amp;#34;css\u0026amp;#34; }, \u0026amp;#34;@schematics/angular:directive\u0026amp;#34;: { \u0026amp;#34;spec\u0026amp;#34;: false, \u0026amp;#34;prefix\u0026amp;#34;: \u0026amp;#34;jhi\u0026amp;#34; }, \u0026amp;#34;@schematics/angular:guard\u0026amp;#34;: { \u0026amp;#34;spec\u0026amp;#34;: …","date":1551097137,"description":"","fuzzywordcount":300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"fb39f79ca315f58474bccab49183e18b","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-angular-cli/","section":"posts","summary":"\u003cp\u003e由于我选择的项目前端开发框架用的angular，那么jhipster前端angular利用到了官方的\u003ca href=\"https://github.com/angular/angular-cli\"\u003eangular-cli\u003c/a\u003e来解决问题，\u003c/p\u003e","tags":["jhipster","angular"],"title":"Jhipster 项目之架构分析之angular.json","url":"https://yinlongfei.com/posts/jhipster/jhipster-angular-cli/","wordcount":245},{"categories":"posts","content":"java开发的项目用gradle来管理项目依赖，项目开发，我们这里面还有前端的一些东西，这些东西在不同平台上如何处理，比如window上的空格跟linux上的处理方式就不同该怎么办？jhipster通过他们丰富的经验在这里给出了模板 下面我们会详细的讲解他们这座做的原因\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 …","date":1551097137,"description":"","fuzzywordcount":2700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"511439399807e8c2caa39455441018b5","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-gradle/","section":"posts","summary":"\u003cp\u003ejava开发的项目用gradle来管理项目依赖，项目开发，我们这里面还有前端的一些东西，这些东西在不同平台上如何处理，比如window上的空格跟linux上的处理方式就不同该怎么办？jhipster通过他们丰富的经验在这里给出了模板\n下面我们会详细的讲解他们这座做的原因\u003c/p\u003e","tags":["jhipster","gradle"],"title":"Jhipster 项目之架构分析之build.gradle","url":"https://yinlongfei.com/posts/jhipster/jhipster-gradle/","wordcount":2624},{"categories":"posts","content":"项目开发时，随着人员的增多，需要大家规范开发中的代码格式，虽然各个开发工具都有格式代码的工具，但是人员不同个人喜好的开发工具也不同，为了遵循大家自由的选择开发工具，而又可以满足维护一致的编码样式，该如何处理呢， EditorConfig刚好就是为这种场景而生的工具\n.editorconfig 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # EditorConfig helps developers define and maintain consistent # coding styles between different editors and IDEs # editorconfig.org root = true [*] # Change these settings to your own preference # 缩进格式为4个空格 indent_style = space indent_size = 4 # We recommend you to keep these unchanged # 设置结尾符号为LF，统一结尾符号，避免window上跟linux或mac上结尾不同 end_of_line = lf # 统一字符编码为UTF-8 charset = utf-8 # 删除换行符号前面的所有空白字符 trim_trailing_whitespace = true # Unix-style 风格的换行 insert_final_newline = true [*.md] # 针对markdown文件不去除换行福前面的空白字符 trim_trailing_whitespace = false [package.json] # package.json文件缩进为两个空格 indent_style = space indent_size = 2 这是这个配置文件的简单介绍。本篇先到此为止\n","date":1551097137,"description":"","fuzzywordcount":400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"1bd801feae4aa13a39ef3b06855efefd","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-editorconfig/","section":"posts","summary":"\u003cp\u003e项目开发时，随着人员的增多，需要大家规范开发中的代码格式，虽然各个开发工具都有格式代码的工具，但是人员不同个人喜好的开发工具也不同，为了遵循大家自由的选择开发工具，而又可以满足维护一致的编码样式，该如何处理呢，\n\u003ca href=\"https://github.com/editorconfig/editorconfig\"\u003eEditorConfig\u003c/a\u003e刚好就是为这种场景而生的工具\u003c/p\u003e","tags":["jhipster","editorconfig"],"title":"Jhipster 项目之架构分析之EditorConfig","url":"https://yinlongfei.com/posts/jhipster/jhipster-editorconfig/","wordcount":387},{"categories":"posts","content":"在开发一个web项目时，如果用git管理一个项目，项目中有几十中格式的文件时，git能否正常的处理这些文件呢？比如图片这种二进制，比如window平台下的bat文件在git仓库上是否应该是一样的，比如jar包这种文件，等等，像这种繁多的文件有时候并不是git默认配置情况下可以处理的非常优秀的，那么下面可以用git的属性, 的配置，让git了解这些文件具体该如何处理，并且配置什么类型的文件应该是什么格式，什么结尾，这个文件定义了常见的文件格式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 # This file is inspired by https://github.com/alexkaratarakis/gitattributes # # Auto detect text files and perform LF normalization # http://davidlaing.com/2012/09/19/customise-your-gitattributes-to-become-a-git-ninja/ * text=auto # The above will handle all files NOT found below # These …","date":1551097137,"description":"","fuzzywordcount":1e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"2e42b418ca807e1d5011138c87378d2b","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-gitattribute/","section":"posts","summary":"\u003cp\u003e在开发一个web项目时，如果用git管理一个项目，项目中有几十中格式的文件时，git能否正常的处理这些文件呢？比如图片这种二进制，比如window平台下的bat文件在git仓库上是否应该是一样的，比如jar包这种文件，等等，像这种繁多的文件有时候并不是git默认配置情况下可以处理的非常优秀的，那么下面可以用\u003ca href=\"https://git-scm.com/book/zh/v1/%E8%87%AA%E5%AE%9A%E4%B9%89-Git-Git%E5%B1%9E%E6%80%A7\"\u003egit的属性\u003c/a\u003e,\n的配置，让git了解这些文件具体该如何处理，并且配置什么类型的文件应该是什么格式，什么结尾，这个文件定义了常见的文件格式\u003c/p\u003e","tags":["jhipster","gitattributes"],"title":"Jhipster 项目之架构分析之gitattributes","url":"https://yinlongfei.com/posts/jhipster/jhipster-gitattribute/","wordcount":909},{"categories":"posts","content":"不论是用什么源码控制软件来控制源码，项目中会有可忽略的文件，比如一些需要运行时才生成的文件，这种文件又大，又不属于源码的范围，这种文件不太建议保存到。那么svn中有ignore的配置文件，而我们用git的中也有类似的配置文件 文件名叫.gitignore文件。 格式主要有以下两种，一种就是排除某个格式，另一种就是在排除的目录中再，\n空行不匹配任何文件 #开头表示是注释内容,对于#字符如果想用，可以用转移字符\\ 特殊字符，可以用转移字符来处理\\ !开头表示，非，可以用这个想排除目录中不想排除的文件设置出来 以/结尾表示忽略整个目录 如果格式不包含/就相当于在根目录下匹配 *匹配出/之外的任何内容，？匹配除了/之外的任何一个字符，[]匹配所选字符 /*.c表示匹配c结尾的格式文件 **/foo表示匹配任意目录中, /** 匹配某个目录下的所有内容 a/**/b 匹配a/x/b,a/x/y/b 上面的条目就是git的格式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 ###################### # Project Specific ###################### /build/www/** /src/test/javascript/coverage/ …","date":1551097137,"description":"","fuzzywordcount":800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"16cf8ee2399ae3b815f74cba4cec22d4","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-gitignore/","section":"posts","summary":"\u003cp\u003e不论是用什么源码控制软件来控制源码，项目中会有可忽略的文件，比如一些需要运行时才生成的文件，这种文件又大，又不属于源码的范围，这种文件不太建议保存到。那么svn中有ignore的配置文件，而我们用git的中也有类似的配置文件\n文件名叫.gitignore文件。\n格式主要有以下两种，一种就是排除某个格式，另一种就是在排除的目录中再，\u003c/p\u003e","tags":["jhipster",".gitignore"],"title":"Jhipster 项目之架构分析之gitignore","url":"https://yinlongfei.com/posts/jhipster/jhipster-gitignore/","wordcount":735},{"categories":"posts","content":"gradle 的属性配置文件，可以直接在gradle.build中的代码project.hasProperty判断处理。\nrootProject.name=demo profile=dev # Build properties node_version=10.14.1 npm_version=6.4.1 yarn_version=1.12.3 # Dependency versions jhipster_dependencies_version=2.0.29 # The spring-boot version should match the one managed by # https://mvnrepository.com/artifact/io.github.jhipster/jhipster-dependencies/${jhipster_dependencies_version} spring_boot_version=2.0.7.RELEASE # The hibernate version should match the one managed by # https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-dependencies/${spring-boot.version} --\u0026amp;gt; hibernate_version=5.2.17.Final mapstruct_version=1.2.0.Final liquibase_hibernate5_version=3.6 liquibaseTaskPrefix=liquibase ## below are some of the gradle performance improvement settings that can be used as required, these are not enabled by default ## The Gradle daemon aims to improve the startup and execution time of Gradle. ## The daemon is enabled by default in Gradle 3+ setting this …","date":1551097137,"description":"","fuzzywordcount":400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"04671dfbf131f0a5c5a12f37921df67c","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-gradle-properties/","section":"posts","summary":"\u003cp\u003egradle 的属性配置文件，可以直接在gradle.build中的代码project.hasProperty判断处理。\u003c/p\u003e","tags":["jhipster","gradle"],"title":"Jhipster 项目之架构分析之gradle.properteis","url":"https://yinlongfei.com/posts/jhipster/jhipster-gradle-properties/","wordcount":313},{"categories":"posts","content":"gradle 的gradlew这个工具可以，下载包裹的gradle，下面我们简单来分一下该脚本，我会通过注释来描述问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 #!/usr/bin/env sh # 从环境变量中找sh可执行命令 ############################################################################## ## ## Gradle start up script for UN*X ## ############################################################################## # Attempt …","date":1551097137,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"66abc58669d5afffc0e596773f048fed","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-gradlew-sh/","section":"posts","summary":"\u003cp\u003egradle 的gradlew这个工具可以，下载包裹的gradle，下面我们简单来分一下该脚本，我会通过注释来描述问题。\u003c/p\u003e","tags":["jhipster","gradle"],"title":"Jhipster 项目之架构分析之gradlew","url":"https://yinlongfei.com/posts/jhipster/jhipster-gradlew-sh/","wordcount":1697},{"categories":"posts","content":"上一章讲了gradlew的类unix的脚本，这章主要讲一下window的内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 @if \u0026amp;#34;%DEBUG%\u0026amp;#34; == \u0026amp;#34;\u0026amp;#34; @echo off @rem ########################################################################## @rem @rem Gradle startup script for Windows @rem @rem ########################################################################## @rem Set local scope for the variables with windows NT shell if \u0026amp;#34;%OS%\u0026amp;#34;==\u0026amp;#34;Windows_NT\u0026amp;#34; setlocal set DIRNAME=%~dp0 if \u0026amp;#34;%DIRNAME%\u0026amp;#34; == \u0026amp;#34;\u0026amp;#34; set DIRNAME=. set APP_BASE_NAME=%~n0 set APP_HOME=%DIRNAME% @rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script. set DEFAULT_JVM_OPTS= @rem Find java.exe if defined JAVA_HOME goto findJavaFromJavaHome set JAVA_EXE=java.exe %JAVA_EXE% …","date":1551097137,"description":"","fuzzywordcount":600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c93385ef802e488e4e84630506000e82","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-gradlew.bat/","section":"posts","summary":"\u003cp\u003e上一章讲了gradlew的类unix的脚本，这章主要讲一下window的内容\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e18\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e19\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e20\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e21\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e22\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e23\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e24\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e25\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e26\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e27\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e28\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e29\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e30\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e31\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e32\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e33\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e34\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e35\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e36\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e37\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e38\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e39\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e40\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e41\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e42\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e43\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e44\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e45\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e46\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e47\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e48\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e49\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e50\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e51\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e52\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e53\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e54\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e55\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e56\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e57\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e58\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e59\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e60\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e61\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e62\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e63\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e64\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e65\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e66\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e67\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e68\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e69\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e70\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e71\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e72\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e73\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e74\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e75\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e76\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e77\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e78\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e79\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e80\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e81\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e82\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e83\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e84\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bat\" data-lang=\"bat\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e@\u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"nv\"\u003e%DEBUG%\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u003c/span\u003e \u003cspan class=\"p\"\u003e@\u003c/span\u003e\u003cspan class=\"k\"\u003eecho\u003c/span\u003e off\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e@\u003c/span\u003e\u003cspan class=\"c1\"\u003erem ##########################################################################\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e@\u003c/span\u003e\u003cspan class=\"c1\"\u003erem\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e@\u003c/span\u003e\u003cspan class=\"c1\"\u003erem  Gradle startup script for Windows\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e@\u003c/span\u003e\u003cspan class=\"c1\"\u003erem\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e@\u003c/span\u003e\u003cspan class=\"c1\"\u003erem ##########################################################################\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e@\u003c/span\u003e\u003cspan class=\"c1\"\u003erem Set local scope for the variables with windows NT shell\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"nv\"\u003e%OS%\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Windows_NT\u0026#34;\u003c/span\u003e \u003cspan class=\"k\"\u003esetlocal\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eset\u003c/span\u003e \u003cspan class=\"nv\"\u003eDIRNAME\u003c/span\u003e\u003cspan class=\"p\"\u003e=\u003c/span\u003e\u003cspan class=\"nv\"\u003e%~dp0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"nv\"\u003e%DIRNAME%\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u003c/span\u003e \u003cspan class=\"k\"\u003eset\u003c/span\u003e \u003cspan class=\"nv\"\u003eDIRNAME\u003c/span\u003e\u003cspan class=\"p\"\u003e=\u003c/span\u003e.\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eset\u003c/span\u003e \u003cspan class=\"nv\"\u003eAPP_BASE_NAME\u003c/span\u003e\u003cspan class=\"p\"\u003e=\u003c/span\u003e\u003cspan class=\"nv\"\u003e%~n0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eset\u003c/span\u003e \u003cspan class=\"nv\"\u003eAPP_HOME\u003c/span\u003e\u003cspan class=\"p\"\u003e=\u003c/span\u003e\u003cspan class=\"nv\"\u003e%DIRNAME%\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e@\u003c/span\u003e\u003cspan class=\"c1\"\u003erem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eset\u003c/span\u003e \u003cspan class=\"nv\"\u003eDEFAULT_JVM_OPTS\u003c/span\u003e\u003cspan class=\"p\"\u003e=\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e@\u003c/span\u003e\u003cspan class=\"c1\"\u003erem Find java.exe\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"k\"\u003edefined\u003c/span\u003e \u003cspan class=\"nv\"\u003eJAVA_HOME\u003c/span\u003e \u003cspan class=\"k\"\u003egoto\u003c/span\u003e \u003cspan class=\"nl\"\u003efindJavaFromJavaHome\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eset\u003c/span\u003e \u003cspan class=\"nv\"\u003eJAVA_EXE\u003c/span\u003e\u003cspan class=\"p\"\u003e= …\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003c/div\u003e\u003c/div\u003e","tags":["jhipster","gradle"],"title":"Jhipster 项目之架构分析之gradlew.bat","url":"https://yinlongfei.com/posts/jhipster/jhipster-gradlew.bat/","wordcount":542},{"categories":"posts","content":"jhipster是一个快速生成项目的脚手架，能够快速提高开发效率，本身并不是一个开发技术，但是这个东西本身实际上是一个最佳实践，我们可以看看他的最佳实践做一些学习。\n项目目录结构 项目的目录结构如上图所示，接下来，咱们详细的讲解一下目录结构的作用。 其中.gradle,.idea,node_modules,out，build这几个文件是工具自动生成文件，咱们不需要了解，就不细说这个了，\n.jhipster目录 这个目录中都是定义的实体配置，还有就是jhi提供的钩子，可以在开发插件时利用这些钩子做一些有意思的事情，比如给实体添加实体审核的,这里面的文件大部分情况下我们是不需要动地，因为这些文件是jhipster自动帮忙生成的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 { \u0026amp;#34;name\u0026amp;#34;: \u0026amp;#34;About\u0026amp;#34;, \u0026amp;#34;fields\u0026amp;#34;: [ { \u0026amp;#34;fieldName\u0026amp;#34;: \u0026amp;#34;info\u0026amp;#34;, \u0026amp;#34;fieldType\u0026amp;#34;: \u0026amp;#34;String\u0026amp;#34; }, { \u0026amp;#34;fieldName\u0026amp;#34;: \u0026amp;#34;content\u0026amp;#34;, \u0026amp;#34;fieldType\u0026amp;#34;: \u0026amp;#34;String\u0026amp;#34; }, { \u0026amp;#34;fieldName\u0026amp;#34;: \u0026amp;#34;order\u0026amp;#34;, \u0026amp;#34;fieldType\u0026amp;#34;: \u0026amp;#34;Long\u0026amp;#34; } ], \u0026amp;#34;relationships\u0026amp;#34;: [], \u0026amp;#34;changelogDate\u0026amp;#34;: \u0026amp;#34;20190105111036\u0026amp;#34;, \u0026amp;#34;entityTableName\u0026amp;#34;: \u0026amp;#34;about\u0026amp;#34;, \u0026amp;#34;dto\u0026amp;#34;: \u0026amp;#34;no\u0026amp;#34;, \u0026amp;#34;pagination\u0026amp;#34;: \u0026amp;#34;no\u0026amp;#34;, \u0026amp;#34;service\u0026amp;#34;: \u0026amp;#34;no\u0026amp;#34;, \u0026amp;#34;jpaMetamodelFiltering\u0026amp;#34;: false, \u0026amp;#34;fluentMethods\u0026amp;#34;: true, …","date":1551097137,"description":"","fuzzywordcount":3e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"125a777c978c416c72beaebf760b1713","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-architecture/","section":"posts","summary":"\u003cp\u003ejhipster是一个快速生成项目的脚手架，能够快速提高开发效率，本身并不是一个开发技术，但是这个东西本身实际上是一个最佳实践，我们可以看看他的最佳实践做一些学习。\u003c/p\u003e","tags":["jhipster","gradle"],"title":"Jhipster 项目之架构分析之gradle目录结构","url":"https://yinlongfei.com/posts/jhipster/jhipster-architecture/","wordcount":2976},{"categories":"posts","content":"在开发的时候，我们有的时候需要在提交的时候做一些校验，比如控制一些不规范的提交，不规范的推送，这里刚好又这么个校验工具huskrc 这个工具现在也是有很多有名的开源软件在使用，比如\njQuery babel create-react-app Next.js Hyper Kibana JSON Server Hotel Jhipster同样采用了，这个工具来做前端的一些lint校验，具体配置如下所示\n1 2 3 4 5 { \u0026amp;#34;hooks\u0026amp;#34;: { \u0026amp;#34;pre-commit\u0026amp;#34;: \u0026amp;#34;lint-staged\u0026amp;#34; } } 钩子的内容，在提交前执行lint-staged，好的本篇文章就降到这里，具体的huskrc可以看我的关于huskrc详细介绍的博文\n","date":1551097137,"description":"","fuzzywordcount":300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"d5baa9ffd117a80f39fa90857386bb86","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-huskrc/","section":"posts","summary":"\u003cp\u003e在开发的时候，我们有的时候需要在提交的时候做一些校验，比如控制一些不规范的提交，不规范的推送，这里刚好又这么个校验工具\u003ca href=\"https://github.com/typicode/husky\"\u003ehuskrc\u003c/a\u003e\n这个工具现在也是有很多有名的开源软件在使用，比如\u003c/p\u003e","tags":["jhipster","huskrc"],"title":"Jhipster 项目之架构分析之huskrc","url":"https://yinlongfei.com/posts/jhipster/jhipster-huskrc/","wordcount":215},{"categories":"posts","content":"由于前端的项目现在发展的日新月异，同样有类似后台的依赖管理工具，前端的依赖管理工具就是NPM（Node Package Manager），\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 { \u0026amp;#34;name\u0026amp;#34;: \u0026amp;#34;demo\u0026amp;#34;, \u0026amp;#34;version\u0026amp;#34;: \u0026amp;#34;0.0.0\u0026amp;#34;, \u0026amp;#34;description\u0026amp;#34;: \u0026amp;#34;Description for demo\u0026amp;#34;, \u0026amp;#34;private\u0026amp;#34;: true, \u0026amp;#34;license\u0026amp;#34;: \u0026amp;#34;UNLICENSED\u0026amp;#34;, \u0026amp;#34;cacheDirectories\u0026amp;#34;: [ \u0026amp;#34;node_modules\u0026amp;#34; ], \u0026amp;#34;dependencies\u0026amp;#34;: { \u0026amp;#34;@angular/common\u0026amp;#34;: \u0026amp;#34;7.1.0\u0026amp;#34;, \u0026amp;#34;@angular/compiler\u0026amp;#34;: \u0026amp;#34;7.1.0\u0026amp;#34;, \u0026amp;#34;@angular/core\u0026amp;#34;: \u0026amp;#34;7.1.0\u0026amp;#34;, \u0026amp;#34;@angular/forms\u0026amp;#34;: \u0026amp;#34;7.1.0\u0026amp;#34;, \u0026amp;#34;@angular/platform-browser\u0026amp;#34;: …","date":1551097137,"description":"","fuzzywordcount":1700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"de7c9ef5beef2a1813acdec4cde11809","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-packge.json/","section":"posts","summary":"\u003cp\u003e由于前端的项目现在发展的日新月异，同样有类似后台的依赖管理工具，前端的依赖管理工具就是NPM（Node Package Manager），\u003c/p\u003e","tags":["jhipster","package"],"title":"Jhipster 项目之架构分析之package.json","url":"https://yinlongfei.com/posts/jhipster/jhipster-packge.json/","wordcount":1668},{"categories":"posts","content":"在开发代码时候，前端项目如何让代码格式固定，有很多办法，批量格式化代码的神器，虽然咱们前面已经有editorconfig来保证跨开发工具的缩进啊，之类的包支持一直，但是如果需要批量格式化代码，该如何处理呢，刚好 perttier就是这个神器,可以陪和前面的huskrc在提交前，批量把之前的代码统一按配置的格式化处理\n.prettierrc 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Prettier configuration # 每行行宽 printWidth: 140 # 单引号 singleQuote: true # tab是4个空格代替 tabWidth: 4 # 不用tab字符 useTabs: false # js and ts rules: arrowParens: avoid # jsx and tsx rules: jsxBracketSameLine: false 通过上面的配置，就可以在前端代码中作出如下的格式化。\n.prettierignore 针对这种批量格式化任务呢，我们针对一些不必要的文件不用格式化，比如node_modules，这个是别人开发好的库文件，格式化了，没什么用，还有编译后的文件，这个不是我们源码需要处理的内容，再有就是锁定版本的文件，更是不需要更新了\nnode_modules target package-lock.json 那么通过上面两个文件，我们就可以处理批量格式化了，本篇文章到此结束\n","date":1551097137,"description":"","fuzzywordcount":500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"3e0c07465c12b58e4a49f8146193810b","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-prettier/","section":"posts","summary":"\u003cp\u003e在开发代码时候，前端项目如何让代码格式固定，有很多办法，批量格式化代码的神器，虽然咱们前面已经有editorconfig来保证跨开发工具的缩进啊，之类的包支持一直，但是如果需要批量格式化代码，该如何处理呢，刚好\n\u003ca href=\"https://github.com/prettier/prettier\"\u003eperttier\u003c/a\u003e就是这个神器,可以陪和前面的huskrc在提交前，批量把之前的代码统一按配置的格式化处理\u003c/p\u003e","tags":["jhipster","perttier"],"title":"Jhipster 项目之架构分析之perttier","url":"https://yinlongfei.com/posts/jhipster/jhipster-prettier/","wordcount":404},{"categories":"posts","content":"jhipster generator这个工具本身使用yeoman开发的，那么yo他的开发工具生成代码，jhipster利用这个配置文件来保存生成项目时的一些配置，比如项目名称，用的什么组件之类的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 { \u0026amp;#34;generator-jhipster\u0026amp;#34;: { \u0026amp;#34;applicationType\u0026amp;#34;: \u0026amp;#34;monolith\u0026amp;#34;, \u0026amp;#34;gitCompany\u0026amp;#34;: \u0026amp;#34;\u0026amp;#34;, \u0026amp;#34;baseName\u0026amp;#34;: \u0026amp;#34;demo\u0026amp;#34;, \u0026amp;#34;packageName\u0026amp;#34;: \u0026amp;#34;org.ylf.demo\u0026amp;#34;, \u0026amp;#34;packageFolder\u0026amp;#34;: \u0026amp;#34;org/ylf/demo\u0026amp;#34;, \u0026amp;#34;serverPort\u0026amp;#34;: 8080, \u0026amp;#34;serviceDiscoveryType\u0026amp;#34;: false, \u0026amp;#34;authenticationType\u0026amp;#34;: \u0026amp;#34;jwt\u0026amp;#34;, \u0026amp;#34;uaaBaseName\u0026amp;#34;: \u0026amp;#34;../uaa\u0026amp;#34;, \u0026amp;#34;cacheProvider\u0026amp;#34;: \u0026amp;#34;ehcache\u0026amp;#34;, \u0026amp;#34;enableHibernateCache\u0026amp;#34;: true, \u0026amp;#34;websocket\u0026amp;#34;: false, \u0026amp;#34;databaseType\u0026amp;#34;: \u0026amp;#34;sql\u0026amp;#34;, \u0026amp;#34;devDatabaseType\u0026amp;#34;: \u0026amp;#34;h2Disk\u0026amp;#34;, \u0026amp;#34;prodDatabaseType\u0026amp;#34;: \u0026amp;#34;mysql\u0026amp;#34;, \u0026amp;#34;searchEngine\u0026amp;#34;: false, \u0026amp;#34;enableSwaggerCodegen\u0026amp;#34;: false, \u0026amp;#34;messageBroker\u0026amp;#34;: false, \u0026amp;#34;buildTool\u0026amp;#34;: \u0026amp;#34;gradle\u0026amp;#34;, …","date":1551097137,"description":"","fuzzywordcount":300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"10ae929aba1b36672e012de2e40ee19e","publishdate":1551097137,"relpermalink":"/posts/jhipster/jhipster-yo-rc/","section":"posts","summary":"\u003cp\u003ejhipster generator这个工具本身使用\u003ca href=\"https://github.com/yeoman/yo\"\u003eyeoman\u003c/a\u003e开发的，那么yo他的开发工具生成代码，jhipster利用这个配置文件来保存生成项目时的一些配置，比如项目名称，用的什么组件之类的\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e18\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e19\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e20\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e21\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e22\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e23\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e24\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e25\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e26\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e27\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e28\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e29\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e30\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e31\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e32\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e33\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e34\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e35\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e36\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e37\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e38\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e39\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e40\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nt\"\u003e\u0026#34;generator-jhipster\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;applicationType\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;monolith\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;gitCompany\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;baseName\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;demo\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;packageName\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;org.ylf.demo\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;packageFolder\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;org/ylf/demo\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;serverPort\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e8080\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;serviceDiscoveryType\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kc\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;authenticationType\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;jwt\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;uaaBaseName\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;../uaa\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;cacheProvider\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;ehcache\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;enableHibernateCache\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;websocket\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"kc\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;databaseType\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;sql\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;devDatabaseType\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;h2Disk\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nt\"\u003e\u0026#34;prodDatabaseType\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;mysql\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e, …\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003c/div\u003e\u003c/div\u003e","tags":["jhipster","yo-rc"],"title":"Jhipster 项目之架构分析之yo-rc.json","url":"https://yinlongfei.com/posts/jhipster/jhipster-yo-rc/","wordcount":251},{"categories":"posts","content":"Cilium 1.4：多集群服务路由，DNS授权，IPVLAN支持，透明加密，Flannel集成，与其他CNI的基准测试，...... 通告\n我们很高兴地宣布Cilium 1.4版本。 该版本引入了几项新功能以及优化和可扩展性工作。 重点包括增加全局服务，提供跨多个集群的Kubernetes服务路由、DNS请求/响应感知授权和可见性、透明加密（beta）、IPVLAN支持以获得更好的性能和延迟（beta）、与Flannel集成、GKE在COS上支持、基于AWS元数据的策略实施（alpha）以及优化内存和CPU使用的重要工作。\n像往常一样，感谢过去4个月中在版本1.3和1.4之间贡献了1048次提交的Cilium开发人员及整个社区。\nCilium是什么？ Cilium是一个开源软件，用于透明地提供和保护使用Kubernetes、Docker和Mesos等Linux容器管理平台部署的应用程序服务之间的网络和API连接。\nCilium的基础是一种名为BPF的新Linux内核技术，它可以在Linux本身内动态插入强大的安全性、可见性和网络控制逻辑。BPF用于提供诸如多集群路由，负载均衡以取代kube-proxy，使用X.509证书的透明加密以及网络和服务安全性等功能。除了提供传统的网络级安全性之外，BPF的灵活性还可以通过应用程序协议和DNS请求/响应的上下文实现安全性。Cilium与Envoy紧密集成，并提供基于Go的扩展框架。由于BPF在Linux内核中运行，因此可以应用所有Cilium功能，而无需对应用程序代码或容器配置进行任何更改。\n有关 Cilium 的更详细的介绍， 请参阅**Cilium简介** 一节。\n多集群服务路由 Cilium 1.3在多个集群之间引入了基本的pod IP路由功能。Cilium 1.4引入了基于标准Kubernetes服务的全局服务概念。全局服务允许用户指定Kubernetes服务在多个集群中可用。然后，该服务可以在多个集群中具有后端pod。\n用户体验就像在每个集群中定义具有相同名称和命名空间的Kubernetes服务并添加注释以将其标记为全局一样简单。 当pod向上或向下扩展或变得不健康时，Kubernetes运行状态检查信息可用于自动添加和删除后端服务。\n控制平面建立在etcd之上，类似于Kubernetes原生的操作方式，具有弹性和 …","date":1549929600,"description":"“Cilium 1.4：多集群服务路由，DNS授权，IPVLAN支持，透明加密，Flannel集成，与其他CNI的基准测试。\"","fuzzywordcount":6600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"f707a006b50b28686e416b99089b0af5","publishdate":1549929600,"relpermalink":"/posts/translations/cilium-14/","section":"posts","summary":"\u003ch1 id=\"cilium-14多集群服务路由dns授权ipvlan支持透明加密flannel集成与其他cni的基准测试\"\u003eCilium 1.4：多集群服务路由，DNS授权，IPVLAN支持，透明加密，Flannel集成，与其他CNI的基准测试，......\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://cilium.io/blog/categories/Announcements\"\u003e通告\u003c/a\u003e\u003c/p\u003e","tags":["cilium","encryption","multi-cluster","multi-mesh","dns","kubernetes"],"title":"Cilium 1.4发布了","url":"https://yinlongfei.com/posts/translations/cilium-14/","wordcount":6565},{"categories":"posts","content":"Istio 是一个由Google，IBM和Lyft团队合作开发的开源项目，它提供了基于微服务的应用程序复杂性的解决方案，仅举几例：\n流量管理 ：超时，重试，负载均衡， 安全性： 最终用户身份验证和授权， 可观察性： 跟踪，监控和记录。 所有这些都可以在应用程序层中解决，但是您的服务不再是“微型”，相对于提供业务价值的资源，实现这些的所有额外工作都是公司资源的压力。我们来举个例子：\nPM：添加反馈功能需要多长时间？\n开发：两个冲刺（敏捷开发中的术语，一般一个冲刺周期30天）。\nPM：什么......？ 那只是一个CRUD！\n\\[... \\] PM：那么我们就把它放在产品服务中吧。哎呀！\n你明白了，必须满足所有形式才可以为我们添加一项巨大的服务（有很多不是业务功能的代码）。在本文中，我们将展示Istio如何从我们的服务中删除所有上述交叉问题。\n注意： 本文假设您具有Kubernetes的知识。如果不是这种情况，我建议您阅读 我对Kubernetes的介绍，然后继续阅读本文。\n关于Istio 在没有Istio的世界中，一个服务向另一个服务直接发出请求，并且在发生故障的情况下，服务需要通过重试，超时，打开熔断器等来处理它。\n为了解决这个问题，Istio通过与服务完全分离，并通过拦截所有网络通信来提供一种巧妙的解决方案。这样做可以实现：\nFault Tolerance - 使用响应状态代码，它可以在请求失败并重试时理解。 Canary Rollouts - 仅将指定百分比的请求转发到新版本的服务。 监控和指标 - 服务响应所花费的时间。 跟踪和可观察性 - 它在每个请求中添加特殊header，并在集群中跟踪它们。 安全性 - 提取JWT令牌并对用户进行身份验证和授权。 仅举几例（仅举几例），让您感兴趣！ 我们来看一些技术细节吧！\nIstio的架构 Istio拦截所有网络流量，并通过在每个pod中注入智能代理作为sidecar来应用一组规则。启用所有功能的代理包括 数据平面， 并且这些代理可由控制平面 动态配置。\n数据平面 注入的代理使Istio能够轻松满足我们的要求。举个例子，我们来看看重试和熔断器功能。\n总结一下：\nEnvoy将请求发送到服务B的第一个实例，但它失败了。 Envoy sidecar重试。（1） 返回对调用代理的失败请求。 这将打开熔断器并在后续请求中调用下一 …","date":1549929600,"description":"使用Istio打造微服务（第1部分）","fuzzywordcount":9800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"12e804d2e63199a03dded851be5c73d9","publishdate":1549929600,"relpermalink":"/posts/translations/service-mesh/istio/back-to-microservices-with-istio-p1/","section":"posts","summary":"\u003cp\u003e\u003cstrong\u003eIstio\u003c/strong\u003e 是一个由Google，IBM和Lyft团队合作开发的开源项目，它提供了基于微服务的应用程序复杂性的解决方案，仅举几例：\u003c/p\u003e","tags":["istio","microservices","kubernetes","vs","tracing","monitor"],"title":"使用Istio打造微服务（第1部分）","url":"https://yinlongfei.com/posts/translations/service-mesh/istio/back-to-microservices-with-istio-p1/","wordcount":9726},{"categories":"posts","content":"无服务器与容器 原文链接：https://dzone.com/articles/serverless-vs-containers\n作者：Yan Cui\n译者：殷龙飞\n让我们来看看采用率，工具支持以及围绕无服务器和容器化争论的其他因素。 在无服务器和容器中，我们有两种令人惊叹的技术，可以为工程师提供高效的，与机器无关的抽象。然而，两个阵营之间似乎存在着不可逾越的鸿沟。\n如果你读过我在过去两年写的任何内容，你就会知道我坚定地站在无服务器阵营。但我也是容器的早期采用者。在Docker达到1.0里程碑后不久，2015年初我的第一个容器化项目问世。\n这篇文章不是企图另一次引发阵营战争或宣布某个阵营的胜利。相反，我将尝试客观地看待无服务器和容器的状态，根据它们提供的利弊权衡，并对未来的情况给出诚实的看法。\n鉴于无服务器和FaaS函数即服务（FAAS）通常已经可以互换使用，为了本文的目的，我将限制无服务器的定义为FAAS产品，例如AWS Lambda。\n容器状态 自从Docker早期可用以来，事情已经走过了漫长的道路。随着我们在容器上运行的系统越来越复杂，我们的需求已经催生了丰富的工具生态系统。\nAWS还拥有自己的托管容器服务ECS。这提供了与AWS生态系统其他部分更紧密的集成。\n如服务网格也正在获得可见性和被采用。它们将常见的交叉问题（例如跟踪和断路器）移出应用层。通过解决基础架构层中的这些问题，它们为这些挑战提供了语言和运行时无关的解决方案。这使它们非常适合现代IT组织，即使用各种不同语言的构建微服务。\n无服务器状态 虽然围绕无服务器的炒作并没有和容器一样长。值得记住的是，在Lamber达到1.0之后仅一个月，AWS Lambda就在 2014年发布了。它随附了CloudWatch的基本日志记录和监视支持，即使我们现在依赖的许多事件源（例如API Gateway）都是在之后引入的。\n除了这些托管服务之外，还有一些解决方案可以让您在自己的Kubernetes集群上运行无服务器。这些包括谷歌和合作公司最近宣布的。虽然这些解决方案试图满足许多开发人员的需求，但我感到他们放弃了无服务器的最佳功能 - 不必担心服务器！\n采用趋势 根据一些调查和研究，无服务器和容器的采用正在快速增长。以下是我认为的一些亮点。\nA Cloudability发现，2017年第四季度AWS用户的容器采用量增长 …","date":1537013937,"description":"","fuzzywordcount":3500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"82ff8187fad6fce69408a214460c3f6a","publishdate":1537013937,"relpermalink":"/posts/translations/serveless/serverless-vs-containers/","section":"posts","summary":"\u003ch1 id=\"无服务器与容器\"\u003e无服务器与容器\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e原文链接：https://dzone.com/articles/serverless-vs-containers\u003c/p\u003e","tags":["serverless"],"title":"无服务器与容器","url":"https://yinlongfei.com/posts/translations/serveless/serverless-vs-containers/","wordcount":3403},{"categories":"posts","content":" 原文链接：https://www.infoq.com/articles/microservices-post-kubernetes\n作者：Bilgin Ibryam 英文审校：Daniel Bryant\n译者：殷龙飞\n关键要点 微服务架构仍然是分布式系统最流行的架构风格。 但 Kubernetes 和云原生运动已经大规模重新定义了应用程序设计和开发。 在云原生平台上，服务的可观察性是不够的。 更基本的先决条件是通过实施健康检查，对信号做出反应，声明资源消耗等，使微服务自动化。 在后 Kubernetes 时代，服务网格技术将完全取代使用库来实现操作网络问题（例如 Hystrix 断路器）。 微服务现在必须通过从多个维度实现幂等性来设计用于“恢复”。 现代开发人员必须精通编程语言以实现业务功能，并且同样精通云原生技术以满足非功能性基础架构级别要求。 微服务炒作开始于一堆关于组织结构，团队规模，服务规模，重写和抛出服务而不是修复，避免单元测试等的极端想法。根据我的经验，大多数这些想法被证明是错误的，而不是实用的，或者至少一般不适用。 如今，大多数剩余的原则和实践都是如此通用和松散地定义，以至于它们在未来许多年都会成立，而在实践中却没有多大意义。\n在 Kubernetes 诞生之前几年被采用，微服务仍然是分布式系统最流行的架构风格。 但 Kubernetes 和云原生运动已经大规模重新定义了应用程序设计和开发的某些方面。 在本文中，我想质疑一些原始的微服务理念，并承认它们在后 Kubernetes 时代并不像以前那样强大。\n不仅可观察，而且还有自动化服务 可观察性从一开始就是微服务的基本原则。 虽然对于一般的分布式系统来说它是正确的，但今天（特别是在 Kubernetes 上），它的很大一部分是平台级别的开箱即用（例如进程运行状况检查，CPU 和内存消耗）。 最低要求是应用程序以 JSON 格式登录控制台。 从那时起，平台可以跟踪资源消耗，请求跟踪，收集所有类型的指标，错误率等，而无需太多的服务级别开发工作。\n在云原生平台上，可观察性是不够的。 更基本的先决条件是通过实施健康检查，对信号做出反应，声明资源消耗等使微服务自动化 。可以将几乎任何应用程序放入容器中并运行它。 但是要创建一个容器化的应用程序，可以通过云原生平台自动化和协调编排，需要遵循一定的规则。 遵循这些  …","date":1536063537,"description":"","fuzzywordcount":3400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"317ddc9d5b3778f026bbd19e4b5bac24","publishdate":1536063537,"relpermalink":"/posts/translations/microservices-post-kubernetes/","section":"posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e原文链接：https://www.infoq.com/articles/microservices-post-kubernetes\u003c/p\u003e","tags":["Kubernetes"],"title":"后 Kubernetes 时代的微服务","url":"https://yinlongfei.com/posts/translations/microservices-post-kubernetes/","wordcount":3322},{"categories":"posts","content":" 原文链接：https://www.infoq.com/articles/envoy-service-mesh-cascading-failure\n作者：Jose Nino 作者：Daniel Hochman\n译者：殷龙飞\n关键要点 在过去的四年中，Lyft 已从单体架构转变为数百个微服务。随着微服务数量的增加，由于级联故障或意外内部拒绝服务导致的中断次数也在增加。 今天，这些故障情况在 Lyft 基础设施中基本上是一个已解决的问题。Lyft 部署的每项服务都通过使用 Envoy 代理自动获得吞吐量和并发保护。 Envoy 可以作为中间件部署或仅在请求入口时部署，但最大的好处来自于在应用程序本地的入口和出口部署它。在请求的两端部署 Envoy 允许它充当服务器的智能客户端和反向代理。 在接下来的几个月里，Lyft 将与 Netflix 的并发限制库背后的团队合作，将基于其库的系统带入 Envoy L7 过滤器。 级联故障是高吞吐量分布式系统中不可用的主要原因之一。在过去的四年中，Lyft 已从单体架构转变为数百种微服务。随着微服务数量的增加， 由于级联故障或意外内部拒绝服务导致的中断次数也在增加。今天，这些故障情况在 Lyft 基础设施中基本上是一个已解决的问题。 Lyft 部署的每项服务都会自动获得吞吐量和并发保护。通过对我们最关键的服务进行一些有针对性的配置更改，基于负载的事件减少了 95％，从而影响了用户体验。\n在我们检查特定的故障情况和相应的保护机制之前，让我们首先了解如何在 Lyft 部署网络防御。Envoy 是一个 源自 Lyft 的代理， 后来开源并捐赠给 Cloud Native Computing Foundation 。Envoy 与许多其他负载均衡解决方案的区别在于它被设计为以“网格”配置部署。 Envoy 可以作为中间件部署或仅在请求入口时部署，但最大的好处来自于在应用程序本地的入口和出口部署它。在请求的两端部署 Envoy 允许它充当服务器的智能客户端和反向代理。 在双方，我们可以选择采用速率限制和断路来保护服务器免受各种情况下的过载。\n核心概念 并发和速率限制 并发和速率限制是相关的，但不同的概念; 同一枚硬币的两面。在考虑限制系统负载时，运营商传统上会考虑每秒的请求数。 限制发送到系统的请求的速率的行为是速率限制的。通常进行压力测试以确 …","date":1535631537,"description":"","fuzzywordcount":5700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"ae3c8a4b82e4cd66e52fa6defff73dad","publishdate":1535631537,"relpermalink":"/posts/translations/service-mesh/istio/envoy-service-mesh-cascading-failure/","section":"posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e原文链接：https://www.infoq.com/articles/envoy-service-mesh-cascading-failure\u003c/p\u003e","tags":["Lyft","Envoy","Burstiness"],"title":"使用 Kubernetes 和 Istio 进行基于容器的全面服务监控","url":"https://yinlongfei.com/posts/translations/service-mesh/istio/envoy-service-mesh-cascading-failure/","wordcount":5655},{"categories":"posts","content":"云平台系统设计系列深度硬核解析 第三章：存储系统设计 存储系统是云平台的基础支柱，直接影响数据的持久性、性能和成本。在云计算中，存储需求多样化，从高性能的块存储到海量数据的对象存储，再到共享访问的文件存储，每种类型都有其独特的设计考量。本章将深入探讨云存储的分类与选型，剖析分布式存储的底层原理，并分析存储优化与挑战，为设计高效存储方案提供硬核指导。\n3.1 云存储的分类与选型 3.1.1 块存储：高性能与一致性 原理：块存储（如 AWS EBS）以固定大小的块（通常 4KB 或 8KB）为单位提供低级磁盘访问，类似本地硬盘。 特性： 高 IOPS（每秒输入输出操作数），适合数据库（如 MySQL）。 强一致性，保证写后读一致。 实现：通过 iSCSI 或 NVMe over Fabric 协议挂载到实例。 硬核细节：EBS 的性能依赖 SSD 的底层架构（如 NVMe SSD），延迟通常在 1ms 以下，吞吐量受限于网络带宽（如 10 Gbps）。 适用场景：需要高性能随机访问的工作负载，如事务型数据库。 3.1.2 对象存储：分布式与高持久性 原理：对象存储（如 AWS S3）以对象为单位存储数据，每个对象包含数据、元数据和唯一标识符。 特性： 高持久性（Durability，通常 11 个 9）。 最终一致性（Eventual Consistency），适合静态内容。 实现：基于分布式键值存储（如 DynamoDB 架构），通过 HTTP REST API 访问。 硬核细节：S3 使用纠删码（Erasure Coding）替代多副本存储，降低成本。例如，6+3 纠删码可容忍 3 个分片丢失，保证 99.999999999% 的数据可靠性。 适用场景：静态文件存储（如图片、视频）、备份归档。 3.1.3 文件存储：共享访问与 POSIX 兼容性 原理：文件存储（如 AWS EFS）提供基于文件系统的共享存储，支持多实例挂载。 特性： POSIX 兼容，支持文件锁和层次目录。 吞吐量随容量线性扩展。 实现：基于 NFS（网络文件系统）协议，底层可能是分布式文件系统（如 GlusterFS）。 硬核细节：EFS 的性能通过元数据服务器和数据节点的分离优化，延迟通常在 5-10ms，适合并发读写。 适用场景：需要共享存储的场景，如内容管理系统（CMS）。 3.2 分布式 …","date":1535631537,"description":"","fuzzywordcount":2200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"202a74825928cf5ff94e3dbc7926178c","publishdate":1535631537,"relpermalink":"/posts/cloud-platfomr-design/storage-system-design/","section":"posts","summary":"\u003ch2 id=\"云平台系统设计系列深度硬核解析\"\u003e云平台系统设计系列深度硬核解析\u003c/h2\u003e\n\u003ch3 id=\"第三章存储系统设计\"\u003e第三章：存储系统设计\u003c/h3\u003e\n\u003cp\u003e存储系统是云平台的基础支柱，直接影响数据的持久性、性能和成本。在云计算中，存储需求多样化，从高性能的块存储到海量数据的对象存储，再到共享访问的文件存储，每种类型都有其独特的设计考量。本章将深入探讨云存储的分类与选型，剖析分布式存储的底层原理，并分析存储优化与挑战，为设计高效存储方案提供硬核指导。\u003c/p\u003e","tags":["hypervisor","KVM","kubernetes","storage"],"title":"云平台系统设计系列深度硬核解析（第三篇）: 存储系统设计","url":"https://yinlongfei.com/posts/cloud-platfomr-design/storage-system-design/","wordcount":2127},{"categories":"posts","content":"云平台系统设计系列深度硬核解析 第二章：计算资源设计 计算资源是云平台的核心，直接决定了系统能否高效、稳定地处理工作负载。随着技术演进，虚拟机、容器和无服务器（Serverless）成为主流选择，每种方式都有其独特的优势和挑战。本章将深入剖析这些计算模型的实现原理，探讨负载均衡与弹性扩展的机制，并分析多租户设计的复杂性，为构建高性能云平台提供硬核指导。\n2.1 虚拟机 vs 容器 vs 无服务器 2.1.1 虚拟机（VM）的资源分配与隔离机制 原理：虚拟机通过 hypervisor（如 KVM、VMware ESXi）模拟完整硬件环境，每个 VM 拥有独立操作系统。 资源分配：基于 vCPU 和内存配额，调度依赖于主机内核的进程管理。 隔离性：硬件级隔离，依赖 VT-x（Intel）或 AMD-V 指令集实现虚拟化。 硬核细节：VM 的性能开销主要来自 hypervisor 的上下文切换和 I/O 虚拟化（如 VirtIO），典型开销约为 5%-15%。 适用场景：运行遗留系统或需要强隔离的负载。 2.1.2 容器的轻量化与 Docker/Kubernetes 原理 原理：容器基于操作系统级虚拟化，共享主机内核，通过 cgroups 限制资源，namespaces 实现隔离。 Docker 实现： 使用 UnionFS（如 OverlayFS）实现镜像分层。 通过 libcontainer 或 runc 执行容器运行时。 Kubernetes 调度： Pod 作为最小单位，调度器根据资源请求（Request）和限制（Limit）进行 Bin Packing 优化。 控制器（如 ReplicaSet）确保副本数和高可用。 硬核细节：容器启动时间通常在毫秒级，相比 VM 的秒级启动快数个数量级，但安全性依赖内核补丁（如 seccomp）。 适用场景：微服务、DevOps 快速迭代。 2.1.3 Serverless 的触发机制与冷启动优化 原理：Serverless 将计算抽象为函数，按事件触发执行（如 AWS Lambda 的 HTTP 请求或 S3 事件）。 实现： 底层基于容器（如 Firecracker 微型 VM），动态分配资源。 运行时（如 Node.js、Python）按需加载。 冷启动优化： 预热：定期触发函数保持容器活跃。 轻量化运行时：用 Go …","date":1535545137,"description":"","fuzzywordcount":2e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"85ec366f640f8b11d86526c051d31f5a","publishdate":1535545137,"relpermalink":"/posts/cloud-platfomr-design/compute-resource-design/","section":"posts","summary":"\u003ch2 id=\"云平台系统设计系列深度硬核解析\"\u003e云平台系统设计系列深度硬核解析\u003c/h2\u003e\n\u003ch3 id=\"第二章计算资源设计\"\u003e第二章：计算资源设计\u003c/h3\u003e\n\u003cp\u003e计算资源是云平台的核心，直接决定了系统能否高效、稳定地处理工作负载。随着技术演进，虚拟机、容器和无服务器（Serverless）成为主流选择，每种方式都有其独特的优势和挑战。本章将深入剖析这些计算模型的实现原理，探讨负载均衡与弹性扩展的机制，并分析多租户设计的复杂性，为构建高性能云平台提供硬核指导。\u003c/p\u003e","tags":["hypervisor","KVM","kubernetes"],"title":"云平台系统设计系列深度硬核解析（第二篇）: 计算资源设计","url":"https://yinlongfei.com/posts/cloud-platfomr-design/compute-resource-design/","wordcount":1970},{"categories":"posts","content":"云平台系统设计系列深度硬核解析 第一章：云平台设计基础 云计算已经渗透到现代技术的方方面面，从初创公司的快速部署到大企业的全球服务分发，无不依赖于其强大的灵活性和扩展能力。然而，一个优秀的云平台系统并非简单的资源堆叠，而是需要从设计之初就明确目标、理解原理并权衡约束。本章将从云计算的核心概念入手，剖析设计目标与约束，并探讨云平台架构的分层模型，为后续章节打下坚实基础。\n1.1 云计算的核心概念 1.1.1 IaaS、PaaS、SaaS 的本质区别与适用场景 云计算的服务模型通常分为三层：\nIaaS（基础设施即服务）\n提供虚拟化的计算、存储和网络资源，用户拥有最大控制权。例如，AWS EC2 允许用户启动虚拟机并安装任意操作系统。\n适用场景：需要灵活配置底层资源，如托管传统应用或运行自定义工作负载。 硬核细节：IaaS 的核心依赖于虚拟化技术（如 KVM、Xen），通过 hypervisor 将物理硬件抽象为多个隔离的虚拟实例。 PaaS（平台即服务）\n在 IaaS 之上提供开发和运行时环境，用户无需管理底层基础设施。例如，Google App Engine 提供自动扩展的运行环境。\n适用场景：快速开发和部署应用，适合微服务或 API 服务。 硬核细节：PaaS 通常内置负载均衡和容器调度（如 Heroku 的 Dyno），屏蔽了操作系统层面的复杂性。 SaaS（软件即服务）\n直接面向最终用户，提供完整的软件功能，如 Gmail 或 Salesforce。\n适用场景：无需开发，直接使用现成服务。 硬核细节：SaaS 背后往往是多租户架构，通过数据库分片或命名空间隔离实现用户数据的逻辑分离。 1.1.2 云原生（Cloud Native）的定义与技术栈 云原生是充分利用云计算优势的设计理念，强调微服务、容器化、持续交付和动态管理。其核心技术栈包括：\n容器：如 Docker，提供轻量级隔离和一致性部署。 编排：如 Kubernetes，管理容器的调度、扩展和容错。 CI/CD：如 GitHub Actions 或 Jenkins，实现快速迭代。 硬核解析：Kubernetes 的 Pod 是最小调度单位，内部通过 cgroups 和 namespaces 实现资源限制与隔离，而其调度器则基于优先级和约束条件进行优化。 1.1.3 虚拟化、容器化与 Serverless 的 …","date":1535458737,"description":"","fuzzywordcount":2200,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"115cd27128b5896fe0e03fe17a8080f2","publishdate":1535458737,"relpermalink":"/posts/cloud-platfomr-design/fundamentals-of-cloud-platform-design/","section":"posts","summary":"\u003ch2 id=\"云平台系统设计系列深度硬核解析\"\u003e云平台系统设计系列深度硬核解析\u003c/h2\u003e\n\u003ch3 id=\"第一章云平台设计基础\"\u003e第一章：云平台设计基础\u003c/h3\u003e\n\u003cp\u003e云计算已经渗透到现代技术的方方面面，从初创公司的快速部署到大企业的全球服务分发，无不依赖于其强大的灵活性和扩展能力。然而，一个优秀的云平台系统并非简单的资源堆叠，而是需要从设计之初就明确目标、理解原理并权衡约束。本章将从云计算的核心概念入手，剖析设计目标与约束，并探讨云平台架构的分层模型，为后续章节打下坚实基础。\u003c/p\u003e","tags":["hypervisor","KVM","kubernetes"],"title":"云平台系统设计系列深度硬核解析（第一篇）: 云平台设计基础","url":"https://yinlongfei.com/posts/cloud-platfomr-design/fundamentals-of-cloud-platform-design/","wordcount":2159},{"categories":"posts","content":" 原文链接：https://searchitoperations.techtarget.com/tip/Istio-service-mesh-tech-boosts-Kubernetes-work-with-trade-offs\n作者：[Alan R. Earls\n译者：殷龙飞\n为什么 IT 团队不可以使用一种工具，使开发人员能够专注于编写应用程序代码，使管理员可以以专注于 IT 资源的操作？尽管如此，Istio 确实需要研究利弊。 Kubernetes 是一个开源容器编排系统，它提供了管理和扩展容器化应用程序的强大功能，但有些事情它不能很好地完成。而 Istio 增加了额外的支持，它可以管理微服务之间的流量。\nIstio 服务网格项目是平台无关的，协作和开源的，由 IBM，Google 和 Lyft（基于应用程序的传输服务）开发。它使用代理 sider car 模型在云平台上连接，保护，管理和监控微服务网络。Istio 明确定义了基础架构的作用，与运行在其上的软件分离。\nIstio 整合的利弊 编排工具 Kubernetes 与 Istio 的整合，可以让开发人员和 IT 管理员在应用程序容器化这一共同目标上一起努力，IT 管理软件提供商 SolarWinds 的首席软件架构师 Karlo Zatylny 表示: “软件开发人员......将注意力集中在编写能够创造最大商业价值的代码上”。他们不需要考虑部署因素，例如支持容器的 VM 和物理环境。\nZatylny 说：通过 Istio，IT 管理员可以专注于计算资源和网络资源，而不是处理特定的硬件和虚拟分配。部署的基于微服务的应用程序在消耗可用资源方面变得更有效率，而不是在过度使用未充分利用基础架构的某些部分。Istio 还使用配置驱动的通信架构，这提高了开发周期的速度，因此开发人员可以在业务需求变化时轻松地进行软件重新设计。\n尽管代码重用和其他设计选择使复杂性最小化，但 Istio 服务网格设计带来了复杂性和额外的管理开销。\nIstio 在上行和下游提供负载平衡，授权，可见性和运行状况检查，使管理员能够查找，连接和路由各个部署部分。IDC 分析师 Brad Casemore 表示，它将网络应用于开放系统互连模型第7层的微服务交付环境，而不是IP的第3层或第2层的以太网。\nRed Hat 产品管理高级主管 Rich …","date":1533212337,"description":"","fuzzywordcount":1800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"9a5fcd8b3444ea24a9977d64c02daf33","publishdate":1533212337,"relpermalink":"/posts/translations/service-mesh/istio/istio-service-mesh-tech-boosts-kubernetes-work-with-trade-offs/","section":"posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e原文链接：https://searchitoperations.techtarget.com/tip/Istio-service-mesh-tech-boosts-Kubernetes-work-with-trade-offs\u003c/p\u003e","tags":["hypervisor","KVM","kubernetes"],"title":"衡取 Istio 服务网格基于 Kubernetes 工作的优缺点","url":"https://yinlongfei.com/posts/translations/service-mesh/istio/istio-service-mesh-tech-boosts-kubernetes-work-with-trade-offs/","wordcount":1742},{"categories":"posts","content":"Spring 5 源码分析之Spring技术内幕的读书笔记 再读Spring技术内幕，由于之前没做笔记，再读一次觉得做个记录很有必要，这里会把我看这本书的所看所想做简单地记录，首先发现书中讲的Spring版本太老了，书中的Spring版本讲的是3.x版本的，现在Spring版本已经是5.x了，我会把更新部分的内容同样写出来，这里做个做一个读书笔记，看到少写多少吧，以免到时候忘的干净，第一章讲了Spring家族产品包含那些，例如Spring core，spring bean,spring tx,spring mvc spring android等等，讲了Spring的由来，以及Spring的设计理念。不过接下来第二章比较有意思，开始讲SpringIoc的设计原理，在Spring的Ioc中主要有BeanFactory这个接口，根据这个最原始的容器定义接口分别扩展出不同的接口，\nSpring Ioc容器的实现 这里上一下ioc主要的核心接口设计图\n书中主要讲的一个代表性容器是XmlBeanFactory，比过这个容器在5.X时已经设置为不推荐使用的状态，这个类的继承实现类图如下所示，从注释上来看，这个类在3.1时已经不推荐用了，推荐直接用DefaultListableBeanFactory\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Deprecated @SuppressWarnings({\u0026amp;#34;serial\u0026amp;#34;, \u0026amp;#34;all\u0026amp;#34;}) public class XmlBeanFactory extends DefaultListableBeanFactory { private final XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(this); /** * Create a new XmlBeanFactory with the given resource, * which must be parsable using DOM. * @param resource the XML resource to load bean definitions …","date":1532521137,"description":"","fuzzywordcount":1100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"66d94cd2b5f9ccebe876f7ded5ed5602","publishdate":1532521137,"relpermalink":"/posts/spring/spring5-technology-insider-one-part/","section":"posts","summary":"\u003ch1 id=\"spring-5-源码分析之spring技术内幕的读书笔记\"\u003eSpring 5 源码分析之Spring技术内幕的读书笔记\u003c/h1\u003e\n\u003cp\u003e再读Spring技术内幕，由于之前没做笔记，再读一次觉得做个记录很有必要，这里会把我看这本书的所看所想做简单地记录，首先发现书中讲的Spring版本太老了，书中的Spring版本讲的是3.x版本的，现在Spring版本已经是5.x了，我会把更新部分的内容同样写出来，这里做个做一个读书笔记，看到少写多少吧，以免到时候忘的干净，第一章讲了Spring家族产品包含那些，例如Spring core，spring bean,spring tx,spring mvc\nspring android等等，讲了Spring的由来，以及Spring的设计理念。不过接下来第二章比较有意思，开始讲SpringIoc的设计原理，在Spring的Ioc中主要有BeanFactory这个接口，根据这个最原始的容器定义接口分别扩展出不同的接口，\u003c/p\u003e","tags":["spring","android","ioc"],"title":"Spring 5 源码分析之Spring技术内幕的读书笔记","url":"https://yinlongfei.com/posts/spring/spring5-technology-insider-one-part/","wordcount":1029},{"categories":"posts","content":" 原文链接：https://www.circonus.com/2018/06/comprehensive-container-based-service-monitoring-with-kubernetes-and-istio/\n作者：Fred Moyer\n译者：殷龙飞\n运营容器化基础设施带来了一系列新的挑战。您需要对容器进行测试，评估您的 API 端点性能，并确定您的基础架构中的不良的组件。Istio 服务网格可在不更改代码的情况下实现 API 的检测，并且可以自由的设置服务延迟。但是，你如何理解所有这些数据？用数学的方式，对，就是这样。\nCirconus 是 Istio 的第一个第三方适配器。在 之前的文章中，我们讨论了第一个用于监视基于 Istio 的服务的 Istio社区适配器。这篇文章将对此进行扩展。我们将解释如何全面了解您的 Kubernetes 基础设施。我们还将解释如何为基于容器的基础架构增加 Istio 服务网格实现。\nIstio 概述 Istio 是 Kubernetes 的服务网格，这意味着它负责所有服务之间的通信和协调，就像网络路由软件为 TCP/IP 流量所做的一样。除了 Kubernetes 之外，Istio 还可以与基于 Docker 和 Consul 的服务进行交互。它与 LinkerD 相似，它已经存在了一段时间。\nIstio 是由 Google，IBM，思科和 Lyft 的 Envoy 开发的开源项目。该项目已经有一年的历史了，而 Istio 已经进入了大规模生产环境。在这篇文章发布时，当前版本为 0.8。\n那么，Istio 如何融入Kubernetes 生态系统？Kubernetes 充当数据层，Istio 充当控制层。Kubernetes 承载应用程序流量，处理容器编排，部署和扩展。Istio 路由应用程序流量，处理策略执行，流量管理和负载均衡。它还处理遥测联合，如指标，日志和跟踪。Istio 是基于容器的基础设施的交叉防护装置和报告部分。\n上图显示了服务网格体系结构。Istio 为每项服务使用了一个 envoy sidecar proxy。Envoy 通过 GRPC 调用代理到 Istio Mixer 服务的入站请求。然后，Mixer 应用流量管理规则，并联合请求遥测。Mixer 是 Istio 的大脑。 …","date":1532521137,"description":"","fuzzywordcount":6900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"b595be850057d8cf7a481cabe9cdf74a","publishdate":1532521137,"relpermalink":"/posts/translations/service-mesh/istio/comprehensive-container-based-service-monitoring-with-kubernetes-and-istio/","section":"posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e原文链接：https://www.circonus.com/2018/06/comprehensive-container-based-service-monitoring-with-kubernetes-and-istio/\u003c/p\u003e","tags":["istio","circonus","kubernetes"],"title":"使用 Kubernetes 和 Istio 进行基于容器的全面服务监控","url":"https://yinlongfei.com/posts/translations/service-mesh/istio/comprehensive-container-based-service-monitoring-with-kubernetes-and-istio/","wordcount":6899},{"categories":"posts","content":" 原文链接：https://searchitoperations.techtarget.com/feature/Service-mesh-architecture-radicalizes-container-networking\n作者：Beth Pariseau\n译者：殷龙飞\n容器化是IT行业最喜欢的超级英雄，因此容器在服务网格中具有强大的伙伴关系是唯一的选择。他们一起对抗网络管理混乱。 这篇文章也可以在高级版中找到。 现代堆栈：Kubernetes sidecar 是否能提供容器般的快乐？\nBeth Pariseau\n高级新闻作家\n容器和微服务产生了一种称为服务网格的新型网络架构范例，但 IT 行业观察人士对它是否会看到广泛的企业用途持不同意见。\n服务网格体系结构使用一个代理，该代理称为附加到每个应用程序容器，虚拟机或容器编排 pod 的 sidecar 容器，具体取决于所使用的服务网格的类型。然后，该代理可以连接到集中式控制平面软件，这些软件收集细粒度的网络遥测数据，应用网络管理策略或更改代理配置，建立并执行网络安全策略。\nIT系统中的服务网格体系结构还处于初期阶段，但与集装箱一样，其突出地位一直很快。在 2017 年 12 月云原生计算基金会（CNCF）的 KubeCon 和 CloudNativeCon 上，服务网格已经绕过容器成为尖端 DevOps 商店中最热门的主题。\n“我们经常发现自己希望构建应用软件，但我们实际上在做的是一遍又一遍地编写相同的代码来解决某些实际上非常困难的计算机科学问题，这些问题应该被考虑到某种通用接口中”，微服务监控创业公司 LightStep 首席执行官 Ben Sigelman 在 KubeCon 的服务网格主题演讲中表示。\n“服务网格可以帮助发现服务，互连这些服务，断路由，负载均衡，......安全和身份验证” , Sigelman说，他是前谷歌工程师，OpenTracing 的创建者，OpenTracing 是开源的，提供不依赖供应商的 API。\n服务网格简史 最早版本的 sidecar 代理技术在 2016 年初开始出现在网络规模的商店，如谷歌和推特，微服务管理需要对网络进行新的思考。与传统的单体应用程序不同，微服务依靠外部网络来沟通和协调应用程序功能。这些微服务通信需要密切监控，有时需要大规模重新配置。\n用于使微服务网络 …","date":1530447537,"description":"","fuzzywordcount":4100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c4801505fa096f9d3b3cd8cd511e04d5","publishdate":1530447537,"relpermalink":"/posts/translations/service-mesh/service-mesh-architecture-radicalizes-container-networking/","section":"posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e原文链接：https://searchitoperations.techtarget.com/feature/Service-mesh-architecture-radicalizes-container-networking\u003c/p\u003e","tags":["service-mesh"],"title":"服务网状结构激化了容器网络","url":"https://yinlongfei.com/posts/translations/service-mesh/service-mesh-architecture-radicalizes-container-networking/","wordcount":4025},{"categories":"posts","content":" 原文链接：https://hackernoon.com/traffic-routing-between-fn-functions-using-fn-project-and-istio-fd56607913b8\n作者：Peter Jausovec\n译者：殷龙飞\n在本文中，我将解释如何在 Fn 函数之间使用 Istio 服务网格实现基于版本的流量路由。\n我将首先解释 Istio 路由的基础知识以及 Fn 部署和运行在 Kubernetes 上的方式。最后，我将解释我是如何利用Istio 服务网格及其路由规则在两个不同的 Fn 函数之间路由流量的。\n请注意，接下来的解释非常基本和简单 - 我的目的不是解释 Istio 或 Fn 的深入工作，而是我想解释得足够多，所以您可以了解如何使自己的路由工作。\nIstio 路由 101 让我花了一点时间来解释 Istio 路由如何工作。Istio 使用 sidecar 容器（ istio-proxy ）注入到您部署的应用中。注入的代理会劫持所有进出该 pod 的网络流量。部署中所有这些代理的集合与 Istio 系统的其他部分进行通信，以确定如何以及在何处路由流量（以及其他一些很酷的事情，如流量镜像，故障注入和断路由）。\n为了解释这是如何工作的，我们将开始运行一个 Kubernetes 服务（myapp）和两个特定版本的应用程序部署（v1和v2）。\n在上图中，我们有 myapp 一个选择器设置为 Kubernetes 的服务app=myapp , 这意味着它将查找具有 app=myapp 标签集的所有 Pod，并将流量发送给它们。基本上，如果您执行此操作，curl myapp-service 您将从运行 v1 版本应用程序的 pod 或运行 v2 版本的 pod 获得响应。\n我们还有两个 Kubernetes 部署 - 这些部署myapp运行了 v1 和 v2 代码。除 app=myapp 标签外，每个 pod 还将version标签设置为 v1或 v2。\n上图中的所有内容都是可以从 Kubernetes 中开箱即用的。\n进入 Istio。为了能够做到更智能化和基于权重的路由，我们需要安装 Istio，然后将代理注入到我们的每个容器中，如下面的另一个真棒图所示。下图中的每个 pod 都有一个带有 Istio 代理的容器（用蓝色图标表 …","date":1530015537,"description":"","fuzzywordcount":4600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"0f5d8216e890f4927b7c85e826d8d436","publishdate":1530015537,"relpermalink":"/posts/translations/service-mesh/istio/traffic-routing-between-fn-functions-using-fn-project-and-istio-fd/","section":"posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e原文链接：https://hackernoon.com/traffic-routing-between-fn-functions-using-fn-project-and-istio-fd56607913b8\u003c/p\u003e","tags":["Istio"],"title":"使用 Fn Project 和 Istio 的 Function 之间的通信路由","url":"https://yinlongfei.com/posts/translations/service-mesh/istio/traffic-routing-between-fn-functions-using-fn-project-and-istio-fd/","wordcount":4599},{"categories":"posts","content":" 原文链接：https://medium.com/@prune998/istio-envoy-cert-manager-lets-encrypt-for-tls-14b6a098f289\n作者：Prune\n译者：殷龙飞\n更新\n感谢 Laurent Demailly 的评论，这里有一些更新。这篇文章已经得到了更新：\n现在有一个 Cert-Manager 官方 Helm 图表 Istio Ingress 也支持基于 HTTP/2 的 GRPC Istio Istio 是管理微服务世界中数据流的一种新方式。事实上，这对我来说更是如此。 人们不停的谈论微服务与单体应用，说微服务更好开发，易于维护，部署更快...... 呃，他们是对的，但微服务不应该仅仅是小应用程序之间互相通信。微服务应该考虑沉淀为你的基础设施的这种方式。考虑如何决定您的“简单”应用程序公开指标和日志的方式，考虑您如何跟踪状态，考虑如何控制服务之间的流程以及如何管理错误，这些问题应该是做微服务应该考虑的。\n那么 Istio 能够在这个微服务世界中增加什么？\nIstio 是一个服务网格的实现！\nWhaaaaaat？服务网格？我们已经有了 Kubernetes API，我们需要“网格”吗？\n那么，是的，你需要服务网格。 我不会解释使用它的所有好处，你会在网上找到足够的文档。但是用一句话来说，服务网格就是将您所有的服务提供给其他服务的技术。 事实上，它还强制执行所有“微服务”最佳实践，例如添加流量和错误指标，添加对 OpenTracing（ Zipkin 和Jaegger）的支持，允许控制重试，金丝雀部署......阅读 Istio doc ！\n所以，回到本话题...\n必要条件 建议运行在 Kubernetes1.7 及以上的集群版本 一个或多个 DNS 域名 让 Istio 利用Ingress Controller 在你的集群中工作 将上面的 DNS 域名配置为指向 Istio Ingress IP SSL SSL 是安全的（很好），但它通常是软件中实现的最后一件事。为什么？之前它实现起来是“很困难的”，但我现在看不出任何理由。Let\u0026#39;s Encrypt 创建一个新的范例，它的 DAMN 很容易使用 API 调用创建 Valide SSL 证书（协议被称为ACME ...）。它为您提供 3 种验证您是域名所有者的 …","date":1529669937,"description":"","fuzzywordcount":4300,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"b051e9aa6f41b538428ba58df6dadcb6","publishdate":1529669937,"relpermalink":"/posts/translations/service-mesh/istio/istio-envoy-cert-manager-lets-encrypt-for-tls/","section":"posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e原文链接：https://medium.com/@prune998/istio-envoy-cert-manager-lets-encrypt-for-tls-14b6a098f289\u003c/p\u003e","tags":["hypervisor","KVM","kubernetes"],"title":"利用Let's Encrypt 为Istio（Envoy）添加TLS 支持","url":"https://yinlongfei.com/posts/translations/service-mesh/istio/istio-envoy-cert-manager-lets-encrypt-for-tls/","wordcount":4270},{"categories":"posts","content":"这个原文是 5 月初发表的原文的翻译。补充一下这篇文章的背景，Cookpad 是一家拥有 200 多种产品开发的中型科技公司，拥有 10 多支团队，每月平均用户数量达到 9000 万。https://www.cookpadteam.com/\n你好，我是来自生产团队的开发人员Taiki。目前，我想介绍一下在 Cookpad 上构建和使用服务网格所获得的知识。\n对于服务网格本身，我认为您将对以下文章，公告和教程有完整的了解：\nhttps://speakerdeck.com/taiki45/observability-service-mesh-and-microservices https://buoyant.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/ https://blog.envoyproxy.io/service-mesh-data-plane-vs-control-plane-2774e720f7fc https://istioio.io/docs/setup/kubernetes/quick-start.html https://www.youtube.com/playlist?list=PLj6h78yzYM2P-3-xqvmWaZbbI1sW-ulZb 我们的目标 我们引入了一个服务网格来解决故障排除，容量规划和保持系统可靠性等操作问题。尤其是：\n降低服务组的管理成本 可观察性的改进 \\(分别参考了 [ Twitter ](https://blog.twitter.com/engineering/en_us/a/2013/observability-at-twitter.html) 和 [Medium的博客](https://medium.com/@copyconstruct/monitoring-and-observability-8417d1952e1c)\\) 建立更好的故障隔离机制 就第一个问题而言，随着规模的扩大，存在难以掌握哪个服务和哪个服务正在进行通信，某个服务的失败是哪里传播导致的问题。我认为这个问题应该通过综合管理服务在哪里和服务在哪里连接的相关信息来解决。\n对于第二个问题而言，我们进一步深究了第一个问题，我们发现我们不知道一个服务与另一个服务之间的通信状态。例 …","date":1529410737,"description":"","fuzzywordcount":3100,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"c323211d6edf81f98f99411e7ca6e790","publishdate":1529410737,"relpermalink":"/posts/translations/service-mesh/service-mesh-and-cookpad/","section":"posts","summary":"\u003cp\u003e这个原文是 5 月初发表的\u003ca href=\"http://techlife.cookpad.com/entry/2018/05/08/080000\"\u003e原文\u003c/a\u003e的翻译。补充一下这篇文章的背景，Cookpad 是一家拥有 200 多种产品开发的中型科技公司，拥有 10 多支团队，每月平均用户数量达到 9000 万。\u003ca href=\"https://www.cookpadteam.com/\"\u003ehttps://www.cookpadteam.com/\u003c/a\u003e\u003c/p\u003e","tags":["service-mesh","cookpad"],"title":"服务网格和Cookpad","url":"https://yinlongfei.com/posts/translations/service-mesh/service-mesh-and-cookpad/","wordcount":3097},{"categories":"posts","content":"\nAspen Mesh的Andrew Jenkins说，转向微服务本身并不能消除复杂性。\n知识共享零\n在本文中，我们与Aspen Mesh的首席架构师Andrew Jenkins谈论了如何从单一应用程序转向微服务，并通过一些关于服务网格的宣传来管理微服务架构。有关服务网格的更多信息，请考虑参加于2018年5月2日至4日在丹麦哥本哈根举行的KubeCon + CloudNativeCon EU。\n微服务解决了许多公司面临的单片架构问题。你在哪里看到最大的价值？\nAndrew Jenkins ： 对我来说，这是关于最小化时间对用户的影响。向虚拟化和云转型的关键是降低与支持应用程序的所有基础架构相关的复杂性，以便您可以灵活地分配服务器和存储等。但是这种转变并不一定会改变我们构建的应用程序。现在我们有了灵活的基础架构，我们应该构建灵活的应用程序以充分利用它。\n微服务是那些灵活的应用程序 - 构建小型，单一用途的模块并快速构建它们，以便您可以快速将它们交付给最终用户。组织可以使用它来根据实际用户需求进行测试并迭代构建。\n2.随着企业从单一应用程序向微服务转移，收益显而易见，但公司在采取行动时遇到的一些挑战是什么？\nJenkins ： 转向微服务本身并不能消除复杂性。任何一个微服务的复杂性都很小，但是整个系统都很复杂。从根本上说，公司希望知道哪个服务正在与哪个服务对话，代表哪个服务对象，然后能够使用策略来控制该通信。\n经许可使用\n3.组织如何尝试应对这些挑战？\nJenkins ： 一些公司从第一天起就将这种可见性和策略部分添加到他们构建的每个应用程序中。当公司投资于定制工具，工作流程，部署管理和 CD 管道时，这种情况尤其常见。我们也发现这些公司通常是以几种语言为导向，并且几乎写出他们自己运行的所有内容。\n如果您的应用程序堆栈是多边形的，并且是新开发和迁移现有应用程序的组合，则很难证明将这些部分单独添加到每个应用程序是合理的。来自不同团队和外部开发的应用程序的应用程序更多地提高了这一点，一种方法是分别对待那些不符合要求的应用程序 - 将它们置于策略执行代理之后，或者从可见性角度将它们视为更多的黑盒子。但是，如果你不必做出这种分离，那么如果有一种简单的方法来获得任何语言的任何应用程序的原生式策略和可见性，那么你可以看到它的优势。服务网格就是这样的一种方法。\n4.作为管理微服务架构 …","date":1529410737,"description":"","fuzzywordcount":3e3,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"77e86c4f07fd51f36b6dd1ba3a25002a","publishdate":1529410737,"relpermalink":"/posts/translations/service-mesh/making-most-out-microservices-service-mesh/","section":"posts","summary":"\u003cp\u003e\u003cimg src=\"https://ws1.sinaimg.cn/large/61411417ly1fsgj45r133j20m80aumyx.jpg\" alt=\"\" title=\"mesh\"\u003e\u003c/p\u003e\n\u003cp\u003eAspen Mesh的Andrew Jenkins说，转向微服务本身并不能消除复杂性。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.linux.com/licenses/category/creative-commons-zero\"\u003e知识共享零\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e在本文中，我们与Aspen Mesh的首席架构师Andrew Jenkins谈论了如何从单一应用程序转向微服务，并通过一些关于服务网格的宣传来管理微服务架构。有关服务网格的更多信息，请考虑参加于2018年5月2日至4日在丹麦哥本哈根举行的\u003ca href=\"https://events.linuxfoundation.org/events/kubecon-cloudnativecon-europe-2018/attend/register/\"\u003eKubeCon + CloudNativeCon EU\u003c/a\u003e。\u003c/p\u003e","tags":["service-mesh","kubernetes"],"title":"利用服务网格充分利用微服务","url":"https://yinlongfei.com/posts/translations/service-mesh/making-most-out-microservices-service-mesh/","wordcount":2967},{"categories":"posts","content":"开篇：大数据的新十字路口 大数据的征途已走过二十余载，从Hadoop的奠基到云计算的普及，再到AI驱动的智能分析，它深刻改变了我们的技术与生活图景。然而，2017年的今天，全球数据总量突破200泽字节（ZB），大数据生态却站在了新的十字路口。爆炸式增长的规模、日益严格的隐私法规、复杂多样的应用场景，正推动技术面临前所未有的挑战。与此同时，量子计算、边缘智能等前沿技术为大数据带来了新的可能性。本篇将带你剖析大数据的痛点与瓶颈，并展望其未来的硬核趋势。\n大数据的旅程远未结束，它既是挑战的深渊，也是机遇的巅峰。让我们从当前的困境开始，逐步探索未来的蓝图。\n一、大数据的核心挑战 大数据的成功背后隐藏着诸多技术与实践难题，以下是三大核心挑战。\n1. 数据治理：从混乱到秩序 问题： 数据孤岛：企业内部系统分散，数据难以整合。 元数据混乱：缺乏统一标注，查询效率低下。 量化：一份调研显示，70%的企业数据未被有效利用，平均每TB数据治理成本达数千美元。 案例：某零售商因数据格式不一致，库存分析耗时从小时级升至天级。 技术瓶颈 元数据管理：传统RDBMS无法处理PB级异构元数据。 数据湖的陷阱：HDFS等存储虽容量大，但未经治理沦为“数据沼泽”。 当前解法 数据目录：如Apache Atlas，自动生成元数据标签。 湖仓一体：Databricks Delta Lake整合数据湖与仓库，支持事务与版本控制。 2. 隐私与安全：数据的双刃剑 问题： 法规压力：GDPR、CCPA要求数据最小化与用户同意。 安全威胁：2024年全球数据泄露事件同比增长30%。 量化：一次TB级数据泄露平均损失超500万美元。 案例：某医疗公司因未加密患者数据，罚款1亿欧元。 技术瓶颈 加密开销：全盘加密降低查询性能10-50%。 匿名化矛盾：去标识化（如K匿名）削弱分析精度。 当前解法 同态加密：加密数据上直接计算，性能仍需优化。 差分隐私：添加噪声保护个体，Google已用于人口统计。 3. 技术复杂性与成本 问题： 架构复杂：从存储到计算到可视化，技术栈繁琐。 资源消耗：PB级处理需高昂硬件与云费用。 量化：AWS上处理1PB数据年成本可达百万美元。 案例：某初创公司因未优化Spark集群，计算费用超预算50%。 技术瓶颈 调度效率：Kubernetes虽强大，但配置复杂。 冷热分离：频繁访问冷数据成 …","date":1504959537,"description":"","fuzzywordcount":2700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"612ae53278facff1358af05e8853f3cd","publishdate":1504959537,"relpermalink":"/posts/big-data/big_data6/","section":"posts","summary":"\u003ch2 id=\"开篇大数据的新十字路口\"\u003e开篇：大数据的新十字路口\u003c/h2\u003e\n\u003cp\u003e大数据的征途已走过二十余载，从Hadoop的奠基到云计算的普及，再到AI驱动的智能分析，它深刻改变了我们的技术与生活图景。然而，2017年的今天，全球数据总量突破200泽字节（ZB），大数据生态却站在了新的十字路口。爆炸式增长的规模、日益严格的隐私法规、复杂多样的应用场景，正推动技术面临前所未有的挑战。与此同时，量子计算、边缘智能等前沿技术为大数据带来了新的可能性。本篇将带你剖析大数据的痛点与瓶颈，并展望其未来的硬核趋势。\u003c/p\u003e","tags":["大数据"],"title":"大数据系列硬核专题（第六篇）: 大数据的挑战与未来趋势","url":"https://yinlongfei.com/posts/big-data/big_data6/","wordcount":2628},{"categories":"posts","content":"开篇：可视化，数据的最后一公里 如果说存储奠定了大数据的根基，计算赋予了生命，算法挖掘了价值，那么可视化就是连接数据与决策的最后一公里。2025年，全球数据总量已超过200泽字节（ZB），从亿级传感器读数到实时社交媒体流，数据的复杂性和规模对传统可视化技术提出了前所未有的挑战。如何将海量、异构、动态的数据转化为直观的图表、仪表盘甚至交互式体验？本篇将带你走进大数据可视化的硬核世界，剖析其技术内核、工具原理与应用实践。\n可视化不仅是呈现数据的工具，更是洞察与行动的桥梁。让我们从技术挑战开始，逐步揭开大数据可视化的层层奥秘。\n一、大数据可视化的技术挑战 大数据可视化不同于传统小规模数据呈现，其难点在于规模、速度和多样性的综合考验。\n1. 海量数据的渲染瓶颈 问题：亿级数据点的可视化（如散点图）超出浏览器或GPU的处理能力。 量化：假设绘制1亿个点，每个点10字节（坐标+属性），总计1GB，单线程渲染需数分钟。 解决方向： 数据聚合：聚类（如K-Means）或分桶（Binning）减少绘制点数。 GPU加速：WebGL利用显卡并行渲染。 2. 实时性的性能要求 问题：秒级更新的仪表盘需低延迟处理和渲染。 案例：金融交易监控需每秒刷新数十万条记录。 解决方向： 增量更新：只渲染变化数据。 流式计算：后端实时聚合，前端订阅更新。 3. 数据多样性的表达 问题：结构化（表格）、半结构化（JSON）和非结构化（文本、图像）数据需统一呈现。 挑战：如何在同一界面展示时间序列、地理分布和网络关系？ 解决方向： 多视图设计：分层展示不同数据类型。 自定义可视化：支持用户定义映射规则。 小结：大数据可视化需平衡性能、实时性和灵活性，技术复杂度远超传统工具。\n二、可视化工具的硬核原理 从底层库到企业级解决方案，可视化工具各有千秋。我们聚焦D3.js和Tableau的内核。\n1. D3.js：底层渲染的艺术 D3.js（Data-Driven Documents）是Web可视化的基石，依赖JavaScript和SVG。\n原理与架构 数据绑定：将数据与DOM元素一一映射。 示例：d3.selectAll(\u0026amp;quot;circle\u0026amp;quot;).data(points).enter().append(\u0026amp;quot;circle\u0026amp;quot;)。 渲染管道： 数据加载（如JSON）。 计算布局（如力导 …","date":1504873137,"description":"","fuzzywordcount":2600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"3f5306ab4089ee4934adddf9ffa23ab4","publishdate":1504873137,"relpermalink":"/posts/big-data/big_data5/","section":"posts","summary":"\u003ch2 id=\"开篇可视化数据的最后一公里\"\u003e开篇：可视化，数据的最后一公里\u003c/h2\u003e\n\u003cp\u003e如果说存储奠定了大数据的根基，计算赋予了生命，算法挖掘了价值，那么可视化就是连接数据与决策的最后一公里。2025年，全球数据总量已超过200泽字节（ZB），从亿级传感器读数到实时社交媒体流，数据的复杂性和规模对传统可视化技术提出了前所未有的挑战。如何将海量、异构、动态的数据转化为直观的图表、仪表盘甚至交互式体验？本篇将带你走进大数据可视化的硬核世界，剖析其技术内核、工具原理与应用实践。\u003c/p\u003e","tags":["大数据","可视化","D3"],"title":"大数据系列硬核专题（第五篇）: 大数据分析的硬核算法","url":"https://yinlongfei.com/posts/big-data/big_data5/","wordcount":2547},{"categories":"posts","content":"开篇：算法，洞察的钥匙 如果说存储是大数据的基石，计算是数据的生命力，那么分析算法就是解锁洞察的钥匙。2025年，全球数据总量突破200泽字节（ZB），单纯的存储和计算已不足以应对商业决策、科学研究和实时预测的需求。从推荐系统的个性化推送，到社交网络的异常检测，再到金融市场的风险评估，大数据分析算法将混沌的数据转化为可操作的智慧。本篇将带你走进大数据分析的硬核世界，剖析其核心算法、分布式实现与应用实践。\n算法不仅是数学的艺术，更是数据的灵魂。让我们从分布式机器学习的架构开始，逐步揭开大数据分析的技术内核。\n一、分布式机器学习：从单机到集群的突破 机器学习（ML）在大数据时代面临计算与数据规模的双重挑战，分布式训练成为必然趋势。我们聚焦两种主流架构：参数服务器和AllReduce。\n1. 参数服务器（Parameter Server） 参数服务器架构将模型参数与计算任务分离，适合深度学习等高维模型。\n架构与原理 角色： Server节点：存储和更新全局参数。 Worker节点：计算梯度，基于本地数据。 工作流程： Worker从Server拉取最新参数。 Worker计算梯度（基于数据分片）。 Worker推送梯度至Server，Server聚合更新参数。 同步模式： 同步（Sync）：所有Worker完成后更新。 异步（Async）：Worker独立更新，允许延迟。 硬核细节 通信开销：梯度传输是瓶颈。例如，1亿参数模型（float32，4字节/参数），每次传输400MB。 容错性：Server故障通过检查点恢复，Worker失败重启任务。 优化：梯度压缩（如量化）减少带宽需求。 数学视角 梯度下降更新：\n\\( w_{t+1} = w_t - \\eta \\sum_{i=1}^N g_i \\)，\n其中 \\( g_i \\) 为第 \\( i \\) 个Worker的梯度，\\( N \\) 为Worker数，\\( \\eta \\) 为学习率。 假设100个Worker，每秒传输1GB梯度，网络带宽10Gbps，通信延迟约0.8秒。 案例 Google用参数服务器训练神经网络，处理PB级搜索日志，优化广告点击率。\n2. AllReduce：去中心化的并行 AllReduce是MPI（消息传递接口）中的经典操作，广泛用于分布式ML（如TensorFlow）。\n架构与原理 无中心节点： …","date":1504786737,"description":"","fuzzywordcount":2700,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"ce4def64e087bbb84dc9ef41160619fb","publishdate":1504786737,"relpermalink":"/posts/big-data/big_data4/","section":"posts","summary":"\u003ch2 id=\"开篇算法洞察的钥匙\"\u003e开篇：算法，洞察的钥匙\u003c/h2\u003e\n\u003cp\u003e如果说存储是大数据的基石，计算是数据的生命力，那么分析算法就是解锁洞察的钥匙。2025年，全球数据总量突破200泽字节（ZB），单纯的存储和计算已不足以应对商业决策、科学研究和实时预测的需求。从推荐系统的个性化推送，到社交网络的异常检测，再到金融市场的风险评估，大数据分析算法将混沌的数据转化为可操作的智慧。本篇将带你走进大数据分析的硬核世界，剖析其核心算法、分布式实现与应用实践。\u003c/p\u003e","tags":["大数据","算法","ML"],"title":"大数据系列硬核专题（第四篇）: 大数据分析的硬核算法","url":"https://yinlongfei.com/posts/big-data/big_data4/","wordcount":2690},{"categories":"posts","content":"开篇：计算，数据的生命力 如果说存储是大数据的基石，那么计算就是赋予数据生命力的引擎。2017年，随着数据规模从PB迈向ZB，计算需求从批处理转向实时、从单机走向分布式、从静态分析迈向动态预测，大数据计算框架经历了深刻的变革。从Hadoop MapReduce的开山之作，到Spark的内存计算革命，再到Flink的流批一体，每一次技术迭代都重塑了数据处理的边界。本篇将带你走进大数据计算的硬核世界，剖析其架构原理、性能瓶颈与应用实践。\n计算不仅是数据的加工厂，更是洞察的源泉。让我们从MapReduce的起点出发，逐步揭开现代计算引擎的技术内核。\n一、MapReduce：分布式计算的奠基石 MapReduce由Google提出并在2004年公开，是大数据计算的起点，随后被Hadoop实现并推广。\n1. 架构与工作原理 MapReduce将大规模数据处理分解为两个阶段，通过分布式并行执行实现高效计算。\n工作流程 输入分片（Input Split）：将输入数据按块（默认128MB）分割，分配给Map任务。 Map阶段：对每个分片执行用户定义的Map函数，生成中间键值对（Key-Value Pair）。 Shuffle阶段：按键分区并排序，分发到Reduce节点。 Reduce阶段：对每个键的数值进行聚合，输出最终结果。 代码示例（词频统计） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // Map函数 public class Mapper { void map(String line, Context context) { String[] words = line.split(\u0026amp;#34;\\\\s+\u0026amp;#34;); for (String word : words) { context.write(word, 1); // 输出 (word, 1) } } } // Reduce函数 public class Reducer { void reduce(String key, Iterable\u0026amp;lt;Integer\u0026amp;gt; values, Context context) { int sum = 0; for (int value : values) { sum += value; } …","date":1504441137,"description":"","fuzzywordcount":2900,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"d2367bbf877da9ebfee0b6d3d35fd4e1","publishdate":1504441137,"relpermalink":"/posts/big-data/big_data3/","section":"posts","summary":"\u003ch2 id=\"开篇计算数据的生命力\"\u003e开篇：计算，数据的生命力\u003c/h2\u003e\n\u003cp\u003e如果说存储是大数据的基石，那么计算就是赋予数据生命力的引擎。2017年，随着数据规模从PB迈向ZB，计算需求从批处理转向实时、从单机走向分布式、从静态分析迈向动态预测，大数据计算框架经历了深刻的变革。从Hadoop MapReduce的开山之作，到Spark的内存计算革命，再到Flink的流批一体，每一次技术迭代都重塑了数据处理的边界。本篇将带你走进大数据计算的硬核世界，剖析其架构原理、性能瓶颈与应用实践。\u003c/p\u003e","tags":["大数据","MapReduce","Spark"],"title":"大数据系列硬核专题（第三篇）: 大数据计算的硬核引擎","url":"https://yinlongfei.com/posts/big-data/big_data3/","wordcount":2866},{"categories":"posts","content":"开篇：存储，数据的第一道防线 如果说大数据是信息时代的洪流，那么存储就是这场洪流的基石。2017年，全球数据总量已超过200泽字节（ZB），其中90%以上是非结构化数据，传统单机存储早已不堪重负。从PB级文件的分布式管理，到毫秒级响应的实时查询，大数据存储技术经历了从量变到质变的飞跃。本篇将带你走进存储技术的硬核世界，剖析其底层原理、关键实现和未来趋势。\n存储不仅是数据的容器，更是计算与分析的起点。让我们从分布式文件系统的奠基之作开始，逐步揭开大数据存储的层层技术面纱。\n一、分布式文件系统：从单机到集群的跨越 分布式文件系统（DFS）是大规模数据存储的基石，解决了单机容量和性能的瓶颈。HDFS和GFS是最具代表性的实现，我们将深入其内核。\n1. HDFS：Hadoop的存储基石 Revisited HDFS（Hadoop Distributed File System）在上一专题中已有提及，但其存储细节值得进一步挖掘。\n架构与原理 NameNode：元数据管理中心，存储文件路径、分片位置等信息。内存中维护文件树，持久化到磁盘（fsimage和editlog）。 DataNode：数据存储节点，默认块大小128MB，3副本策略确保容错。 读写流程： 写：客户端联系NameNode分配块位置，数据分片后并行写入DataNode，副本同步完成。 读：NameNode返回块位置，客户端直接访问DataNode，优先选择最近节点（数据本地性）。 硬核细节 块大小设计：128MB远大于传统文件系统（如ext4的4KB），为何？大块减少元数据开销，提升顺序读写性能，但不适合小文件。 容错机制：DataNode定期发送心跳（默认3秒），若10分钟无响应，NameNode触发副本重建。重建速度受限于网络带宽（如10Gbps下，1TB需2小时）。 瓶颈：单一NameNode的内存容量限制集群规模，后引入Federation（多NameNode分担命名空间）。 数学视角 假设集群有100个DataNode，每个存储2TB，副本因子3： 总容量 = 200TB / 3 ≈ 66.7TB（实际可用）。 单节点故障，丢失2TB，副本恢复需复制2TB数据。 2. GFS：Google的存储启示 Google File System（GFS）是HDFS的灵感来源，2003年论文奠定了分布式存储的范 …","date":1504354737,"description":"","fuzzywordcount":3400,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"e48c5b9d61c11225c7c85fad12cbb88f","publishdate":1504354737,"relpermalink":"/posts/big-data/big_data2/","section":"posts","summary":"\u003ch2 id=\"开篇存储数据的第一道防线\"\u003e开篇：存储，数据的第一道防线\u003c/h2\u003e\n\u003cp\u003e如果说大数据是信息时代的洪流，那么存储就是这场洪流的基石。2017年，全球数据总量已超过200泽字节（ZB），其中90%以上是非结构化数据，传统单机存储早已不堪重负。从PB级文件的分布式管理，到毫秒级响应的实时查询，大数据存储技术经历了从量变到质变的飞跃。本篇将带你走进存储技术的硬核世界，剖析其底层原理、关键实现和未来趋势。\u003c/p\u003e","tags":["大数据","HDFS","Hadoop","存储"],"title":"大数据系列硬核专题（第二篇）: 大数据存储的硬核技术","url":"https://yinlongfei.com/posts/big-data/big_data2/","wordcount":3314},{"categories":"posts","content":"开篇：大数据的冰山一角 在信息时代，数据如洪流般席卷而来。2017年，全球每天产生的数据量已超过500艾字节（EB），社交媒体、物联网设备、自动驾驶汽车和金融交易系统无时无刻不在生成海量信息。然而，大数据究竟是什么？是单纯的“量大”，还是隐藏在技术与思维深处的革命性转变？本篇将带你从现象深入本质，拆解大数据的定义、技术基石与实践根源，揭开这一领域的硬核面纱。\n大数据不仅仅是技术的堆砌，它是一种从“存储”到“洞察”的思维跃迁。让我们从最基础的概念开始，逐步走进分布式系统的理论内核和早期技术的奠基实践。\n一、大数据的“5V”特征：从表象到内核 大数据的定义并非空洞的口号，而是由五个核心特征（5V）支撑的理论框架。这些特征不仅描述了数据的物理属性，更揭示了技术设计的挑战与方向。\n1. Volume（体量）：数据的洪流 体量是大数据最直观的特征。2025年，全球数据总量预计突破200泽字节（ZB），其中90%是非结构化数据。以YouTube为例，每分钟上传的视频时长超过500小时，相当于每天生成约1PB的数据。\n技术挑战：传统单机存储（如RAID磁盘阵列）已无法应对PB级需求。假设一块硬盘容量为10TB，一个PB需要100块硬盘，而数据中心的扩展性、散热和能耗问题随之而来。 量化视角：存储1PB数据需要约10^15字节，若按每秒读写速度500MB/s计算，单机顺序读取需要23天，这显然不可接受。 2. Velocity（速度）：实时性的较量 速度指的是数据生成和处理的频率。从金融高频交易（毫秒级响应）到工业传感器（秒级监控），实时性已成为大数据的核心诉求。\n案例：股票交易所每天处理超过10亿条交易记录，延迟超过50毫秒可能导致数百万美元的损失。 技术演进：批处理（如Hadoop MapReduce）逐渐被流处理（如Apache Kafka和Flink）取代，后者能在毫秒级窗口内完成数据聚合。 3. Variety（多样性）：数据的异构融合 大数据不再局限于结构化表格，而是涵盖文本、图像、视频、日志等多种形态。例如，一条社交媒体帖子可能包含文字、表情包和定位信息。\n挑战：如何将这些异构数据统一存储和分析？传统关系型数据库（RDBMS）的严格Schema设计在此失效。 解法：NoSQL数据库（如MongoDB）和分布式文件系统（如HDFS）应运而生，支持灵活的数据模型。 4. …","date":1504009137,"description":"","fuzzywordcount":3600,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"15cf82aea9f0e34c220d92bc5c763579","publishdate":1504009137,"relpermalink":"/posts/big-data/big_data1/","section":"posts","summary":"\u003ch2 id=\"开篇大数据的冰山一角\"\u003e开篇：大数据的冰山一角\u003c/h2\u003e\n\u003cp\u003e在信息时代，数据如洪流般席卷而来。2017年，全球每天产生的数据量已超过500艾字节（EB），社交媒体、物联网设备、自动驾驶汽车和金融交易系统无时无刻不在生成海量信息。然而，大数据究竟是什么？是单纯的“量大”，还是隐藏在技术与思维深处的革命性转变？本篇将带你从现象深入本质，拆解大数据的定义、技术基石与实践根源，揭开这一领域的硬核面纱。\u003c/p\u003e","tags":["大数据","CAP","Hadoop"],"title":"大数据系列硬核专题（第一篇）: 大数据的本质与技术基石","url":"https://yinlongfei.com/posts/big-data/big_data1/","wordcount":3521},{"categories":"posts","content":"SpringBootServletInitializer 源码分析如何实现SpringBootServletInitializer整个加载过程 实现自定义WebApplicationInitializer配置加载 实现自定义ServletContainerInitializer配置加载 示例代码 首先web.xml主要配置各种servlet,filter,listener等,如常见的Log4jConfigListener,OpenSessionInViewFilter,CharacterEncodingFilter,DispatcherServlet等,此大部分信息均是容器启动时加载. 在SpringBoot中我们从SpringBootServletInitializer源码入手: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public abstract class SpringBootServletInitializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext servletContext) throws ServletException { // Logger initialization is deferred in case a ordered // LogServletContextInitializer is being used this.logger = LogFactory.getLog(getClass()); WebApplicationContext rootAppContext = createRootApplicationContext( servletContext); if (rootAppContext != null) { servletContext.addListener(new ContextLoaderListener(rootAppContext) { @Override public void contextInitialized(ServletContextEvent event) { // no-op …","date":1469449137,"description":"","fuzzywordcount":2500,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"6a35362696e2dedf917a46048c187f66","publishdate":1469449137,"relpermalink":"/posts/spring/springbootservletinitializer%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0web.xml%E8%A7%A3%E6%9E%90/","section":"posts","summary":"\u003ch1 id=\"springbootservletinitializer\"\u003eSpringBootServletInitializer\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003e源码分析如何实现SpringBootServletInitializer整个加载过程\u003c/li\u003e\n\u003cli\u003e实现自定义WebApplicationInitializer配置加载\u003c/li\u003e\n\u003cli\u003e实现自定义ServletContainerInitializer配置加载\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"示例代码\"\u003e示例代码\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e首先web.xml主要配置各种servlet,filter,listener等,如常见的Log4jConfigListener,OpenSessionInViewFilter,CharacterEncodingFilter,DispatcherServlet等,此大部分信息均是容器启动时加载.\u003c/li\u003e\n\u003cli\u003e在SpringBoot中我们从SpringBootServletInitializer源码入手:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e18\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e19\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e20\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e21\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e22\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e23\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003eabstract\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eSpringBootServletInitializer\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003eimplements\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eWebApplicationInitializer\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"nd\"\u003e@Override\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \t\u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eonStartup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eServletContext\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eservletContext\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003ethrows\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eServletException\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \t\t\u003c/span\u003e\u003cspan class=\"c1\"\u003e// Logger initialization is deferred in case a ordered\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \t\t\u003c/span\u003e\u003cspan class=\"c1\"\u003e// LogServletContextInitializer is being used\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \t\t\u003c/span\u003e\u003cspan class=\"k\"\u003ethis\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003elogger\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eLogFactory\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003egetLog\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003egetClass\u003c/span\u003e\u003cspan class=\"p\"\u003e());\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \t\t\u003c/span\u003e\u003cspan class=\"n\"\u003eWebApplicationContext\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003erootAppContext\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ecreateRootApplicationContext\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \t\t\t\t\u003c/span\u003e\u003cspan class=\"n\"\u003eservletContext\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \t\t\u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erootAppContext\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e!=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kc\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \t\t\t\u003c/span\u003e\u003cspan class=\"n\"\u003eservletContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eaddListener\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eContextLoaderListener\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erootAppContext\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{ …\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003c/div\u003e\u003c/div\u003e","tags":["spring"],"title":"SpringBootServletInitializer如何实现web.xml解析","url":"https://yinlongfei.com/posts/spring/springbootservletinitializer%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0web.xml%E8%A7%A3%E6%9E%90/","wordcount":2408},{"categories":"posts","content":"[设计实用RESTful API的最佳实践] 您的数据模型已开始稳定，您可以为您的网络应用创建公共API。您意识到，一旦API发布并且希望尽可能正确地获得API，很难对其进行重大更改。现在，互联网上对API设计的看法并不缺乏。但是，由于没有一个广泛采用的标准适用于所有情况，因此您有许多选择：您应该接受哪些格式？ 你应该如何认证？ 你的API应该被版本化吗？\n在为 Enchant （ Zendesk Alternative ） 设计API时 ，我试图为这些问题提出实用的答案。我的目标是为Enchant设计的API 是易于使用，易于采用，并具有足够的灵活性，以内部测试 为我们自己的用户界面。\n目录 API是开发人员的用户界面 - 所以要付出一些努力让它变得愉快 使用RESTful URL和操作 在任何地方使用SSL，没有例外 API只有它的文档一样好 - 所以有很好的文档 版本通过URL，而不是通过标题 使用查询参数进行高级筛选，排序和搜索 提供一种方法来限制从API返回的字段 从POST，PATCH和PUT请求中返回一些有用的东西 HATEOAS还不实用 尽可能使用JSON，只有在必要时才使用XML 你应该使用带有JSON的camelCase，但是snake_case更容易阅读20％ 默认打印漂亮并确保支持gzip 默认情况下不要使用响应封装 考虑将JSON用于POST，PUT和PATCH请求主体 使用链接标头进行分页 提供自动加载相关资源表示的方法 提供一种覆盖HTTP方法的方法 为速率限制提供有用的响应标头 使用基于令牌的身份验证，通过需要委派的OAuth2进行传输 包括便于缓存的响应标头 定义消耗品错误有效负载 有效使用HTTP状态代码 API的关键要求 网上发现的许多API设计观点都是围绕模糊标准的主观解释而不是在现实世界中有意义的学术讨论。我在这篇文章中的目标是描述为当今的Web应用程序设计的实用API的最佳实践。如果感觉不对，我不会尝试满足标准。为了帮助指导决策制定过程，我已经写下了API必须要求的一些要求：\n它应该使用有意义的 Web标准 它应该对开发人员友好，并可通过浏览器地址栏进行探索 它应该简单，直观和一致，以使采用不仅容易而且令人愉快 它应该提供足够的灵活性来为大多数 enchant UI 提供动力 它应该是有效的， …","date":1456402737,"description":"","fuzzywordcount":9800,"kind":"page","lang":"zh-cn","lastmod":1746717453,"objectID":"b71d5f819969152a3e755518a3012564","publishdate":1456402737,"relpermalink":"/posts/translations/restful-api-design/","section":"posts","summary":"\u003ch1 id=\"设计实用restful-api的最佳实践\"\u003e[设计实用RESTful API的最佳实践]\u003c/h1\u003e\n\u003cp\u003e您的数据模型已开始稳定，您可以为您的网络应用创建公共API。您意识到，一旦API发布并且希望尽可能正确地获得API，很难对其进行重大更改。现在，互联网上对API设计的看法并不缺乏。但是，由于没有一个广泛采用的标准适用于所有情况，因此您有许多选择：您应该接受哪些格式？ 你应该如何认证？ 你的API应该被版本化吗？\u003c/p\u003e","tags":["RESTful","design"],"title":"设计实用RESTful API的最佳实践","url":"https://yinlongfei.com/posts/translations/restful-api-design/","wordcount":9759}]